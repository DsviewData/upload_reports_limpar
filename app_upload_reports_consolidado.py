import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta
from io import BytesIO
from msal import ConfidentialClientApplication
import unicodedata
import logging
import os
import json
import uuid
import time

# ===========================
# CONFIGURA√á√ïES DE VERS√ÉO - ATUALIZADO v2.2.1
# ===========================
APP_VERSION = "2.2.1"
VERSION_DATE = "2025-08-07"
CHANGELOG = {
    "2.2.1": {
        "date": "2025-08-07",
        "changes": [
            "üîí Sistema de lock implementado - apenas 1 usu√°rio pode enviar por vez",
            "‚è±Ô∏è Timeout autom√°tico de 10 minutos para processos travados",
            "üìä Interface mostra status do sistema em tempo real",
            "üîÑ Auto-refresh quando sistema est√° ocupado",
            "üÜò Bot√£o de libera√ß√£o for√ßada para processos √≥rf√£os",
            "üì± Session ID √∫nico para controle de concorr√™ncia",
            "üõ°Ô∏è Prote√ß√£o completa contra perda de dados em envios simult√¢neos"
        ]
    },
    "2.2.0": {
        "date": "2025-08-07",
        "changes": [
            "üìÅ Separa√ß√£o de pastas: arquivos enviados e backups agora ficam em pasta separada",
            "üóÇÔ∏è Nova estrutura: consolidado em FontedeDados, envios/backups em PlanilhasEnviadas_Backups",
            "üíæ Sistema de backup melhorado com localiza√ß√£o dedicada",
            "üìä Interface atualizada mostrando localiza√ß√£o dos arquivos",
            "üîß Fun√ß√µes de upload especializadas por tipo de arquivo"
        ]
    },
    "2.1.0": {
        "date": "2025-08-07",
        "changes": [
            "üîç Valida√ß√£o detalhada de datas com 6 tipos de problemas diferentes",
            "üë• Exibe respons√°vel nas linhas com problemas",
            "üìä Categoriza√ß√£o visual dos problemas (VAZIO, FORMATO, FUTURO, etc.)",
            "üí° Dicas espec√≠ficas de corre√ß√£o para cada tipo de problema",
            "üìà Resumo visual por tipo de problema encontrado",
            "üè∑Ô∏è Sistema de versionamento implementado"
        ]
    },
    "2.0.0": {
        "date": "2024-12-15",
        "changes": [
            "üîÑ Nova l√≥gica de consolida√ß√£o completa",
            "üíæ Sistema de backup autom√°tico melhorado",
            "üìä M√©tricas detalhadas de consolida√ß√£o",
            "üéØ Interface aprimorada com resumos visuais"
        ]
    }
}

# ===========================
# CONFIGURA√á√ÉO DE LOGGING
# ===========================
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===========================
# CREDENCIAIS VIA ST.SECRETS
# ===========================
try:
    CLIENT_ID = st.secrets["CLIENT_ID"]
    CLIENT_SECRET = st.secrets["CLIENT_SECRET"]
    TENANT_ID = st.secrets["TENANT_ID"]
    EMAIL_ONEDRIVE = st.secrets["EMAIL_ONEDRIVE"]
    SITE_ID = st.secrets["SITE_ID"]
    DRIVE_ID = st.secrets["DRIVE_ID"]
except KeyError as e:
    st.error(f"‚ùå Credencial n√£o encontrada: {e}")
    st.stop()

# ===========================
# CONFIGURA√á√ÉO DE PASTAS - v2.2.0
# ===========================
# PASTA PRINCIPAL - onde fica o arquivo consolidado
PASTA_CONSOLIDADO = "Documentos Compartilhados/LimparAuto/FontedeDados"

# NOVA PASTA - para arquivos enviados e backups
PASTA_ENVIOS_BACKUPS = "Documentos Compartilhados/PlanilhasEnviadas_Backups/LimparAuto"

# Manter compatibilidade (algumas fun√ß√µes ainda usam)
PASTA = PASTA_CONSOLIDADO

# ===========================
# CONFIGURA√á√ÉO DO SISTEMA DE LOCK - v2.2.1 NOVO
# ===========================
ARQUIVO_LOCK = "sistema_lock.json"
TIMEOUT_LOCK_MINUTOS = 10

# ===========================
# AUTENTICA√á√ÉO
# ===========================
@st.cache_data(ttl=3300)  # Cache por 55 minutos (token v√°lido por 1h)
def obter_token():
    """Obt√©m token de acesso para Microsoft Graph API"""
    try:
        app = ConfidentialClientApplication(
            CLIENT_ID,
            authority=f"https://login.microsoftonline.com/{TENANT_ID}",
            client_credential=CLIENT_SECRET
        )
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        
        if "access_token" not in result:
            error_desc = result.get("error_description", "Token n√£o obtido")
            st.error(f"‚ùå Falha na autentica√ß√£o: {error_desc}")
            return None
            
        return result["access_token"]
        
    except Exception as e:
        st.error(f"‚ùå Erro na autentica√ß√£o: {str(e)}")
        logger.error(f"Erro de autentica√ß√£o: {e}")
        return None

# ===========================
# SISTEMA DE LOCK PARA CONTROLE DE CONCORR√äNCIA - v2.2.1 NOVO
# ===========================

def gerar_id_sessao():
    """Gera um ID √∫nico para a sess√£o atual"""
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())[:8]
    return st.session_state.session_id

def verificar_lock_existente(token):
    """Verifica se existe um lock ativo no sistema"""
    try:
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            lock_data = response.json()
            
            # Verificar se o lock n√£o expirou
            timestamp_lock = datetime.fromisoformat(lock_data['timestamp'])
            agora = datetime.now()
            
            if agora - timestamp_lock > timedelta(minutes=TIMEOUT_LOCK_MINUTOS):
                # Lock expirado - remover automaticamente
                logger.info(f"Lock expirado removido automaticamente. Era de {timestamp_lock}")
                remover_lock(token, force=True)
                return False, None
            
            return True, lock_data
        
        elif response.status_code == 404:
            # Arquivo de lock n√£o existe
            return False, None
        else:
            # Erro ao verificar - assumir que n√£o h√° lock por seguran√ßa
            logger.warning(f"Erro ao verificar lock: {response.status_code}")
            return False, None
            
    except Exception as e:
        logger.error(f"Erro ao verificar lock: {e}")
        return False, None

def criar_lock(token, operacao="Consolida√ß√£o de dados"):
    """Cria um lock para bloquear outras opera√ß√µes"""
    try:
        session_id = gerar_id_sessao()
        
        lock_data = {
            "timestamp": datetime.now().isoformat(),
            "session_id": session_id,
            "operacao": operacao,
            "status": "EM_ANDAMENTO",
            "app_version": APP_VERSION
        }
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.put(url, headers=headers, data=json.dumps(lock_data))
        
        if response.status_code in [200, 201]:
            logger.info(f"Lock criado com sucesso. Session ID: {session_id}")
            return True, session_id
        else:
            logger.error(f"Erro ao criar lock: {response.status_code}")
            return False, None
            
    except Exception as e:
        logger.error(f"Erro ao criar lock: {e}")
        return False, None

def remover_lock(token, session_id=None, force=False):
    """Remove o lock do sistema"""
    try:
        if not force and session_id:
            # Verificar se o lock pertence a esta sess√£o
            lock_existe, lock_data = verificar_lock_existente(token)
            if lock_existe and lock_data.get('session_id') != session_id:
                logger.warning("Tentativa de remover lock de outra sess√£o!")
                return False
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.delete(url, headers=headers)
        
        if response.status_code in [200, 204]:
            logger.info("Lock removido com sucesso")
            return True
        elif response.status_code == 404:
            # Lock j√° n√£o existe
            return True
        else:
            logger.error(f"Erro ao remover lock: {response.status_code}")
            return False
            
    except Exception as e:
        logger.error(f"Erro ao remover lock: {e}")
        return False

def atualizar_status_lock(token, session_id, novo_status, detalhes=None):
    """Atualiza o status do lock durante o processo"""
    try:
        lock_existe, lock_data = verificar_lock_existente(token)
        
        if not lock_existe or lock_data.get('session_id') != session_id:
            logger.warning("Lock n√£o existe ou n√£o pertence a esta sess√£o")
            return False
        
        # Atualizar dados do lock
        lock_data['status'] = novo_status
        lock_data['ultima_atualizacao'] = datetime.now().isoformat()
        
        if detalhes:
            lock_data['detalhes'] = detalhes
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.put(url, headers=headers, data=json.dumps(lock_data))
        return response.status_code in [200, 201]
        
    except Exception as e:
        logger.error(f"Erro ao atualizar status do lock: {e}")
        return False

def exibir_status_sistema(token):
    """Exibe o status atual do sistema de lock"""
    lock_existe, lock_data = verificar_lock_existente(token)
    
    if lock_existe:
        timestamp_inicio = datetime.fromisoformat(lock_data['timestamp'])
        duracao = datetime.now() - timestamp_inicio
        
        # Determinar cor baseada na dura√ß√£o
        if duracao.total_seconds() < 60:  # Menos de 1 minuto
            cor = "üü°"  # Amarelo - normal
        elif duracao.total_seconds() < 300:  # Menos de 5 minutos  
            cor = "üü†"  # Laranja - demorado
        else:  # Mais de 5 minutos
            cor = "üî¥"  # Vermelho - muito demorado
        
        # Calcular tempo restante at√© timeout
        tempo_limite = timestamp_inicio + timedelta(minutes=TIMEOUT_LOCK_MINUTOS)
        tempo_restante = tempo_limite - datetime.now()
        
        st.error(f"üîí **Sistema ocupado** - Outro usu√°rio est√° enviando dados")
        
        with st.expander("‚ÑπÔ∏è Detalhes do processo em andamento"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.info(f"**Opera√ß√£o:** {lock_data.get('operacao', 'N/A')}")
                st.info(f"**Status:** {lock_data.get('status', 'N/A')}")
                st.info(f"**In√≠cio:** {timestamp_inicio.strftime('%H:%M:%S')}")
                
            with col2:
                st.info(f"{cor} **Dura√ß√£o:** {int(duracao.total_seconds()//60)}min {int(duracao.total_seconds()%60)}s")
                if tempo_restante.total_seconds() > 0:
                    st.info(f"‚è±Ô∏è **Timeout em:** {int(tempo_restante.total_seconds()//60)}min")
                else:
                    st.warning("‚ö†Ô∏è **Processo pode ter travado** (ser√° liberado automaticamente)")
                
            # Detalhes adicionais se dispon√≠veis
            if 'detalhes' in lock_data:
                st.info(f"**Detalhes:** {lock_data['detalhes']}")
                
            # Mostrar session ID para debug (apenas alguns caracteres)
            session_id_display = lock_data.get('session_id', 'N/A')[:8]
            st.caption(f"Session ID: {session_id_display}")
        
        # Bot√£o de for√ßa para administradores (caso necess√°rio)
        if tempo_restante.total_seconds() < 0:
            if st.button("üÜò Liberar Sistema (For√ßar)", type="secondary"):
                if remover_lock(token, force=True):
                    st.success("‚úÖ Sistema liberado com sucesso!")
                    st.rerun()
                else:
                    st.error("‚ùå Erro ao liberar sistema")
        
        return True  # Sistema ocupado
    else:
        # Sistema livre
        st.success("‚úÖ **Sistema dispon√≠vel** - Voc√™ pode enviar sua planilha")
        return False  # Sistema livre

# ===========================
# FUN√á√ïES AUXILIARES
# ===========================

def criar_pasta_se_nao_existir(caminho_pasta, token):
    """Cria pasta no OneDrive se n√£o existir"""
    try:
        # Dividir o caminho em partes
        partes = caminho_pasta.split('/')
        caminho_atual = ""
        
        for parte in partes:
            if not parte:
                continue
                
            caminho_anterior = caminho_atual
            caminho_atual = f"{caminho_atual}/{parte}" if caminho_atual else parte
            
            # Verificar se a pasta existe
            url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{caminho_atual}"
            headers = {"Authorization": f"Bearer {token}"}
            response = requests.get(url, headers=headers)
            
            if response.status_code == 404:
                # Criar pasta
                parent_url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root"
                if caminho_anterior:
                    parent_url += f":/{caminho_anterior}"
                parent_url += ":/children"
                
                create_body = {
                    "name": parte,
                    "folder": {},
                    "@microsoft.graph.conflictBehavior": "rename"
                }
                
                create_response = requests.post(
                    parent_url, 
                    headers={**headers, "Content-Type": "application/json"}, 
                    json=create_body
                )
                
                if create_response.status_code not in [200, 201]:
                    logger.warning(f"N√£o foi poss√≠vel criar pasta {parte}")
                    
    except Exception as e:
        logger.warning(f"Erro ao criar estrutura de pastas: {e}")

# ===========================
# UPLOAD E BACKUP - v2.2.0
# ===========================
def upload_onedrive(nome_arquivo, conteudo_arquivo, token, tipo_arquivo="consolidado"):
    """
    Faz upload de arquivo para OneDrive com pasta espec√≠fica baseada no tipo
    
    tipo_arquivo: "consolidado", "enviado", "backup"
    """
    try:
        # Determinar pasta baseada no tipo
        if tipo_arquivo == "consolidado":
            pasta_base = PASTA_CONSOLIDADO
        elif tipo_arquivo in ["enviado", "backup"]:
            pasta_base = PASTA_ENVIOS_BACKUPS
        else:
            pasta_base = PASTA_CONSOLIDADO  # fallback
        
        # Garantir que a pasta existe
        pasta_arquivo = "/".join(nome_arquivo.split("/")[:-1]) if "/" in nome_arquivo else ""
        if pasta_arquivo:
            criar_pasta_se_nao_existir(f"{pasta_base}/{pasta_arquivo}", token)
        
        # Fazer backup se arquivo j√° existir (apenas para consolidado)
        if tipo_arquivo == "consolidado" and "/" not in nome_arquivo:
            mover_arquivo_existente(nome_arquivo, token, pasta_base)
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{pasta_base}/{nome_arquivo}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/octet-stream"
        }
        response = requests.put(url, headers=headers, data=conteudo_arquivo)
        
        return response.status_code in [200, 201], response.status_code, response.text
        
    except Exception as e:
        logger.error(f"Erro no upload: {e}")
        return False, 500, f"Erro interno: {str(e)}"

def mover_arquivo_existente(nome_arquivo, token, pasta_base=None):
    """Move arquivo existente para backup antes de substituir"""
    try:
        if pasta_base is None:
            pasta_base = PASTA_CONSOLIDADO
            
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{pasta_base}/{nome_arquivo}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            file_id = response.json().get("id")
            timestamp = datetime.now().strftime("%Y-%m-%d_%Hh%M")
            nome_base = nome_arquivo.replace(".xlsx", "")
            novo_nome = f"{nome_base}_backup_{timestamp}.xlsx"
            
            patch_url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/items/{file_id}"
            patch_body = {"name": novo_nome}
            patch_headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }
            patch_response = requests.patch(patch_url, headers=patch_headers, json=patch_body)
            
            if patch_response.status_code in [200, 201]:
                st.info(f"üíæ Backup criado: {novo_nome}")
            else:
                st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel criar backup do arquivo existente")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao processar backup: {str(e)}")
        logger.error(f"Erro no backup: {e}")

# ===========================
# VALIDA√á√ÉO MELHORADA DE DATAS
# ===========================
def validar_datas_detalhadamente(df):
    """
    üîç NOVA VALIDA√á√ÉO DETALHADA DE DATAS - v2.1.0
    
    Detecta 6 tipos diferentes de problemas:
    1. VAZIO - Datas em branco ou nulas
    2. FORMATO - Formatos inv√°lidos ou n√£o convers√≠veis
    3. IMPOSS√çVEL - Datas logicamente imposs√≠veis (31/02)
    4. FUTURO - Datas muito distantes no futuro
    5. ANTIGA - Datas muito antigas
    6. INCONSISTENTE - Outros problemas de consist√™ncia
    """
    from datetime import datetime
    import pandas as pd
    
    problemas = []
    
    logger.info(f"üîç Iniciando valida√ß√£o detalhada de {len(df)} registros...")
    
    for idx, row in df.iterrows():
        linha_excel = idx + 2  # Excel come√ßa em 1 + cabe√ßalho
        valor_original = row["DATA"]
        responsavel = row.get("RESPONS√ÅVEL", "N/A")
        
        problema_encontrado = None
        tipo_problema = None
        data_convertida = None
        
        # 1. VERIFICAR SE DATA EST√Å VAZIA
        if pd.isna(valor_original) or str(valor_original).strip() == "":
            problema_encontrado = "Data vazia ou nula"
            tipo_problema = "VAZIO"
            
        else:
            try:
                # 2. TENTAR CONVERTER PARA DATETIME
                data_convertida = pd.to_datetime(valor_original, errors='raise')
                
                # 3. VERIFICA√á√ïES DE L√ìGICA DE NEG√ìCIO
                hoje = datetime.now()
                ano_atual = hoje.year
                
                # Data muito no futuro (mais de 2 anos)
                if data_convertida > hoje + pd.Timedelta(days=730):
                    problema_encontrado = f"Data muito distante no futuro: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "FUTURO"
                
                # Data muito antiga (antes de 2020)
                elif data_convertida < pd.Timestamp('2020-01-01'):
                    problema_encontrado = f"Data muito antiga: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "ANTIGA"
                
                # Verificar datas imposs√≠veis (ex: 31/02, 30/02, etc.)
                elif data_convertida.day > 31 or data_convertida.month > 12:
                    problema_encontrado = f"Data imposs√≠vel: dia={data_convertida.day}, m√™s={data_convertida.month}"
                    tipo_problema = "IMPOSS√çVEL"
                    
                # Verificar se a data est√° num futuro muito pr√≥ximo mas suspeito
                elif data_convertida > hoje + pd.Timedelta(days=90):
                    problema_encontrado = f"Data no futuro (verificar se est√° correta): {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "FUTURO"
                    
            except (ValueError, TypeError, pd.errors.OutOfBoundsDatetime, OverflowError) as e:
                # Data n√£o pode ser convertida - problema de formato
                problema_encontrado = f"Formato inv√°lido: '{str(valor_original)}'"
                tipo_problema = "FORMATO"
                logger.debug(f"Erro de convers√£o na linha {linha_excel}: {e}")
        
        # Se encontrou qualquer problema, adicionar aos detalhes
        if problema_encontrado:
            problemas.append({
                "Linha no Excel": linha_excel,
                "Data Inv√°lida": str(valor_original)[:50],  # Limitar tamanho
                "Tipo Problema": tipo_problema,
                "Descri√ß√£o": problema_encontrado,
                "Respons√°vel": str(responsavel)[:30]  # Limitar tamanho
            })
    
    logger.info(f"‚úÖ Valida√ß√£o conclu√≠da: {len(problemas)} problemas encontrados")
    return problemas

def exibir_relatorio_problemas_datas(problemas_datas):
    """
    üìã Exibe relat√≥rio visual detalhado dos problemas encontrados nas datas
    """
    if not problemas_datas:
        st.success("‚úÖ **Todas as datas est√£o v√°lidas e consistentes!**")
        return
    
    # Cabe√ßalho do relat√≥rio
    st.error(f"‚ùó **ATEN√á√ÉO: {len(problemas_datas)} problemas encontrados nas datas**")
    
    # Converter para DataFrame para an√°lise
    df_problemas = pd.DataFrame(problemas_datas)
    
    # 1. RESUMO POR TIPO DE PROBLEMA
    if "Tipo Problema" in df_problemas.columns:
        tipos_problema = df_problemas.groupby('Tipo Problema').size().sort_values(ascending=False)
        
        st.markdown("### üìä **Resumo dos Problemas:**")
        
        # Criar colunas para mostrar os tipos
        cols = st.columns(min(len(tipos_problema), 4))
        
        emoji_map = {
            "VAZIO": "üî¥",
            "FORMATO": "üü†", 
            "IMPOSS√çVEL": "üü£",
            "FUTURO": "üü°",
            "ANTIGA": "üü§",
            "INCONSISTENTE": "‚ö´"
        }
        
        for i, (tipo, qtd) in enumerate(tipos_problema.items()):
            emoji = emoji_map.get(tipo, "‚ùå")
            col_idx = i % len(cols)
            
            with cols[col_idx]:
                st.metric(
                    label=f"{emoji} {tipo}",
                    value=f"{qtd} linha{'s' if qtd > 1 else ''}",
                    help=f"Problemas do tipo {tipo}"
                )
    
    st.divider()
    
    # 2. TABELA DETALHADA DOS PROBLEMAS
    st.markdown("### üìã **Detalhes das Linhas com Problemas:**")
    
    # Preparar colunas para exibi√ß√£o
    colunas_exibir = ["Linha no Excel", "Respons√°vel", "Data Inv√°lida", "Descri√ß√£o"]
    
    # Limitar n√∫mero de linhas exibidas para n√£o sobrecarregar
    max_linhas_exibir = 50
    
    if len(df_problemas) <= max_linhas_exibir:
        st.dataframe(
            df_problemas[colunas_exibir], 
            use_container_width=True, 
            hide_index=True,
            height=min(400, len(df_problemas) * 35)
        )
    else:
        st.dataframe(
            df_problemas.head(max_linhas_exibir)[colunas_exibir], 
            use_container_width=True, 
            hide_index=True,
            height=400
        )
        st.warning(f"‚ö†Ô∏è **Exibindo apenas as primeiras {max_linhas_exibir} linhas.** Total de problemas: {len(df_problemas)}")
    
    # 3. AN√ÅLISE POR RESPONS√ÅVEL
    if "Respons√°vel" in df_problemas.columns:
        responsaveis_problemas = df_problemas.groupby('Respons√°vel').size().sort_values(ascending=False)
        
        if len(responsaveis_problemas) > 1:
            st.markdown("### üë• **Problemas por Respons√°vel:**")
            
            col1, col2 = st.columns([2, 3])
            
            with col1:
                for responsavel, qtd in responsaveis_problemas.head(5).items():
                    st.write(f"‚Ä¢ **{responsavel}**: {qtd} problema{'s' if qtd > 1 else ''}")
                    
                if len(responsaveis_problemas) > 5:
                    st.write(f"‚Ä¢ ... e mais {len(responsaveis_problemas) - 5} respons√°veis")
            
            with col2:
                # Gr√°fico simples de problemas por respons√°vel
                st.bar_chart(responsaveis_problemas.head(10))
    
    st.divider()
    
    # 4. GUIA DE CORRE√á√ÉO DETALHADA
    st.markdown("### üí° **Guia de Corre√ß√£o:**")
    
    with st.expander("üìñ Como corrigir cada tipo de problema", expanded=True):
        
        guia_correcao = {
            "VAZIO": {
                "emoji": "üî¥",
                "problema": "C√©lulas de data em branco",
                "solucao": "Preencha com a data correta no formato DD/MM/AAAA",
                "exemplo": "Exemplo: 15/03/2024"
            },
            "FORMATO": {
                "emoji": "üü†", 
                "problema": "Formato de data inv√°lido",
                "solucao": "Use apenas n√∫meros no formato DD/MM/AAAA",
                "exemplo": "‚úÖ 15/03/2024  ‚ùå '15 de mar√ßo' ou 'mar√ßo/2024'"
            },
            "IMPOSS√çVEL": {
                "emoji": "üü£",
                "problema": "Datas que n√£o existem no calend√°rio",
                "solucao": "Verifique dia e m√™s (ex: fevereiro n√£o tem 30 dias)",
                "exemplo": "‚úÖ 28/02/2024  ‚ùå 31/02/2024"
            },
            "FUTURO": {
                "emoji": "üü°",
                "problema": "Datas muito distantes no futuro",
                "solucao": "Verifique se o ano est√° correto",
                "exemplo": "Se for 2024, n√£o use 2034"
            },
            "ANTIGA": {
                "emoji": "üü§",
                "problema": "Datas muito antigas (antes de 2020)",
                "solucao": "Confirme se o ano est√° correto",
                "exemplo": "Se for 2024, n√£o use 2014"
            }
        }
        
        # Mostrar apenas as dicas para os tipos de problema encontrados
        tipos_encontrados = df_problemas['Tipo Problema'].unique()
        
        for tipo in tipos_encontrados:
            if tipo in guia_correcao:
                info = guia_correcao[tipo]
                
                st.markdown(f"""
                **{info['emoji']} {tipo}:**
                - **Problema:** {info['problema']}
                - **Solu√ß√£o:** {info['solucao']}
                - **{info['exemplo']}**
                """)
    
    # 5. BOT√ÉO DE DOWNLOAD DO RELAT√ìRIO
    with st.expander("üíæ Baixar relat√≥rio de problemas"):
        if st.button("üì• Gerar Excel com problemas encontrados"):
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df_problemas.to_excel(writer, index=False, sheet_name="Problemas_Datas")
            buffer.seek(0)
            
            st.download_button(
                label="‚¨áÔ∏è Baixar relat√≥rio de problemas",
                data=buffer.getvalue(),
                file_name=f"problemas_datas_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

# ===========================
# VALIDA√á√ÉO COMPLETA MELHORADA
# ===========================
def validar_dados_enviados(df):
    """
    üîç VALIDA√á√ÉO COMPLETA DOS DADOS ENVIADOS - v2.1.0
    
    Inclui valida√ß√£o melhorada de datas com detalhamento completo dos problemas
    """
    erros = []
    avisos = []
    linhas_invalidas_detalhes = []
    
    # Validar se DataFrame n√£o est√° vazio
    if df.empty:
        erros.append("‚ùå A planilha est√° vazia")
        return erros, avisos, linhas_invalidas_detalhes
    
    # Validar se existe coluna RESPONS√ÅVEL
    if "RESPONS√ÅVEL" not in df.columns:
        erros.append("‚ö†Ô∏è A planilha deve conter uma coluna 'RESPONS√ÅVEL'")
        avisos.append("üìã Certifique-se de que sua planilha tenha uma coluna chamada 'RESPONS√ÅVEL'")
    else:
        # Validar se h√° respons√°veis v√°lidos
        responsaveis_validos = df["RESPONS√ÅVEL"].notna().sum()
        if responsaveis_validos == 0:
            erros.append("‚ùå Nenhum respons√°vel v√°lido encontrado na coluna 'RESPONS√ÅVEL'")
        else:
            # Mostrar respons√°veis √∫nicos encontrados
            responsaveis_unicos = df["RESPONS√ÅVEL"].dropna().unique()
            if len(responsaveis_unicos) > 0:
                avisos.append(f"üë• Respons√°veis encontrados: {', '.join(responsaveis_unicos[:5])}")
                if len(responsaveis_unicos) > 5:
                    avisos.append(f"... e mais {len(responsaveis_unicos) - 5} respons√°veis")
    
    # NOVA VALIDA√á√ÉO DETALHADA DE DATAS
    if "DATA" not in df.columns:
        erros.append("‚ö†Ô∏è A planilha deve conter uma coluna 'DATA'")
        avisos.append("üìã Lembre-se: o arquivo deve ter uma aba chamada 'Vendas CTs' com as colunas 'DATA' e 'RESPONS√ÅVEL'")
    else:
        # Executar valida√ß√£o detalhada de datas
        problemas_datas = validar_datas_detalhadamente(df)
        
        if problemas_datas:
            avisos.append(f"‚ö†Ô∏è {len(problemas_datas)} linhas com problemas de data ser√£o ignoradas")
            
            # Converter para formato esperado pela interface
            linhas_invalidas_detalhes = problemas_datas
        else:
            avisos.append("‚úÖ Todas as datas est√£o v√°lidas e consistentes!")
    
    # Validar duplicatas na planilha enviada
    if not df.empty and "DATA" in df.columns:
        df_temp = df.copy()
        df_temp["DATA"] = pd.to_datetime(df_temp["DATA"], errors="coerce")
        df_temp = df_temp.dropna(subset=["DATA"])
        
        if not df_temp.empty:
            duplicatas = df_temp.duplicated(subset=["DATA"], keep=False).sum()
            if duplicatas > 0:
                avisos.append(f"‚ö†Ô∏è {duplicatas} linhas com datas duplicadas na planilha")
    
    return erros, avisos, linhas_invalidas_detalhes

# ===========================
# FUN√á√ïES DE CONSOLIDA√á√ÉO - v2.2.0
# ===========================

def baixar_arquivo_consolidado(token):
    """Baixa o arquivo consolidado existente da pasta espec√≠fica"""
    consolidado_nome = "Reports_Geral_Consolidado.xlsx"
    url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{consolidado_nome}:/content"
    headers = {"Authorization": f"Bearer {token}"}
    
    try:
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            df_consolidado = pd.read_excel(BytesIO(response.content))
            df_consolidado.columns = df_consolidado.columns.str.strip().str.upper()
            return df_consolidado, True
        else:
            return pd.DataFrame(), False
            
    except Exception as e:
        logger.error(f"Erro ao baixar arquivo consolidado: {e}")
        return pd.DataFrame(), False

def criar_backup_substituicoes(df_consolidado, detalhes_operacao, token):
    """Cria backup dos registros que foram substitu√≠dos na pasta de backups"""
    try:
        # Extrair apenas opera√ß√µes de remo√ß√£o
        removidos = [d for d in detalhes_operacao if d["Opera√ß√£o"] == "REMOVIDO"]
        
        if not removidos:
            return
        
        # Identificar os registros que foram removidos
        registros_backup = []
        
        for item in removidos:
            responsavel = item["Respons√°vel"]
            data_str = item["Data"]
            data = pd.to_datetime(data_str, format="%d/%m/%Y").date()
            
            mask = (
                (df_consolidado["DATA"].dt.date == data) &
                (df_consolidado["RESPONS√ÅVEL"].str.strip().str.upper() == str(responsavel).strip().upper())
            )
            
            registros_removidos = df_consolidado[mask]
            if not registros_removidos.empty:
                registros_backup.append(registros_removidos)
        
        if registros_backup:
            df_backup = pd.concat(registros_backup, ignore_index=True)
            
            # Adicionar metadados de backup
            df_backup["BACKUP_TIMESTAMP"] = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
            df_backup["BACKUP_MOTIVO"] = "Substitui√ß√£o por novo envio"
            df_backup["APP_VERSION"] = APP_VERSION
            
            # Salvar backup NA NOVA PASTA
            timestamp = datetime.now().strftime('%d-%m-%Y_%Hh%M')
            nome_backup = f"Backups_Substituicoes/backup_substituicao_{timestamp}.xlsx"
            
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df_backup.to_excel(writer, index=False, sheet_name="Registros Substituidos")
            buffer.seek(0)
            
            # USAR NOVA FUN√á√ÉO COM TIPO "backup"
            sucesso, _, _ = upload_onedrive(nome_backup, buffer.read(), token, "backup")
            if sucesso:
                st.info(f"üíæ Backup dos dados substitu√≠dos criado: {PASTA_ENVIOS_BACKUPS}/{nome_backup}")
            else:
                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel criar backup dos dados substitu√≠dos")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao criar backup: {e}")
        logger.error(f"Erro no backup: {e}")

def comparar_e_atualizar_registros(df_consolidado, df_novo):
    """
    L√ìGICA DE CONSOLIDA√á√ÉO COMPLETA:
    
    Para cada combina√ß√£o RESPONS√ÅVEL + DATA no arquivo enviado:
    
    1. SE N√ÉO EXISTE na planilha consolidada:
       ‚ûï INSERE todos os novos registros
       
    2. SE J√Å EXISTE na planilha consolidada:
       üóëÔ∏è REMOVE todos os registros antigos dessa combina√ß√£o
       ‚ûï INSERE todos os novos registros (SUBSTITUI√á√ÉO COMPLETA)
    
    Isso garante que:
    - Novos dados s√£o sempre inclu√≠dos
    - Dados existentes s√£o completamente atualizados
    - N√£o h√° conflitos ou dados parciais
    """
    registros_inseridos = 0
    registros_substituidos = 0
    registros_removidos = 0
    detalhes_operacao = []
    combinacoes_novas = 0
    combinacoes_existentes = 0
    
    if df_consolidado.empty:
        # Primeiro envio - todos os registros s√£o novos
        df_final = df_novo.copy()
        registros_inseridos = len(df_novo)
        
        # Contar combina√ß√µes √∫nicas
        combinacoes_unicas = df_novo.groupby(['RESPONS√ÅVEL', df_novo['DATA'].dt.date]).size()
        combinacoes_novas = len(combinacoes_unicas)
        
        for _, row in df_novo.iterrows():
            detalhes_operacao.append({
                "Opera√ß√£o": "INSERIDO",
                "Respons√°vel": row["RESPONS√ÅVEL"],
                "Data": row["DATA"].strftime("%d/%m/%Y"),
                "Motivo": "Primeira consolida√ß√£o - arquivo vazio"
            })
        
        return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao, combinacoes_novas, combinacoes_existentes
    
    # Garantir que as colunas existem no consolidado
    colunas = df_novo.columns.tolist()
    for col in colunas:
        if col not in df_consolidado.columns:
            df_consolidado[col] = None
    
    # Criar c√≥pia para trabalhar
    df_final = df_consolidado.copy()
    
    # Agrupar registros novos por RESPONS√ÅVEL e DATA
    grupos_novos = df_novo.groupby(['RESPONS√ÅVEL', df_novo['DATA'].dt.date])
    
    for (responsavel, data_grupo), grupo_df in grupos_novos:
        if pd.isna(responsavel) or str(responsavel).strip() == '':
            continue
            
        # Buscar registros existentes para este respons√°vel e data
        mask_existente = (
            (df_final["DATA"].dt.date == data_grupo) &
            (df_final["RESPONS√ÅVEL"].str.strip().str.upper() == str(responsavel).strip().upper())
        )
        
        registros_existentes = df_final[mask_existente]
        
        if not registros_existentes.empty:
            # ===== CEN√ÅRIO 2: SUBSTITUI√á√ÉO COMPLETA =====
            num_removidos = len(registros_existentes)
            df_final = df_final[~mask_existente]
            registros_removidos += num_removidos
            combinacoes_existentes += 1
            
            # Adicionar detalhes da remo√ß√£o
            detalhes_operacao.append({
                "Opera√ß√£o": "REMOVIDO",
                "Respons√°vel": responsavel,
                "Data": data_grupo.strftime("%d/%m/%Y"),
                "Motivo": f"Substitui√ß√£o: {num_removidos} registro(s) antigo(s) removido(s)"
            })
            
            registros_substituidos += len(grupo_df)
            operacao_tipo = "SUBSTITU√çDO"
            motivo = f"Substitui√ß√£o completa: {len(grupo_df)} novo(s) registro(s)"
        else:
            # ===== CEN√ÅRIO 1: INSER√á√ÉO DE NOVOS DADOS =====
            registros_inseridos += len(grupo_df)
            combinacoes_novas += 1
            operacao_tipo = "INSERIDO"
            motivo = f"Nova combina√ß√£o: {len(grupo_df)} registro(s) inserido(s)"
        
        # Inserir novos registros (tanto para inser√ß√£o quanto substitui√ß√£o)
        df_final = pd.concat([df_final, grupo_df], ignore_index=True)
        
        # Adicionar detalhes da opera√ß√£o
        detalhes_operacao.append({
            "Opera√ß√£o": operacao_tipo,
            "Respons√°vel": responsavel,
            "Data": data_grupo.strftime("%d/%m/%Y"),
            "Motivo": motivo
        })
    
    return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao, combinacoes_novas, combinacoes_existentes

def salvar_arquivo_enviado(df, nome_arquivo_original, token):
    """Salva o arquivo enviado com o nome original na nova pasta de enviados"""
    try:
        if not df.empty and "DATA" in df.columns:
            data_base = df["DATA"].min()
            nome_pasta = f"Relatorios_Enviados/{data_base.strftime('%Y-%m')}"
            timestamp = datetime.now().strftime('%d-%m-%Y_%Hh%M')
            
            # Usar nome original do arquivo com timestamp
            nome_sem_extensao = os.path.splitext(nome_arquivo_original)[0]
            nome_arquivo = f"{nome_pasta}/{nome_sem_extensao}_{timestamp}_v{APP_VERSION}.xlsx"
            
            # Salvar arquivo
            buffer_envio = BytesIO()
            with pd.ExcelWriter(buffer_envio, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name="Vendas CTs")
            buffer_envio.seek(0)
            
            # USAR NOVA FUN√á√ÉO COM TIPO "enviado"
            sucesso, _, _ = upload_onedrive(nome_arquivo, buffer_envio.read(), token, "enviado")
            if sucesso:
                st.info(f"üíæ Arquivo salvo como: {PASTA_ENVIOS_BACKUPS}/{nome_arquivo}")
            else:
                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel salvar c√≥pia do arquivo enviado")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel salvar c√≥pia do arquivo: {e}")
        logger.error(f"Erro ao salvar arquivo enviado: {e}")

# ===========================
# NOVA FUN√á√ÉO DE CONSOLIDA√á√ÉO COM LOCK - v2.2.1
# ===========================

def processar_consolidacao_com_lock(df_novo, nome_arquivo, token):
    """
    Vers√£o protegida da consolida√ß√£o com sistema de lock
    """
    session_id = gerar_id_sessao()
    
    try:
        # 1. Verificar se sistema est√° livre
        sistema_ocupado, lock_data = verificar_lock_existente(token)
        if sistema_ocupado:
            st.error("üîí Sistema ocupado! Outro usu√°rio est√° fazendo consolida√ß√£o.")
            return False
        
        # 2. Criar lock
        st.info("üîí Bloqueando sistema para consolida√ß√£o...")
        lock_criado, session_lock = criar_lock(token, "Consolida√ß√£o de planilha")
        
        if not lock_criado:
            st.error("‚ùå N√£o foi poss√≠vel bloquear o sistema. Tente novamente.")
            return False
        
        st.success(f"‚úÖ Sistema bloqueado com sucesso! (ID: {session_lock})")
        
        # 3. Atualizar status: baixando arquivo
        atualizar_status_lock(token, session_lock, "BAIXANDO_ARQUIVO", "Baixando arquivo consolidado")
        
        # 4. Baixar arquivo consolidado existente
        with st.spinner("üì• Baixando arquivo consolidado existente..."):
            df_consolidado, arquivo_existe = baixar_arquivo_consolidado(token)
        
        if arquivo_existe:
            st.info(f"üìÇ Arquivo consolidado carregado ({len(df_consolidado):,} registros)")
        else:
            st.info("üìÇ Criando novo arquivo consolidado")

        # 5. Atualizar status: preparando dados
        atualizar_status_lock(token, session_lock, "PREPARANDO_DADOS", "Validando e preparando dados")
        
        # 6. Preparar dados novos
        df_novo = df_novo.copy()
        df_novo.columns = df_novo.columns.str.strip().str.upper()
        
        # Converter datas e remover linhas inv√°lidas
        df_novo["DATA"] = pd.to_datetime(df_novo["DATA"], errors="coerce")
        linhas_invalidas = df_novo["DATA"].isna().sum()
        df_novo = df_novo.dropna(subset=["DATA"])

        if df_novo.empty:
            st.error("‚ùå Nenhum registro v√°lido para consolidar")
            remover_lock(token, session_lock)
            return False

        if linhas_invalidas > 0:
            st.info(f"üßπ {linhas_invalidas} linhas com datas inv√°lidas foram removidas")

        # 7. An√°lise pr√©via dos dados
        responsaveis_no_envio = df_novo["RESPONS√ÅVEL"].dropna().unique()
        periodo_min = df_novo["DATA"].min().strftime("%d/%m/%Y")
        periodo_max = df_novo["DATA"].max().strftime("%d/%m/%Y")
        
        combinacoes_envio = df_novo.groupby(['RESPONS√ÅVEL', df_novo['DATA'].dt.date]).size()
        total_combinacoes = len(combinacoes_envio)
        
        st.info(f"üë• **Respons√°veis:** {', '.join(responsaveis_no_envio)}")
        st.info(f"üìÖ **Per√≠odo:** {periodo_min} at√© {periodo_max}")
        st.info(f"üìä **Combina√ß√µes √∫nicas (Respons√°vel + Data):** {total_combinacoes}")
        
        # 8. Verificar se haver√° substitui√ß√µes
        if arquivo_existe and not df_consolidado.empty:
            df_consolidado["DATA"] = pd.to_datetime(df_consolidado["DATA"], errors="coerce")
            df_consolidado = df_consolidado.dropna(subset=["DATA"])
            
            registros_para_consolidar = 0
            registros_para_alterar = 0
            
            for responsavel in responsaveis_no_envio:
                datas_envio = df_novo[df_novo["RESPONS√ÅVEL"] == responsavel]["DATA"].dt.date.unique()
                
                for data in datas_envio:
                    mask_conflito = (
                        (df_consolidado["DATA"].dt.date == data) &
                        (df_consolidado["RESPONS√ÅVEL"].str.strip().str.upper() == str(responsavel).strip().upper())
                    )
                    
                    registros_envio = len(df_novo[
                        (df_novo["RESPONS√ÅVEL"] == responsavel) & 
                        (df_novo["DATA"].dt.date == data)
                    ])
                    
                    if mask_conflito.any():
                        registros_para_alterar += registros_envio
                    else:
                        registros_para_consolidar += registros_envio
            
            # Mostrar informa√ß√µes
            if registros_para_consolidar > 0 and registros_para_alterar == 0:
                st.success(f"‚úÖ **{registros_para_consolidar} registro(s) ser√£o CONSOLIDADOS** (dados novos)")
                st.info("‚ÑπÔ∏è Nenhum registro existente ser√° alterado")
                
            elif registros_para_alterar > 0 and registros_para_consolidar == 0:
                st.warning(f"üîÑ **{registros_para_alterar} registro(s) ser√£o ALTERADOS** (substituindo dados existentes)")
                st.info("‚ÑπÔ∏è Nenhum registro novo ser√° adicionado")
                
            elif registros_para_consolidar > 0 and registros_para_alterar > 0:
                col1, col2 = st.columns(2)
                with col1:
                    st.success(f"‚úÖ **{registros_para_consolidar} registro(s) ser√£o CONSOLIDADOS**")
                    st.caption("(dados completamente novos)")
                with col2:
                    st.warning(f"üîÑ **{registros_para_alterar} registro(s) ser√£o ALTERADOS**")
                    st.caption("(substituindo dados existentes)")
            
            else:
                st.error("‚ùå Nenhum registro v√°lido encontrado para processar")
                remover_lock(token, session_lock)
                return False
        else:
            st.success(f"‚úÖ **{len(df_novo)} registro(s) ser√£o CONSOLIDADOS** (primeira consolida√ß√£o)")

        # 9. Atualizar status: processando consolida√ß√£o
        atualizar_status_lock(token, session_lock, "CONSOLIDANDO", f"Processando {len(df_novo)} registros")
        
        # 10. Processar consolida√ß√£o
        with st.spinner("üîÑ Processando consolida√ß√£o (nova l√≥gica)..."):
            df_final, inseridos, substituidos, removidos, detalhes, novas_combinacoes, combinacoes_existentes = comparar_e_atualizar_registros(
                df_consolidado, df_novo
            )

        # 11. Ordenar por data e respons√°vel
        df_final = df_final.sort_values(["DATA", "RESPONS√ÅVEL"], na_position='last').reset_index(drop=True)
        
        # 12. Atualizar status: criando backups
        if removidos > 0:
            atualizar_status_lock(token, session_lock, "CRIANDO_BACKUP", f"Backup de {removidos} registros substitu√≠dos")
            criar_backup_substituicoes(df_consolidado, detalhes, token)
        
        # 13. Atualizar status: salvando arquivo enviado
        atualizar_status_lock(token, session_lock, "SALVANDO_ENVIADO", "Salvando c√≥pia do arquivo enviado")
        salvar_arquivo_enviado(df_novo, nome_arquivo, token)
        
        # 14. Atualizar status: upload final
        atualizar_status_lock(token, session_lock, "UPLOAD_FINAL", "Salvando arquivo consolidado")
        
        # 15. Salvar arquivo consolidado
        with st.spinner("üì§ Salvando arquivo consolidado..."):
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df_final.to_excel(writer, index=False, sheet_name="Vendas CTs")
            buffer.seek(0)
            
            consolidado_nome = "Reports_Geral_Consolidado.xlsx"
            sucesso, status, resposta = upload_onedrive(consolidado_nome, buffer.read(), token, "consolidado")

        # 16. Remover lock SEMPRE (sucesso ou erro)
        remover_lock(token, session_lock)
        
        if sucesso:
            st.success("üîì Sistema liberado!")
            st.success("‚úÖ Consolida√ß√£o realizada com sucesso!")
            
            # Mostrar localiza√ß√£o dos arquivos
            with st.expander("üìÅ Localiza√ß√£o dos Arquivos", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"üìä **Arquivo Consolidado:**\n`{PASTA_CONSOLIDADO}/Reports_Geral_Consolidado.xlsx`")
                with col2:
                    st.info(f"üíæ **Backups e Envios:**\n`{PASTA_ENVIOS_BACKUPS}/`")
            
            # M√©tricas de resultado
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä Total Final", f"{len(df_final):,}")
            with col2:
                st.metric("‚ûï Inseridos", f"{inseridos}")
            with col3:
                st.metric("üîÑ Substitu√≠dos", f"{substituidos}")
            with col4:
                st.metric("üóëÔ∏è Removidos", f"{removidos}")
            
            # M√©tricas de combina√ß√µes
            if novas_combinacoes > 0 or combinacoes_existentes > 0:
                st.markdown("### üìà An√°lise de Combina√ß√µes (Respons√°vel + Data)")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üÜï Novas Combina√ß√µes", novas_combinacoes, 
                             help="Combina√ß√µes de Respons√°vel + Data que n√£o existiam antes")
                with col2:
                    st.metric("üîÑ Combina√ß√µes Atualizadas", combinacoes_existentes,
                             help="Combina√ß√µes que j√° existiam e foram substitu√≠das")
                with col3:
                    total_processadas = novas_combinacoes + combinacoes_existentes
                    st.metric("üìä Total Processado", total_processadas,
                             help="Total de combina√ß√µes √∫nicas processadas")
                
                if novas_combinacoes > 0:
                    st.success(f"üéâ **{novas_combinacoes} nova(s) combina√ß√£o(√µes) adicionada(s)** - Dados completamente novos!")
                if combinacoes_existentes > 0:
                    st.info(f"üîÑ **{combinacoes_existentes} combina√ß√£o(√µes) atualizada(s)** - Dados existentes foram substitu√≠dos pelos novos!")
            
            # Detalhes das opera√ß√µes
            if detalhes:
                with st.expander("üìã Detalhes das Opera√ß√µes", expanded=removidos > 0):
                    df_detalhes = pd.DataFrame(detalhes)
                    
                    operacoes_inseridas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'INSERIDO']
                    operacoes_substituidas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'SUBSTITU√çDO']
                    operacoes_removidas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'REMOVIDO']
                    
                    if not operacoes_inseridas.empty:
                        st.markdown("#### ‚ûï Registros Inseridos (Novos)")
                        st.dataframe(operacoes_inseridas, use_container_width=True, hide_index=True)
                    
                    if not operacoes_substituidas.empty:
                        st.markdown("#### üîÑ Registros Substitu√≠dos")
                        st.dataframe(operacoes_substituidas, use_container_width=True, hide_index=True)
                    
                    if not operacoes_removidas.empty:
                        st.markdown("#### üóëÔ∏è Registros Removidos")
                        st.dataframe(operacoes_removidas, use_container_width=True, hide_index=True)
            
            # Resumo por respons√°vel
            if not df_final.empty:
                resumo_responsaveis = df_final.groupby("RESPONS√ÅVEL").agg({
                    "DATA": ["count", "min", "max"]
                }).round(0)
                
                resumo_responsaveis.columns = ["Total Registros", "Data Inicial", "Data Final"]
                resumo_responsaveis["Data Inicial"] = pd.to_datetime(resumo_responsaveis["Data Inicial"]).dt.strftime("%d/%m/%Y")
                resumo_responsaveis["Data Final"] = pd.to_datetime(resumo_responsaveis["Data Final"]).dt.strftime("%d/%m/%Y")
                
                with st.expander("üë• Resumo por Respons√°vel"):
                    st.dataframe(resumo_responsaveis, use_container_width=True)
            
            return True
        else:
            st.error(f"‚ùå Erro no upload: Status {status}")
            if status != 500:
                st.code(resposta)
            return False
            
    except Exception as e:
        # EM CASO DE ERRO, SEMPRE REMOVER O LOCK
        logger.error(f"Erro na consolida√ß√£o: {e}")
        remover_lock(token, session_id, force=True)
        st.error(f"‚ùå Erro durante consolida√ß√£o: {str(e)}")
        st.info("üîì Sistema liberado automaticamente ap√≥s erro.")
        return False

# ===========================
# INTERFACE STREAMLIT
# ===========================
def exibir_info_versao():
    """Exibe informa√ß√µes de vers√£o e changelog"""
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è Informa√ß√µes do Sistema")
        st.info(f"**Vers√£o:** {APP_VERSION}")
        st.info(f"**Data:** {VERSION_DATE}")
        
        # Mostrar configura√ß√£o de pastas
        with st.expander("üìÅ Configura√ß√£o de Pastas"):
            st.markdown("**Arquivo Consolidado:**")
            st.code(PASTA_CONSOLIDADO, language=None)
            st.markdown("**Backups e Envios:**")
            st.code(PASTA_ENVIOS_BACKUPS, language=None)
        
        with st.expander("üìã Changelog"):
            for version, info in CHANGELOG.items():
                st.markdown(f"#### v{version} ({info['date']})")
                for change in info['changes']:
                    st.markdown(f"- {change}")
                st.markdown("---")

def main():
    st.set_page_config(
        page_title=f"DSView BI - Upload Planilhas v{APP_VERSION}", 
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Header com logo e vers√£o
    st.markdown(
        f'''
        <div style="display: flex; align-items: center; justify-content: space-between; margin-bottom: 20px;">
            <div style="display: flex; align-items: center; gap: 15px;">
                <h2 style="margin: 0; color: #2E8B57;">üìä DSView BI ‚Äì Upload de Planilhas</h2>
            </div>
            <div style="text-align: right; color: #666; font-size: 0.9em;">
                <strong>v{APP_VERSION}</strong><br>
                <small>{VERSION_DATE}</small>
            </div>
        </div>
        ''',
        unsafe_allow_html=True
    )

    # Sidebar navigation
    st.sidebar.markdown("### üì§ Upload de Planilhas")
    st.sidebar.markdown("Sistema de consolida√ß√£o de relat√≥rios")
    st.sidebar.divider()
    st.sidebar.markdown("**Status do Sistema:**")
    
    # Verificar autentica√ß√£o
    token = obter_token()
    if not token:
        st.sidebar.error("‚ùå Desconectado")
        st.error("‚ùå N√£o foi poss√≠vel autenticar. Verifique as credenciais.")
        st.stop()
    else:
        st.sidebar.success("‚úÖ Conectado")

    # ===========================
    # NOVO: VERIFICA√á√ÉO DE SISTEMA DE LOCK
    # ===========================
    st.markdown("## üîí Status do Sistema")
    
    # Verificar e exibir status do lock
    sistema_ocupado = exibir_status_sistema(token)
    
    # Auto-refresh a cada 15 segundos se sistema estiver ocupado
    if sistema_ocupado:
        st.markdown("---")
        st.info("üîÑ Esta p√°gina ser√° atualizada automaticamente a cada 15 segundos")
        time.sleep(15)
        st.rerun()

    st.divider()

    # Informa√ß√µes de vers√£o na sidebar
    exibir_info_versao()

    st.markdown("## üì§ Upload de Planilha Excel")
    
    # Mostrar aviso se sistema estiver ocupado
    if sistema_ocupado:
        st.warning("‚ö†Ô∏è **Upload desabilitado** - Sistema em uso por outro usu√°rio")
        st.info("üí° **Aguarde** a libera√ß√£o do sistema ou tente novamente em alguns minutos")
        
        # Bot√£o para atualizar status
        if st.button("üîÑ Verificar Status Novamente"):
            st.rerun()
        
        # N√£o mostrar o resto da interface se sistema estiver ocupado
        return
    
    # Sistema livre - mostrar interface normal
    st.info("üí° **Importante**: A planilha deve conter uma coluna 'RESPONS√ÅVEL' com os nomes dos respons√°veis!")
    
    # Nova estrutura de pastas
    with st.expander("üìÅ Nova Estrutura de Pastas - v2.2.0", expanded=False):
        st.markdown("### üéØ Organiza√ß√£o Melhorada dos Arquivos")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**üìä Arquivo Consolidado:**")
            st.code(f"{PASTA_CONSOLIDADO}/Reports_Geral_Consolidado.xlsx", language=None)
            st.caption("Arquivo principal com todos os dados consolidados")
            
        with col2:
            st.markdown("**üíæ Backups e Envios:**")
            st.code(f"{PASTA_ENVIOS_BACKUPS}/", language=None)
            st.caption("Pasta separada para arquivos enviados e backups")
        
        st.success("‚úÖ **Benef√≠cios:** Melhor organiza√ß√£o, backups separados e facilita a manuten√ß√£o")
    
    st.divider()

    # Upload de arquivo (s√≥ aparece se sistema estiver livre)
    uploaded_file = st.file_uploader(
        "Escolha um arquivo Excel", 
        type=["xlsx", "xls"],
        help="Formatos aceitos: .xlsx, .xls | Certifique-se de que h√° uma coluna 'RESPONS√ÅVEL' na planilha"
    )

    # Processar arquivo carregado
    df = None
    if uploaded_file:
        try:
            st.success(f"üìÅ Arquivo carregado: **{uploaded_file.name}**")
            
            # Detectar tipo de arquivo
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            with st.spinner("üìñ Lendo arquivo..."):
                if file_extension == 'xls':
                    xls = pd.ExcelFile(uploaded_file, engine='xlrd')
                else:
                    xls = pd.ExcelFile(uploaded_file)
                
                sheets = xls.sheet_names
                
                # Selecionar aba
                if len(sheets) > 1:
                    # Verificar se existe aba "Vendas CTs" 
                    if "Vendas CTs" in sheets:
                        sheet = "Vendas CTs"
                        st.success("‚úÖ Aba 'Vendas CTs' encontrada e selecionada automaticamente")
                    else:
                        sheet = st.selectbox(
                            "Selecione a aba (recomendado: 'Vendas CTs'):", 
                            sheets,
                            help="Para melhor compatibilidade, use uma aba chamada 'Vendas CTs'"
                        )
                        if sheet != "Vendas CTs":
                            st.warning("‚ö†Ô∏è Recomendamos que a aba seja chamada 'Vendas CTs'")
                else:
                    sheet = sheets[0]
                    if sheet != "Vendas CTs":
                        st.warning(f"‚ö†Ô∏è A aba atual se chama '{sheet}'. Recomendamos renome√°-la para 'Vendas CTs'")
                
                # Ler dados
                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                df.columns = df.columns.str.strip().str.upper()
                
            st.success(f"‚úÖ Dados carregados com sucesso!")
            
        except Exception as e:
            st.error(f"‚ùå Erro ao ler o Excel: {e}")
            logger.error(f"Erro ao ler Excel: {e}")

    # Mostrar pr√©via e valida√ß√µes
    if df is not None:
        # Pr√©via dos dados
        st.subheader("üëÄ Pr√©via dos dados")
        st.dataframe(df.head(10), use_container_width=True, height=300)

        # Resumo dos dados
        st.subheader("üìä Resumo dos dados")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Linhas", df.shape[0])
        with col2:
            st.metric("Colunas", df.shape[1])
        with col3:
            if "DATA" in df.columns:
                datas_validas = pd.to_datetime(df["DATA"], errors="coerce").notna().sum()
                st.metric("Datas v√°lidas", datas_validas)

        # Resumo de totais por produto
        st.subheader("üí∞ Resumo de Totais por Produto")
        
        # Lista das colunas de produtos corrigidas
        colunas_produtos = ['TMO - DUTO', 'TMO - FREIO', 'TMO - SANIT', 'TMO - VERNIZ', 'CX EVAP']
        
        # Encontrar colunas que existem no DataFrame
        colunas_encontradas = [col for col in colunas_produtos if col in df.columns]
        
        if colunas_encontradas:
            # Calcular totais
            totais = {}
            total_geral = 0
            
            for coluna in colunas_encontradas:
                # Converter para num√©rico, tratando erros como 0
                valores_numericos = pd.to_numeric(df[coluna], errors='coerce').fillna(0)
                total = int(valores_numericos.sum())  # Converter para inteiro
                totais[coluna] = total
                total_geral += total
            
            # Calcular TMO - Total se houver colunas TMO
            colunas_tmo = [col for col in colunas_encontradas if col.startswith('TMO -')]
            if colunas_tmo:
                tmo_total = sum(totais[col] for col in colunas_tmo)
                totais['TMO - TOTAL'] = tmo_total
            
            # Exibir m√©tricas em colunas
            produtos_para_exibir = [col for col in colunas_produtos if col in totais]
            if 'TMO - TOTAL' in totais:
                produtos_para_exibir.append('TMO - TOTAL')
            
            num_colunas = len(produtos_para_exibir)
            cols = st.columns(num_colunas)
            
            # Mostrar totais por produto
            for i, coluna in enumerate(produtos_para_exibir):
                with cols[i]:
                    total = totais[coluna]
                    # Formatar n√∫mero com separadores de milhares (formato inteiro)
                    total_formatado = f"{total:,}".replace(',', '.')
                    
                    # Definir emoji baseado no produto
                    if 'DUTO' in coluna:
                        emoji = "üîß"
                    elif 'FREIO' in coluna:
                        emoji = "üöó"
                    elif 'SANIT' in coluna:
                        emoji = "üßΩ"
                    elif 'VERNIZ' in coluna:
                        emoji = "üé®"
                    elif 'EVAP' in coluna:
                        emoji = "üì¶"
                    elif 'TOTAL' in coluna:
                        emoji = "üí∞"
                    else:
                        emoji = "üìä"
                    
                    # Nome simplificado para exibi√ß√£o
                    nome_display = coluna.replace('TMO - ', '').title()
                    
                    st.metric(f"{emoji} {nome_display}", total_formatado)
            
            # Tabela resumo adicional
            with st.expander("üìã Detalhes dos Totais"):
                resumo_data = []
                for coluna in produtos_para_exibir:
                    total = totais[coluna]
                    nome_produto = coluna.replace('TMO - ', '').title()
                    resumo_data.append({
                        'Produto': nome_produto,
                        'Total': f"{total:,}".replace(',', '.'),
                        'Registros': (pd.to_numeric(df[coluna], errors='coerce') > 0).sum() if coluna in df.columns else 0
                    })
                
                df_resumo = pd.DataFrame(resumo_data)
                st.dataframe(df_resumo, use_container_width=True, hide_index=True)
        else:
            st.warning("‚ö†Ô∏è Nenhuma coluna de produtos encontrada")
            
            # Mostrar colunas dispon√≠veis para ajudar o usu√°rio
            with st.expander("üîç Ver colunas dispon√≠veis"):
                colunas_disponiveis = [col for col in df.columns if col != 'DATA']
                st.write("**Colunas encontradas na planilha:**")
                for col in colunas_disponiveis:
                    st.write(f"‚Ä¢ {col}")
                st.info("üí° **Dica:** Renomeie as colunas na sua planilha para: TMO - Duto, TMO - Freio, TMO - Sanit, TMO - Verniz, CX EVAP")

        # Verificar colunas com valores nulos
        colunas_nulas = df.columns[df.isnull().any()].tolist()
        if colunas_nulas:
            st.warning(f"‚ö†Ô∏è Colunas com valores nulos: {', '.join(colunas_nulas[:5])}")
            if len(colunas_nulas) > 5:
                st.warning(f"... e mais {len(colunas_nulas) - 5} colunas")
        else:
            st.success("‚úÖ Nenhuma coluna com valores nulos.")

        # NOVA VALIDA√á√ÉO MELHORADA
        st.subheader("üîç Valida√ß√µes Detalhadas")
        erros, avisos, linhas_invalidas_detalhes = validar_dados_enviados(df)
        
        # Mostrar avisos
        for aviso in avisos:
            if aviso.startswith("‚úÖ"):
                st.success(aviso)
            else:
                st.warning(aviso)
        
        # Mostrar detalhes das linhas inv√°lidas
        if linhas_invalidas_detalhes:
            exibir_relatorio_problemas_datas(linhas_invalidas_detalhes)
        
        # Mostrar erros
        if erros:
            for erro in erros:
                st.error(erro)

        # Bot√£o de envio com verifica√ß√£o de lock
        col1, col2 = st.columns([1, 4])
        with col1:
            # Verificar novamente se sistema est√° livre antes de permitir envio
            sistema_ocupado_agora, _ = verificar_lock_existente(token)
            
            if sistema_ocupado_agora:
                st.error("üîí Sistema foi bloqueado por outro usu√°rio")
                if st.button("üîÑ Atualizar P√°gina"):
                    st.rerun()
            else:
                if st.button("üìß Consolidar Dados", type="primary", disabled=bool(erros)):
                    if erros:
                        st.error("‚ùå Corrija os erros acima antes de prosseguir")
                    else:
                        # Usar a nova fun√ß√£o com lock
                        sucesso = processar_consolidacao_com_lock(df, uploaded_file.name, token)
                        if sucesso:
                            st.balloons()
                            
        with col2:
            if st.button("üîÑ Limpar", type="secondary"):
                st.rerun()

    # Rodap√© com informa√ß√µes
    st.divider()
    st.markdown(
        f"""
        <div style="text-align: center; color: #666; font-size: 0.8em;">
            <strong>DSView BI - Sistema de Consolida√ß√£o de Relat√≥rios v{APP_VERSION}</strong><br>
            ‚ö†Ô∏è Certifique-se de que sua planilha contenha:<br>
            ‚Ä¢ Uma aba chamada <strong>'Vendas CTs'</strong><br>
            ‚Ä¢ Uma coluna <strong>'DATA'</strong><br>
            ‚Ä¢ Uma coluna <strong>'RESPONS√ÅVEL'</strong><br>
            ‚Ä¢ Colunas: <strong>TMO - Duto, TMO - Freio, TMO - Sanit, TMO - Verniz, CX EVAP</strong><br>
            <br>
            üìÅ <strong>v2.2.1:</strong> Sistema de lock implementado - apenas 1 usu√°rio por vez<br>
            <small>√öltima atualiza√ß√£o: {VERSION_DATE}</small>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()