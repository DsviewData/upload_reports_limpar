def comparar_e_atualizar_registros_v2(df_consolidado, df_novo):
    """
    Nova l√≥gica de consolida√ß√£o:
    - Para cada RESPONS√ÅVEL e DATA no arquivo novo
    - Remove TODOS os registros existentes com mesmo RESPONS√ÅVEL e DATA
    - Insere os novos registros
    """
    registros_inseridos = 0
    registros_substituidos = 0
    registros_removidos = 0
    detalhes_operacao = []
    
    if df_consolidado.empty:
        # Primeiro envio - todos os registros s√£o novos
        df_final = df_novo.copy()
        registros_inseridos = len(df_novo)
        
        for _, row in df_novo.iterrows():
            detalhes_operacao.append({
                "Opera√ß√£o": "INSERIDO",
                "Respons√°vel": row["RESPONS√ÅVEL"],
                "Data": row["DATA"].strftime("%d/%m/%Y"),
                "Motivo": "Primeiro envio"
            })
        
        return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao
    
    # Garantir que as colunas existem no consolidado
    colunas = df_novo.columns.tolist()
    for col in colunas:
        if col not in df_consolidado.columns:
            df_consolidado[col] = None
    
    # Criar c√≥pia para trabalhar
    df_final = df_consolidado.copy()
    
    # Agrupar registros novos por RESPONS√ÅVEL e DATA
    grupos_novos = df_novo.groupby(['RESPONS√ÅVEL', df_novo['DATA'].dt.date])
    
    for (responsavel, data_grupo), grupo_df in grupos_novos:
        if pd.isna(responsavel) or str(responsavel).strip() == '':
            continue
            
        # Buscar registros existentes para este respons√°vel e data
        mask_existente = (
            (df_final["DATA"].dt.date == data_grupo) &
            (df_final["RESPONS√ÅVEL"].str.strip().str.upper() == str(responsavel).strip().upper())
        )
        
        registros_existentes = df_final[mask_existente]
        
        if not registros_existentes.empty:
            # SUBSTITUI√á√ÉO: Remover registros existentes
            num_removidos = len(registros_existentes)
            df_final = df_final[~mask_existente]
            registros_removidos += num_removidos
            
            # Adicionar detalhes da remo√ß√£o
            detalhes_operacao.append({
                "Opera√ß√£o": "REMOVIDO",
                "Respons√°vel": responsavel,
                "Data": data_grupo.strftime("%d/%m/%Y"),
                "Motivo": f"{num_removidos} registro(s) antigo(s) removido(s)"
            })
            
            registros_substituidos += len(grupo_df)
            operacao_tipo = "SUBSTITU√çDO"
        else:
            # INSER√á√ÉO: N√£o havia registros anteriores
            registros_inseridos += len(grupo_df)
            operacao_tipo = "INSERIDO"
        
        # Inserir novos registros
        df_final = pd.concat([df_final, grupo_df], ignore_index=True)
        
        # Adicionar detalhes da opera√ß√£o
        detalhes_operacao.append({
            "Opera√ß√£o": operacao_tipo,
            "Respons√°vel": responsavel,
            "Data": data_grupo.strftime("%d/%m/%Y"),
            "Motivo": f"{len(grupo_df)} registro(s) processado(s)"
        })
    
    return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao


def processar_consolidacao_v2(df_novo, nome_arquivo, token):
    """
    Vers√£o melhorada do processamento de consolida√ß√£o
    """
    
    # 1. Baixar arquivo consolidado existente
    with st.spinner("üì• Baixando arquivo consolidado existente..."):
        df_consolidado, arquivo_existe = baixar_arquivo_consolidado(token)
    
    if arquivo_existe:
        st.info(f"üìÇ Arquivo consolidado carregado ({len(df_consolidado):,} registros)")
    else:
        st.info("üìÇ Criando novo arquivo consolidado")

    # 2. Preparar dados novos
    df_novo = df_novo.copy()
    df_novo.columns = df_novo.columns.str.strip().str.upper()
    
    # Converter datas e remover linhas inv√°lidas
    df_novo["DATA"] = pd.to_datetime(df_novo["DATA"], errors="coerce")
    linhas_invalidas = df_novo["DATA"].isna().sum()
    df_novo = df_novo.dropna(subset=["DATA"])

    if df_novo.empty:
        st.error("‚ùå Nenhum registro v√°lido para consolidar")
        return False

    if linhas_invalidas > 0:
        st.info(f"üßπ {linhas_invalidas} linhas com datas inv√°lidas foram removidas")

    # An√°lise pr√©via dos dados
    responsaveis_no_envio = df_novo["RESPONS√ÅVEL"].dropna().unique()
    periodo_min = df_novo["DATA"].min().strftime("%d/%m/%Y")
    periodo_max = df_novo["DATA"].max().strftime("%d/%m/%Y")
    
    st.info(f"üë• **Respons√°veis:** {', '.join(responsaveis_no_envio)}")
    st.info(f"üìÖ **Per√≠odo:** {periodo_min} at√© {periodo_max}")
    
    # Verificar se haver√° substitui√ß√µes
    if arquivo_existe and not df_consolidado.empty:
        df_consolidado["DATA"] = pd.to_datetime(df_consolidado["DATA"], errors="coerce")
        df_consolidado = df_consolidado.dropna(subset=["DATA"])
        
        # Verificar conflitos
        conflitos = []
        for responsavel in responsaveis_no_envio:
            datas_envio = df_novo[df_novo["RESPONS√ÅVEL"] == responsavel]["DATA"].dt.date.unique()
            
            for data in datas_envio:
                mask_conflito = (
                    (df_consolidado["DATA"].dt.date == data) &
                    (df_consolidado["RESPONS√ÅVEL"].str.strip().str.upper() == str(responsavel).strip().upper())
                )
                
                if mask_conflito.any():
                    num_existentes = mask_conflito.sum()
                    num_novos = len(df_novo[
                        (df_novo["RESPONS√ÅVEL"] == responsavel) & 
                        (df_novo["DATA"].dt.date == data)
                    ])
                    
                    conflitos.append({
                        "Respons√°vel": responsavel,
                        "Data": data.strftime("%d/%m/%Y"),
                        "Existentes": num_existentes,
                        "Novos": num_novos
                    })
        
        # Mostrar conflitos se existirem
        if conflitos:
            st.warning("‚ö†Ô∏è **ATEN√á√ÉO: Os seguintes dados ser√£o SUBSTITU√çDOS:**")
            
            df_conflitos = pd.DataFrame(conflitos)
            st.dataframe(df_conflitos, use_container_width=True, hide_index=True)
            
            total_substituicoes = sum(c["Existentes"] for c in conflitos)
            st.warning(f"üìù **{total_substituicoes} registro(s) existente(s) ser√£o removidos e substitu√≠dos**")
            
            # Op√ß√£o de confirma√ß√£o
            confirmacao = st.checkbox(
                "‚úÖ Confirmo que desejo substituir os dados existentes pelos novos dados",
                help="Esta a√ß√£o n√£o pode ser desfeita. Os dados antigos ser√£o movidos para backup."
            )
            
            if not confirmacao:
                st.info("‚è∏Ô∏è Marque a confirma√ß√£o acima para prosseguir com a consolida√ß√£o")
                return False

    # 3. Processar consolida√ß√£o com nova l√≥gica
    with st.spinner("üîÑ Processando consolida√ß√£o (nova l√≥gica)..."):
        df_final, inseridos, substituidos, removidos, detalhes = comparar_e_atualizar_registros_v2(
            df_consolidado, df_novo
        )

    # 4. Ordenar por data e respons√°vel
    df_final = df_final.sort_values(["DATA", "RESPONS√ÅVEL"], na_position='last').reset_index(drop=True)
    
    # 5. Criar backup dos dados removidos se houve substitui√ß√µes
    if removidos > 0:
        criar_backup_substituicoes(df_consolidado, detalhes, token)
    
    # 6. Salvar arquivo enviado com nome original
    salvar_arquivo_enviado(df_novo, nome_arquivo, token)
    
    # 7. Salvar arquivo consolidado
    with st.spinner("üì§ Salvando arquivo consolidado..."):
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df_final.to_excel(writer, index=False, sheet_name="Vendas CTs")
        buffer.seek(0)
        
        consolidado_nome = "Reports_Geral_Consolidado.xlsx"
        sucesso, status, resposta = upload_onedrive(consolidado_nome, buffer.read(), token)

    if sucesso:
        st.success("‚úÖ Consolida√ß√£o realizada com sucesso!")
        
        # M√©tricas de resultado melhoradas
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Total Final", f"{len(df_final):,}")
        with col2:
            st.metric("‚ûï Inseridos", inseridos)
        with col3:
            st.metric("üîÑ Substitu√≠dos", substituidos)
        with col4:
            st.metric("üóëÔ∏è Removidos", removidos)
        
        # Detalhes das opera√ß√µes
        if detalhes:
            with st.expander("üìã Detalhes das Opera√ß√µes", expanded=removidos > 0):
                df_detalhes = pd.DataFrame(detalhes)
                st.dataframe(df_detalhes, use_container_width=True, hide_index=True)
        
        # Resumo por respons√°vel
        resumo_responsaveis = df_final.groupby("RESPONS√ÅVEL").agg({
            "DATA": ["count", "min", "max"]
        }).round(0)
        
        resumo_responsaveis.columns = ["Total Registros", "Data Inicial", "Data Final"]
        resumo_responsaveis["Data Inicial"] = pd.to_datetime(resumo_responsaveis["Data Inicial"]).dt.strftime("%d/%m/%Y")
        resumo_responsaveis["Data Final"] = pd.to_datetime(resumo_responsaveis["Data Final"]).dt.strftime("%d/%m/%Y")
        
        with st.expander("üë• Resumo por Respons√°vel"):
            st.dataframe(resumo_responsaveis, use_container_width=True)
        
        return True
    else:
        st.error(f"‚ùå Erro no upload: Status {status}")
        if status != 500:
            st.code(resposta)
        return False


def criar_backup_substituicoes(df_consolidado, detalhes_operacao, token):
    """
    Cria backup dos registros que foram substitu√≠dos
    """
    try:
        # Extrair apenas opera√ß√µes de remo√ß√£o
        removidos = [d for d in detalhes_operacao if d["Opera√ß√£o"] == "REMOVIDO"]
        
        if not removidos:
            return
        
        # Identificar os registros que foram removidos
        registros_backup = []
        
        for item in removidos:
            responsavel = item["Respons√°vel"]
            data_str = item["Data"]
            data = pd.to_datetime(data_str, format="%d/%m/%Y").date()
            
            mask = (
                (df_consolidado["DATA"].dt.date == data) &
                (df_consolidado["RESPONS√ÅVEL"].str.strip().str.upper() == str(responsavel).strip().upper())
            )
            
            registros_removidos = df_consolidado[mask]
            if not registros_removidos.empty:
                registros_backup.append(registros_removidos)
        
        if registros_backup:
            df_backup = pd.concat(registros_backup, ignore_index=True)
            
            # Adicionar metadados de backup
            df_backup["BACKUP_TIMESTAMP"] = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
            df_backup["BACKUP_MOTIVO"] = "Substitui√ß√£o por novo envio"
            
            # Salvar backup
            timestamp = datetime.now().strftime('%d-%m-%Y_%Hh%M')
            nome_backup = f"Backups_Substituicoes/backup_substituicao_{timestamp}.xlsx"
            
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df_backup.to_excel(writer, index=False, sheet_name="Registros Substituidos")
            buffer.seek(0)
            
            sucesso, _, _ = upload_onedrive(nome_backup, buffer.read(), token)
            if sucesso:
                st.info(f"üíæ Backup dos dados substitu√≠dos criado: {nome_backup}")
            else:
                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel criar backup dos dados substitu√≠dos")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao criar backup: {e}")
        logger.error(f"Erro no backup: {e}")


# Fun√ß√£o para substituir a atual no main()
def main_melhorado():
    """
    Vers√£o do main() com a nova l√≥gica de consolida√ß√£o
    """
    # ... (manter todo o c√≥digo do main atual at√© a parte do bot√£o de consolida√ß√£o)
    
    # Substituir apenas esta parte:
    if st.button("üìß Consolidar Dados", type="primary", disabled=bool(erros)):
        if erros:
            st.error("‚ùå Corrija os erros acima antes de prosseguir")
        else:
            # USAR A NOVA FUN√á√ÉO:
            sucesso = processar_consolidacao_v2(df, uploaded_file.name, token)
            if sucesso:
                st.balloons()