import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta
from io import BytesIO
from msal import ConfidentialClientApplication
import unicodedata
import logging
import os
import json
import uuid
import time

# ===========================
# CONFIGURA√á√ïES DE VERS√ÉO - ATUALIZADO v2.4.0
# ===========================
APP_VERSION = "2.4.0"
VERSION_DATE = "2025-09-16"
CHANGELOG = {
    "2.4.0": {
        "date": "2025-09-16",
        "changes": [
            "üé® VISUAL MELHORADO: Interface moderna e responsiva",
            "üìÖ NOVO CAMPO: Data do √∫ltimo envio na planilha",
            "üéØ CSS organizado e componentes Streamlit otimizados",
            "üìä Dashboard visual aprimorado com m√©tricas",
            "üîß Melhor feedback visual durante processos",
            "üé® Tema consistente e cores padronizadas",
            "üì± Layout responsivo para diferentes telas",
            "‚ú® Anima√ß√µes e transi√ß√µes suaves"
        ]
    },
    "2.3.0": {
        "date": "2025-08-20",
        "changes": [
            "üéØ CORRE√á√ÉO CR√çTICA: L√≥gica de consolida√ß√£o por M√äS/ANO",
            "üîß Resolve problema de altera√ß√£o de datas criando duplicatas",
            "üìÖ Consolida√ß√£o agora agrupa por RESPONS√ÅVEL + PER√çODO MENSAL",
            "üõ°Ô∏è Verifica√ß√£o de seguran√ßa aprimorada para per√≠odos",
            "üìä An√°lise pr√©-consolida√ß√£o atualizada para m√™s/ano",
            "üîç Logs detalhados por per√≠odo mensal",
            "‚ö° Performance melhorada no agrupamento",
            "‚úÖ Elimina√ß√£o definitiva de inconsist√™ncias temporais"
        ]
    }
}

# ===========================
# ESTILOS CSS MELHORADOS
# ===========================
def aplicar_estilos_css():
    """Aplica estilos CSS customizados para melhorar a apar√™ncia"""
    st.markdown("""
    <style>
    /* Tema principal */
    :root {
        --primary-color: #2E8B57;
        --secondary-color: #20B2AA;
        --accent-color: #FFD700;
        --success-color: #32CD32;
        --warning-color: #FFA500;
        --error-color: #DC143C;
        --background-light: #F8F9FA;
        --text-dark: #2C3E50;
        --border-color: #E1E8ED;
    }
    
    /* Header principal */
    .main-header {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        color: white;
    }
    
    .main-header h1 {
        margin: 0;
        font-size: 2.5rem;
        font-weight: 700;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .version-badge {
        background: rgba(255,255,255,0.2);
        padding: 0.5rem 1rem;
        border-radius: 25px;
        font-size: 0.9rem;
        font-weight: 600;
        backdrop-filter: blur(10px);
    }
    
    /* Cards de status */
    .status-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.08);
        border-left: 4px solid var(--primary-color);
        margin: 1rem 0;
        transition: transform 0.2s ease;
    }
    
    .status-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 20px rgba(0,0,0,0.12);
    }
    
    .status-card.success {
        border-left-color: var(--success-color);
        background: linear-gradient(135deg, #f0fff4, #ffffff);
    }
    
    .status-card.warning {
        border-left-color: var(--warning-color);
        background: linear-gradient(135deg, #fffaf0, #ffffff);
    }
    
    .status-card.error {
        border-left-color: var(--error-color);
        background: linear-gradient(135deg, #fff0f0, #ffffff);
    }
    
    /* M√©tricas melhoradas */
    .metric-container {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        text-align: center;
        box-shadow: 0 2px 10px rgba(0,0,0,0.08);
        border-top: 3px solid var(--primary-color);
        transition: all 0.3s ease;
    }
    
    .metric-container:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 25px rgba(0,0,0,0.15);
    }
    
    .metric-value {
        font-size: 2.5rem;
        font-weight: 700;
        color: var(--primary-color);
        margin: 0.5rem 0;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: var(--text-dark);
        font-weight: 500;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    /* Bot√µes melhorados */
    .stButton > button {
        border-radius: 8px;
        font-weight: 600;
        transition: all 0.3s ease;
        border: none;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
    }
    
    /* Progress bar customizada */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, var(--primary-color), var(--secondary-color));
        border-radius: 10px;
    }
    
    /* Sidebar melhorada */
    .css-1d391kg {
        background: linear-gradient(180deg, var(--background-light), white);
    }
    
    /* Upload area melhorada */
    .uploadedFile {
        border: 2px dashed var(--primary-color);
        border-radius: 12px;
        padding: 2rem;
        text-align: center;
        background: var(--background-light);
        transition: all 0.3s ease;
    }
    
    .uploadedFile:hover {
        border-color: var(--secondary-color);
        background: white;
    }
    
    /* Tabelas melhoradas */
    .dataframe {
        border-radius: 8px;
        overflow: hidden;
        box-shadow: 0 2px 10px rgba(0,0,0,0.08);
    }
    
    /* Alertas customizados */
    .custom-alert {
        padding: 1rem 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        border-left: 4px solid;
        font-weight: 500;
    }
    
    .custom-alert.info {
        background: #e3f2fd;
        border-left-color: #2196f3;
        color: #0d47a1;
    }
    
    .custom-alert.success {
        background: #e8f5e8;
        border-left-color: #4caf50;
        color: #1b5e20;
    }
    
    .custom-alert.warning {
        background: #fff3e0;
        border-left-color: #ff9800;
        color: #e65100;
    }
    
    .custom-alert.error {
        background: #ffebee;
        border-left-color: #f44336;
        color: #b71c1c;
    }
    
    /* Footer melhorado */
    .footer {
        background: var(--background-light);
        padding: 2rem;
        border-radius: 12px;
        text-align: center;
        margin-top: 3rem;
        border-top: 3px solid var(--primary-color);
    }
    
    /* Anima√ß√µes */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .fade-in {
        animation: fadeIn 0.6s ease-out;
    }
    
    /* Responsividade */
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 2rem;
        }
        
        .metric-value {
            font-size: 2rem;
        }
        
        .status-card {
            padding: 1rem;
        }
    }
    </style>
    """, unsafe_allow_html=True)

# ===========================
# CONFIGURA√á√ÉO DE LOGGING
# ===========================
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===========================
# CREDENCIAIS VIA ST.SECRETS
# ===========================
try:
    CLIENT_ID = st.secrets["CLIENT_ID"]
    CLIENT_SECRET = st.secrets["CLIENT_SECRET"]
    TENANT_ID = st.secrets["TENANT_ID"]
    EMAIL_ONEDRIVE = st.secrets["EMAIL_ONEDRIVE"]
    SITE_ID = st.secrets["SITE_ID"]
    DRIVE_ID = st.secrets["DRIVE_ID"]
except KeyError as e:
    st.error(f"‚ùå Credencial n√£o encontrada: {e}")
    st.stop()

# ===========================
# CONFIGURA√á√ÉO DE PASTAS
# ===========================
PASTA_CONSOLIDADO = "Documentos Compartilhados/LimparAuto/FontedeDados"
PASTA_ENVIOS_BACKUPS = "Documentos Compartilhados/PlanilhasEnviadas_Backups/LimparAuto"
PASTA = PASTA_CONSOLIDADO

# ===========================
# CONFIGURA√á√ÉO DO SISTEMA DE LOCK
# ===========================
ARQUIVO_LOCK = "sistema_lock.json"
TIMEOUT_LOCK_MINUTOS = 10

# ===========================
# AUTENTICA√á√ÉO
# ===========================
@st.cache_data(ttl=3300)
def obter_token():
    """Obt√©m token de acesso para Microsoft Graph API"""
    try:
        app = ConfidentialClientApplication(
            CLIENT_ID,
            authority=f"https://login.microsoftonline.com/{TENANT_ID}",
            client_credential=CLIENT_SECRET
        )
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        
        if "access_token" not in result:
            error_desc = result.get("error_description", "Token n√£o obtido")
            st.error(f"‚ùå Falha na autentica√ß√£o: {error_desc}")
            return None
            
        return result["access_token"]
        
    except Exception as e:
        st.error(f"‚ùå Erro na autentica√ß√£o: {str(e)}")
        logger.error(f"Erro de autentica√ß√£o: {e}")
        return None

# ===========================
# SISTEMA DE LOCK
# ===========================
def gerar_id_sessao():
    """Gera um ID √∫nico para a sess√£o atual"""
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())[:8]
    return st.session_state.session_id

def verificar_lock_existente(token):
    """Verifica se existe um lock ativo no sistema"""
    try:
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            lock_data = response.json()
            timestamp_lock = datetime.fromisoformat(lock_data['timestamp'])
            agora = datetime.now()
            
            if agora - timestamp_lock > timedelta(minutes=TIMEOUT_LOCK_MINUTOS):
                logger.info(f"Lock expirado removido automaticamente. Era de {timestamp_lock}")
                remover_lock(token, force=True)
                return False, None
            
            return True, lock_data
        
        elif response.status_code == 404:
            return False, None
        else:
            logger.warning(f"Erro ao verificar lock: {response.status_code}")
            return False, None
            
    except Exception as e:
        logger.error(f"Erro ao verificar lock: {e}")
        return False, None

def criar_lock(token, operacao="Consolida√ß√£o de dados"):
    """Cria um lock para bloquear outras opera√ß√µes"""
    try:
        session_id = gerar_id_sessao()
        
        lock_data = {
            "timestamp": datetime.now().isoformat(),
            "session_id": session_id,
            "operacao": operacao,
            "status": "EM_ANDAMENTO",
            "app_version": APP_VERSION
        }
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.put(url, headers=headers, data=json.dumps(lock_data))
        
        if response.status_code in [200, 201]:
            logger.info(f"Lock criado com sucesso. Session ID: {session_id}")
            return True, session_id
        else:
            logger.error(f"Erro ao criar lock: {response.status_code}")
            return False, None
            
    except Exception as e:
        logger.error(f"Erro ao criar lock: {e}")
        return False, None

def remover_lock(token, session_id=None, force=False):
    """Remove o lock do sistema"""
    try:
        if not force and session_id:
            lock_existe, lock_data = verificar_lock_existente(token)
            if lock_existe and lock_data.get('session_id') != session_id:
                logger.warning("Tentativa de remover lock de outra sess√£o!")
                return False
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.delete(url, headers=headers)
        
        if response.status_code in [200, 204]:
            logger.info("Lock removido com sucesso")
            return True
        elif response.status_code == 404:
            return True
        else:
            logger.error(f"Erro ao remover lock: {response.status_code}")
            return False
            
    except Exception as e:
        logger.error(f"Erro ao remover lock: {e}")
        return False

def atualizar_status_lock(token, session_id, novo_status, detalhes=None):
    """Atualiza o status do lock durante o processo"""
    try:
        lock_existe, lock_data = verificar_lock_existente(token)
        
        if not lock_existe or lock_data.get('session_id') != session_id:
            logger.warning("Lock n√£o existe ou n√£o pertence a esta sess√£o")
            return False
        
        lock_data['status'] = novo_status
        lock_data['ultima_atualizacao'] = datetime.now().isoformat()
        
        if detalhes:
            lock_data['detalhes'] = detalhes
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.put(url, headers=headers, data=json.dumps(lock_data))
        return response.status_code in [200, 201]
        
    except Exception as e:
        logger.error(f"Erro ao atualizar status do lock: {e}")
        return False

def exibir_status_sistema(token):
    """Exibe o status atual do sistema de lock com visual melhorado"""
    lock_existe, lock_data = verificar_lock_existente(token)
    
    if lock_existe:
        timestamp_inicio = datetime.fromisoformat(lock_data['timestamp'])
        duracao = datetime.now() - timestamp_inicio
        
        # Card de status ocupado
        st.markdown("""
        <div class="status-card error">
            <h3>üîí Sistema Ocupado</h3>
            <p>Outro usu√°rio est√° enviando dados no momento</p>
        </div>
        """, unsafe_allow_html=True)
        
        # M√©tricas do processo
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{int(duracao.total_seconds()//60)}</div>
                <div class="metric-label">Minutos Ativo</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            tempo_limite = timestamp_inicio + timedelta(minutes=TIMEOUT_LOCK_MINUTOS)
            tempo_restante = tempo_limite - datetime.now()
            minutos_restantes = max(0, int(tempo_restante.total_seconds()//60))
            
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{minutos_restantes}</div>
                <div class="metric-label">Min. Restantes</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            status_display = lock_data.get('status', 'N/A')
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Status</div>
                <div style="font-size: 1.2rem; font-weight: 600; color: var(--warning-color);">{status_display}</div>
            </div>
            """, unsafe_allow_html=True)
        
        # Detalhes em expander
        with st.expander("‚ÑπÔ∏è Detalhes do processo em andamento"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.info(f"**Opera√ß√£o:** {lock_data.get('operacao', 'N/A')}")
                st.info(f"**In√≠cio:** {timestamp_inicio.strftime('%H:%M:%S')}")
                
            with col2:
                if 'detalhes' in lock_data:
                    st.info(f"**Detalhes:** {lock_data['detalhes']}")
                    
                session_id_display = lock_data.get('session_id', 'N/A')[:8]
                st.caption(f"Session ID: {session_id_display}")
        
        if tempo_restante.total_seconds() < 0:
            if st.button("üÜò Liberar Sistema (For√ßar)", type="secondary"):
                if remover_lock(token, force=True):
                    st.success("‚úÖ Sistema liberado com sucesso!")
                    st.rerun()
                else:
                    st.error("‚ùå Erro ao liberar sistema")
        
        return True
    else:
        st.markdown("""
        <div class="status-card success">
            <h3>‚úÖ Sistema Dispon√≠vel</h3>
            <p>Voc√™ pode enviar sua planilha agora</p>
        </div>
        """, unsafe_allow_html=True)
        return False

# ===========================
# FUN√á√ïES AUXILIARES
# ===========================
def criar_pasta_se_nao_existir(caminho_pasta, token):
    """Cria pasta no OneDrive se n√£o existir"""
    try:
        partes = caminho_pasta.split('/')
        caminho_atual = ""
        
        for parte in partes:
            if not parte:
                continue
                
            caminho_anterior = caminho_atual
            caminho_atual = f"{caminho_atual}/{parte}" if caminho_atual else parte
            
            url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{caminho_atual}"
            headers = {"Authorization": f"Bearer {token}"}
            response = requests.get(url, headers=headers)
            
            if response.status_code == 404:
                parent_url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root"
                if caminho_anterior:
                    parent_url += f":/{caminho_anterior}"
                parent_url += ":/children"
                
                create_body = {
                    "name": parte,
                    "folder": {},
                    "@microsoft.graph.conflictBehavior": "rename"
                }
                
                create_response = requests.post(
                    parent_url, 
                    headers={**headers, "Content-Type": "application/json"}, 
                    json=create_body
                )
                
                if create_response.status_code not in [200, 201]:
                    logger.warning(f"N√£o foi poss√≠vel criar pasta {parte}")
                    
    except Exception as e:
        logger.warning(f"Erro ao criar estrutura de pastas: {e}")

def upload_onedrive(nome_arquivo, conteudo_arquivo, token, tipo_arquivo="consolidado"):
    """Faz upload de arquivo para OneDrive"""
    try:
        if tipo_arquivo == "consolidado":
            pasta_base = PASTA_CONSOLIDADO
        elif tipo_arquivo in ["enviado", "backup"]:
            pasta_base = PASTA_ENVIOS_BACKUPS
        else:
            pasta_base = PASTA_CONSOLIDADO
        
        pasta_arquivo = "/".join(nome_arquivo.split("/")[:-1]) if "/" in nome_arquivo else ""
        if pasta_arquivo:
            criar_pasta_se_nao_existir(f"{pasta_base}/{pasta_arquivo}", token)
        
        if tipo_arquivo == "consolidado" and "/" not in nome_arquivo:
            mover_arquivo_existente(nome_arquivo, token, pasta_base)
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{pasta_base}/{nome_arquivo}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/octet-stream"
        }
        response = requests.put(url, headers=headers, data=conteudo_arquivo)
        
        return response.status_code in [200, 201], response.status_code, response.text
        
    except Exception as e:
        logger.error(f"Erro no upload: {e}")
        return False, 500, f"Erro interno: {str(e)}"

def mover_arquivo_existente(nome_arquivo, token, pasta_base=None):
    """Move arquivo existente para backup antes de substituir"""
    try:
        if pasta_base is None:
            pasta_base = PASTA_CONSOLIDADO
            
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{pasta_base}/{nome_arquivo}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            file_id = response.json().get("id")
            timestamp = datetime.now().strftime("%Y-%m-%d_%Hh%M")
            nome_base = nome_arquivo.replace(".xlsx", "")
            novo_nome = f"{nome_base}_backup_{timestamp}.xlsx"
            
            patch_url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/items/{file_id}"
            patch_body = {"name": novo_nome}
            patch_headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }
            patch_response = requests.patch(patch_url, headers=patch_headers, json=patch_body)
            
            if patch_response.status_code in [200, 201]:
                st.info(f"üíæ Backup criado: {novo_nome}")
            else:
                st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel criar backup do arquivo existente")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao processar backup: {str(e)}")
        logger.error(f"Erro no backup: {e}")

# ===========================
# VALIDA√á√ÉO DE DATAS
# ===========================
def validar_datas_detalhadamente(df):
    """Valida√ß√£o detalhada de datas"""
    problemas = []
    
    logger.info(f"üîç Iniciando valida√ß√£o detalhada de {len(df)} registros...")
    
    for idx, row in df.iterrows():
        linha_excel = idx + 2
        valor_original = row["DATA"]
        responsavel = row.get("RESPONS√ÅVEL", "N/A")
        
        problema_encontrado = None
        tipo_problema = None
        
        if pd.isna(valor_original) or str(valor_original).strip() == "":
            problema_encontrado = "Data vazia ou nula"
            tipo_problema = "VAZIO"
        else:
            try:
                data_convertida = pd.to_datetime(valor_original, errors='raise')
                hoje = datetime.now()
                
                if data_convertida > hoje + pd.Timedelta(days=730):
                    problema_encontrado = f"Data muito distante no futuro: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "FUTURO"
                elif data_convertida < pd.Timestamp('2020-01-01'):
                    problema_encontrado = f"Data muito antiga: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "ANTIGA"
                elif data_convertida > hoje:
                    problema_encontrado = f"Data no futuro: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "FUTURO"
                    
            except (ValueError, TypeError, pd.errors.OutOfBoundsDatetime) as e:
                if "day is out of range for month" in str(e) or "month must be in 1..12" in str(e):
                    problema_encontrado = f"Data imposs√≠vel: {valor_original}"
                    tipo_problema = "IMPOSS√çVEL"
                else:
                    problema_encontrado = f"Formato inv√°lido: {valor_original}"
                    tipo_problema = "FORMATO"
        
        if problema_encontrado:
            problemas.append({
                "Linha Excel": linha_excel,
                "Respons√°vel": responsavel,
                "Valor Original": valor_original,
                "Problema": problema_encontrado,
                "Tipo Problema": tipo_problema
            })
            
            logger.warning(f"‚ùå Linha {linha_excel}: {problema_encontrado} (Respons√°vel: {responsavel})")
    
    if problemas:
        logger.error(f"‚ùå TOTAL DE PROBLEMAS ENCONTRADOS: {len(problemas)}")
        
        tipos_problema = {}
        for problema in problemas:
            tipo = problema["Tipo Problema"]
            tipos_problema[tipo] = tipos_problema.get(tipo, 0) + 1
        
        logger.error(f"üìä Problemas por tipo: {tipos_problema}")
    else:
        logger.info("‚úÖ Todas as datas est√£o v√°lidas!")
    
    return problemas

def exibir_problemas_datas(problemas_datas):
    """Exibe problemas de datas com visual melhorado"""
    if not problemas_datas:
        return
    
    st.markdown("""
    <div class="custom-alert error">
        <h4>‚ùå Problemas de Data Encontrados</h4>
        <p>√â obrigat√≥rio corrigir TODOS os problemas antes de enviar</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Estat√≠sticas dos problemas
    tipos_problema = {}
    for problema in problemas_datas:
        tipo = problema["Tipo Problema"]
        tipos_problema[tipo] = tipos_problema.get(tipo, 0) + 1
    
    # Exibir m√©tricas dos problemas
    cols = st.columns(len(tipos_problema))
    emoji_map = {
        "VAZIO": "üî¥",
        "FORMATO": "üü†", 
        "IMPOSS√çVEL": "üü£",
        "FUTURO": "üü°",
        "ANTIGA": "üü§"
    }
    
    for i, (tipo, qtd) in enumerate(tipos_problema.items()):
        with cols[i]:
            emoji = emoji_map.get(tipo, "‚ùå")
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{qtd}</div>
                <div class="metric-label">{emoji} {tipo}</div>
            </div>
            """, unsafe_allow_html=True)
    
    # Tabela de problemas
    df_problemas = pd.DataFrame(problemas_datas)
    max_linhas_exibir = 50
    
    if len(df_problemas) > max_linhas_exibir:
        df_problemas_exibir = df_problemas.head(max_linhas_exibir)
        st.warning(f"‚ö†Ô∏è **Exibindo apenas as primeiras {max_linhas_exibir} linhas.** Total de problemas: {len(df_problemas)}")
    else:
        df_problemas_exibir = df_problemas
    
    st.dataframe(
        df_problemas_exibir,
        use_container_width=True,
        hide_index=True,
        height=400
    )

def normalizar_texto(texto):
    """Normaliza strings: remove espa√ßos extras, converte para mai√∫sculas e remove acentos."""
    if pd.isna(texto) or not isinstance(texto, str):
        return texto
    texto = texto.strip().upper()
    texto = ''.join(c for c in texto if c.isalnum() or c.isspace())
    return unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')

def validar_dados_enviados(df):
    """Valida√ß√£o super rigorosa dos dados enviados"""
    erros = []
    avisos = []
    linhas_invalidas_detalhes = []
    
    if df.empty:
        erros.append("‚ùå A planilha est√° vazia")
        return erros, avisos, linhas_invalidas_detalhes
    
    # Valida√ß√£o de campos espec√≠ficos
    campos_para_validar = ["GRUPO", "CONCESSION√ÅRIA", "LOJA", "MARCA", "UF", "RESPONS√ÅVEL", "CONSULTORES"]
    
    for campo in campos_para_validar:
        if campo not in df.columns:
            erros.append(f"‚ö†Ô∏è A planilha deve conter uma coluna \'{campo}\'")
            avisos.append(f"üìã Certifique-se de que sua planilha tenha uma coluna chamada \'{campo}\'")
            continue
        
        # Normalizar a coluna para facilitar a compara√ß√£o e evitar inconsist√™ncias
        df[f"_{campo}_NORMALIZADO"] = df[campo].apply(normalizar_texto)
        
        # Verificar valores vazios ap√≥s normaliza√ß√£o
        if df[f"_{campo}_NORMALIZADO"].isnull().any():
            erros.append(f"‚ùå Coluna \'{campo}\' cont√©m valores vazios ou inv√°lidos ap√≥s normaliza√ß√£o.")
            
        # Verificar inconsist√™ncias de capitaliza√ß√£o/espa√ßos
        valores_originais = df[campo].dropna().unique()
        valores_normalizados = df[f"_{campo}_NORMALIZADO"].dropna().unique()
        
        if len(valores_originais) != len(valores_normalizados):
            # Isso indica que h√° valores que s√£o diferentes na forma original, mas iguais ap√≥s normaliza√ß√£o
            # Ex: 'Nome' e 'nome', ou 'Nome ' e 'Nome'
            inconsistencias_encontradas = []
            for val_norm in valores_normalizados:
                originais_para_norm = [v for v in valores_originais if normalizar_texto(v) == val_norm]
                if len(originais_para_norm) > 1:
                    inconsistencias_encontradas.append(f"'{val_norm}' (originalmente: {', '.join(originais_para_norm)})")
            
            if inconsistencias_encontradas:
                erros.append(f"‚ùå Inconsist√™ncias de capitaliza√ß√£o/espa√ßos na coluna \'{campo}\': {'; '.join(inconsistencias_encontradas)}")
                avisos.append(f"üí° Considere padronizar os valores na coluna \'{campo}\' para evitar problemas.")

    if "RESPONS√ÅVEL" not in df.columns:
        erros.append("‚ö†Ô∏è A planilha deve conter uma coluna 'RESPONS√ÅVEL'")
        avisos.append("üìã Certifique-se de que sua planilha tenha uma coluna chamada 'RESPONS√ÅVEL'")
    else:
        responsaveis_validos = df["RESPONS√ÅVEL"].notna().sum()
        if responsaveis_validos == 0:
            erros.append("‚ùå Nenhum respons√°vel v√°lido encontrado na coluna 'RESPONS√ÅVEL'")
        else:
            responsaveis_unicos = df["RESPONS√ÅVEL"].dropna().unique()
            if len(responsaveis_unicos) > 0:
                avisos.append(f"üë• Respons√°veis encontrados: {', '.join(responsaveis_unicos[:5])}")
                if len(responsaveis_unicos) > 5:
                    avisos.append(f"... e mais {len(responsaveis_unicos) - 5} respons√°veis")
    
    if "DATA" not in df.columns:
        erros.append("‚ö†Ô∏è A planilha deve conter uma coluna 'DATA'")
        avisos.append("üìã Lembre-se: o arquivo deve ter uma aba chamada 'Vendas CTs' com as colunas 'DATA' e 'RESPONS√ÅVEL'")
    else:
        problemas_datas = validar_datas_detalhadamente(df)
        
        if problemas_datas:
            erros.append(f"‚ùå {len(problemas_datas)} problemas de data encontrados - CONSOLIDA√á√ÉO BLOQUEADA")
            erros.append("üîß √â OBRIGAT√ìRIO corrigir TODOS os problemas antes de enviar")
            erros.append("üìã Revise sua planilha e corrija todas as datas inv√°lidas")
            
            linhas_invalidas_detalhes = problemas_datas
            
        else:
            avisos.append("‚úÖ Todas as datas est√£o v√°lidas e consistentes!")
    
    if not df.empty and "DATA" in df.columns:
        df_temp = df.copy()
        df_temp["DATA"] = pd.to_datetime(df_temp["DATA"], errors="coerce")
        df_temp = df_temp.dropna(subset=["DATA"])
        
        if not df_temp.empty:
            duplicatas = df_temp.duplicated(subset=["DATA"], keep=False).sum()
            if duplicatas > 0:
                avisos.append(f"‚ö†Ô∏è {duplicatas} linhas com datas duplicadas na planilha")
    
    return erros, avisos, linhas_invalidas_detalhes

# ===========================
# FUN√á√ïES DE CONSOLIDA√á√ÉO MELHORADAS v2.4.0
# ===========================
def baixar_arquivo_consolidado(token):
    """Baixa o arquivo consolidado existente"""
    consolidado_nome = "Reports_Geral_Consolidado.xlsx"
    url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{consolidado_nome}:/content"
    headers = {"Authorization": f"Bearer {token}"}
    
    try:
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            df_consolidado = pd.read_excel(BytesIO(response.content))
            df_consolidado.columns = df_consolidado.columns.str.strip().str.upper()
            
            logger.info(f"‚úÖ Arquivo consolidado baixado: {len(df_consolidado)} registros")
            if not df_consolidado.empty:
                responsaveis_existentes = df_consolidado['RESPONS√ÅVEL'].dropna().unique()
                logger.info(f"üìä Respons√°veis no consolidado: {responsaveis_existentes}")
            
            return df_consolidado, True
        else:
            logger.info("üìÑ Arquivo consolidado n√£o existe - ser√° criado novo")
            return pd.DataFrame(), False
            
    except Exception as e:
        logger.error(f"Erro ao baixar arquivo consolidado: {e}")
        return pd.DataFrame(), False

def adicionar_data_ultimo_envio(df_final, responsaveis_atualizados):
    """Adiciona/atualiza a coluna DATA_ULTIMO_ENVIO para os respons√°veis que foram atualizados"""
    try:
        # Garantir que a coluna existe
        if 'DATA_ULTIMO_ENVIO' not in df_final.columns:
            df_final['DATA_ULTIMO_ENVIO'] = pd.NaT
            logger.info("‚ûï Coluna 'DATA_ULTIMO_ENVIO' criada")
        
        # Atualizar apenas os respons√°veis que foram modificados neste envio
        data_atual = datetime.now()
        
        for responsavel in responsaveis_atualizados:
            mask = df_final['RESPONS√ÅVEL'].astype(str).str.strip().str.upper() == str(responsavel).strip().upper()
            df_final.loc[mask, 'DATA_ULTIMO_ENVIO'] = data_atual
            
            registros_atualizados = mask.sum()
            logger.info(f"üìÖ Data do √∫ltimo envio atualizada para '{responsavel}': {registros_atualizados} registros")
        
        return df_final
        
    except Exception as e:
        logger.error(f"Erro ao adicionar data do √∫ltimo envio: {e}")
        return df_final

def verificar_seguranca_consolidacao_v2(df_consolidado, df_novo, df_final):
    """Verifica√ß√£o de seguran√ßa cr√≠tica - vers√£o corrigida para m√™s/ano"""
    try:
        responsaveis_antes = set(df_consolidado['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique()) if not df_consolidado.empty else set()
        responsaveis_novos = set(df_novo['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique())
        responsaveis_depois = set(df_final['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique())
        
        logger.info(f"üõ°Ô∏è VERIFICA√á√ÉO DE SEGURAN√áA v2.4.0:")
        logger.info(f"   Respons√°veis ANTES: {responsaveis_antes}")
        logger.info(f"   Respons√°veis NOVOS: {responsaveis_novos}")
        logger.info(f"   Respons√°veis DEPOIS: {responsaveis_depois}")
        
        # Verificar se algum respons√°vel foi perdido completamente
        responsaveis_esperados = responsaveis_antes.union(responsaveis_novos)
        responsaveis_perdidos = responsaveis_esperados - responsaveis_depois
        
        if responsaveis_perdidos:
            error_msg = f"Respons√°veis perdidos durante consolida√ß√£o: {', '.join(responsaveis_perdidos)}"
            logger.error(f"‚ùå ERRO CR√çTICO: {error_msg}")
            return False, error_msg
        
        # Verifica√ß√£o adicional: respons√°veis que n√£o est√£o sendo atualizados n√£o devem desaparecer
        for resp in responsaveis_antes:
            if resp not in responsaveis_novos:
                if resp not in responsaveis_depois:
                    error_msg = f"Respons√°vel '{resp}' foi removido sem justificativa"
                    logger.error(f"‚ùå ERRO: {error_msg}")
                    return False, error_msg
        
        logger.info(f"‚úÖ VERIFICA√á√ÉO DE SEGURAN√áA PASSOU!")
        logger.info(f"   Total antes: {len(responsaveis_antes)} respons√°veis")
        logger.info(f"   Total novos: {len(responsaveis_novos)} respons√°veis") 
        logger.info(f"   Total depois: {len(responsaveis_depois)} respons√°veis")
        
        return True, f"Verifica√ß√£o passou: {len(responsaveis_depois)} respons√°veis mantidos"
        
    except Exception as e:
        error_msg = f"Erro durante verifica√ß√£o de seguran√ßa: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        return False, error_msg

def comparar_e_atualizar_registros_v2(df_consolidado, df_novo):
    """
    L√≥gica de consolida√ß√£o corrigida - v2.4.0
    Consolida por RESPONS√ÅVEL + M√äS/ANO para evitar problemas com altera√ß√µes de data
    """
    registros_inseridos = 0
    registros_substituidos = 0
    registros_removidos = 0
    detalhes_operacao = []
    combinacoes_novas = 0
    combinacoes_existentes = 0
    responsaveis_atualizados = set()
    
    logger.info(f"üîß INICIANDO CONSOLIDA√á√ÉO v2.4.0:")
    logger.info(f"   Consolidado atual: {len(df_consolidado)} registros")
    logger.info(f"   Novo arquivo: {len(df_novo)} registros")
    
    if df_consolidado.empty:
        df_final = df_novo.copy()
        registros_inseridos = len(df_novo)
        
        # Adicionar todos os respons√°veis como atualizados
        responsaveis_atualizados = set(df_novo['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique())
        
        # Criar combina√ß√µes √∫nicas por m√™s/ano
        df_temp = df_novo.copy()
        df_temp['mes_ano'] = df_temp['DATA'].dt.to_period('M')
        combinacoes_unicas = df_temp.groupby(['RESPONS√ÅVEL', 'mes_ano']).size()
        combinacoes_novas = len(combinacoes_unicas)
        
        logger.info(f"‚úÖ PRIMEIRA CONSOLIDA√á√ÉO: {registros_inseridos} registros inseridos")
        
        for _, row in df_novo.iterrows():
            detalhes_operacao.append({
                "Opera√ß√£o": "INSERIDO",
                "Respons√°vel": row["RESPONS√ÅVEL"],
                "M√™s/Ano": row["DATA"].strftime("%m/%Y"),
                "Data": row["DATA"].strftime("%d/%m/%Y"),
                "Motivo": "Primeira consolida√ß√£o - arquivo vazio"
            })
        
        # Adicionar data do √∫ltimo envio
        df_final = adicionar_data_ultimo_envio(df_final, responsaveis_atualizados)
        
        return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao, combinacoes_novas, combinacoes_existentes
    
    # Garantir que as colunas existem no consolidado
    colunas = df_novo.columns.tolist()
    for col in colunas:
        if col not in df_consolidado.columns:
            df_consolidado[col] = None
            logger.info(f"‚ûï Coluna '{col}' adicionada ao consolidado")
    
    # Come√ßar com uma C√ìPIA COMPLETA do consolidado
    df_final = df_consolidado.copy()
    registros_inicial = len(df_final)
    
    # Adicionar colunas auxiliares para agrupamento por m√™s/ano
    df_novo_temp = df_novo.copy()
    df_novo_temp['mes_ano'] = df_novo_temp['DATA'].dt.to_period('M')
    
    df_final_temp = df_final.copy()
    df_final_temp['mes_ano'] = df_final_temp['DATA'].dt.to_period('M')
    
    logger.info(f"üìã Estado inicial do consolidado:")
    if not df_final.empty:
        responsaveis_iniciais = df_final['RESPONS√ÅVEL'].dropna().unique()
        logger.info(f"   Respons√°veis: {responsaveis_iniciais}")
        logger.info(f"   Total de registros: {len(df_final)}")
    
    # Agrupar registros novos por RESPONS√ÅVEL e M√äS/ANO
    grupos_novos = df_novo_temp.groupby(['RESPONS√ÅVEL', 'mes_ano'])
    
    logger.info(f"üìä Processando {len(grupos_novos)} combina√ß√µes √∫nicas de Respons√°vel+M√™s/Ano")
    
    for (responsavel, periodo_grupo), grupo_df in grupos_novos:
        if pd.isna(responsavel) or str(responsavel).strip() == '':
            logger.warning(f"‚ö†Ô∏è Pulando respons√°vel inv√°lido: {responsavel}")
            continue
        
        # Adicionar respons√°vel √† lista de atualizados
        responsaveis_atualizados.add(str(responsavel).strip().upper())
        
        logger.info(f"üîç Processando: '{responsavel}' em {periodo_grupo} ({len(grupo_df)} registros)")
        
        # Buscar registros existentes APENAS para este respons√°vel e per√≠odo ESPEC√çFICOS
        mask_existente = (
            (df_final_temp["mes_ano"] == periodo_grupo) &
            (df_final_temp["RESPONS√ÅVEL"].astype(str).str.strip().str.upper() == str(responsavel).strip().upper())
        )
        
        registros_existentes = df_final[mask_existente]
        total_antes_operacao = len(df_final)
        
        logger.info(f"   üìã Encontrados {len(registros_existentes)} registros existentes para esta combina√ß√£o")
        
        if not registros_existentes.empty:
            # SUBSTITUI√á√ÉO APENAS DA COMBINA√á√ÉO ESPEC√çFICA (RESPONS√ÅVEL + M√äS/ANO)
            num_removidos = len(registros_existentes)
            
            logger.info(f"   üîÑ SUBSTITUI√á√ÉO: Removendo {num_removidos} registros antigos do per√≠odo {periodo_grupo}")
            
            # Remove APENAS os registros dessa combina√ß√£o espec√≠fica
            df_final = df_final[~mask_existente]
            
            # Atualizar df_final_temp tamb√©m
            df_final_temp = df_final_temp[~mask_existente]
            
            total_depois_remocao = len(df_final)
            registros_removidos += num_removidos
            combinacoes_existentes += 1
            
            logger.info(f"   ‚úÖ Removidos {num_removidos} registros. Total: {total_antes_operacao} -> {total_depois_remocao}")
            
            # Verifica√ß√£o de seguran√ßa na remo√ß√£o
            if total_depois_remocao != (total_antes_operacao - num_removidos):
                logger.error(f"‚ùå ERRO NA REMO√á√ÉO! Esperado: {total_antes_operacao - num_removidos}, Atual: {total_depois_remocao}")
            
            # Adicionar detalhes da remo√ß√£o
            detalhes_operacao.append({
                "Opera√ß√£o": "REMOVIDO",
                "Respons√°vel": responsavel,
                "M√™s/Ano": periodo_grupo.strftime("%m/%Y"),
                "Data": f"Todo o per√≠odo {periodo_grupo}",
                "Motivo": f"Substitui√ß√£o: {num_removidos} registro(s) antigo(s) removido(s)"
            })
            
            registros_substituidos += len(grupo_df)
            operacao_tipo = "SUBSTITU√çDO"
            motivo = f"Substitui√ß√£o completa do per√≠odo: {len(grupo_df)} novo(s) registro(s)"
            
        else:
            # INSER√á√ÉO DE NOVOS DADOS
            logger.info(f"   ‚ûï NOVA COMBINA√á√ÉO: Adicionando {len(grupo_df)} registros para {periodo_grupo}")
            registros_inseridos += len(grupo_df)
            combinacoes_novas += 1
            operacao_tipo = "INSERIDO"
            motivo = f"Nova combina√ß√£o: {len(grupo_df)} registro(s) inserido(s)"
        
        # Inserir novos registros (tanto para inser√ß√£o quanto substitui√ß√£o)
        total_antes_insercao = len(df_final)
        
        # Remover coluna auxiliar antes de concatenar
        grupo_para_inserir = grupo_df.drop(columns=['mes_ano'], errors='ignore')
        df_final = pd.concat([df_final, grupo_para_inserir], ignore_index=True)
        
        # Atualizar df_final_temp tamb√©m
        df_final_temp = pd.concat([df_final_temp, grupo_df], ignore_index=True)
        
        total_depois_insercao = len(df_final)
        
        logger.info(f"   ‚úÖ Inseridos {len(grupo_df)} registros. Total: {total_antes_insercao} -> {total_depois_insercao}")
        
        # Adicionar detalhes da opera√ß√£o
        detalhes_operacao.append({
            "Opera√ß√£o": operacao_tipo,
            "Respons√°vel": responsavel,
            "M√™s/Ano": periodo_grupo.strftime("%m/%Y"),
            "Data": f"Per√≠odo {periodo_grupo}",
            "Motivo": motivo
        })
    
    # Adicionar data do √∫ltimo envio para os respons√°veis atualizados
    df_final = adicionar_data_ultimo_envio(df_final, responsaveis_atualizados)
    
    logger.info(f"üéØ CONSOLIDA√á√ÉO FINALIZADA:")
    logger.info(f"   Registros inseridos: {registros_inseridos}")
    logger.info(f"   Registros substitu√≠dos: {registros_substituidos}")
    logger.info(f"   Registros removidos: {registros_removidos}")
    logger.info(f"   Novas combina√ß√µes: {combinacoes_novas}")
    logger.info(f"   Combina√ß√µes existentes: {combinacoes_existentes}")
    logger.info(f"   Respons√°veis atualizados: {responsaveis_atualizados}")
    logger.info(f"   Total final: {len(df_final)} registros")
    
    return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao, combinacoes_novas, combinacoes_existentes

def salvar_arquivo_enviado(df_novo, nome_arquivo_original, token):
    """Salva uma c√≥pia do arquivo enviado na pasta de backups"""
    try:
        timestamp = datetime.now().strftime("%Y-%m-%d_%Hh%M")
        nome_base = nome_arquivo_original.replace(".xlsx", "").replace(".xls", "")
        nome_arquivo_backup = f"{nome_base}_enviado_{timestamp}.xlsx"
        
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df_novo.to_excel(writer, index=False, sheet_name="Vendas CTs")
        buffer.seek(0)
        
        sucesso, status_code, resposta = upload_onedrive(nome_arquivo_backup, buffer.read(), token, "backup")
        
        if sucesso:
            logger.info(f"üíæ Arquivo enviado salvo como backup: {nome_arquivo_backup}")
        else:
            logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel salvar backup do arquivo enviado: {status_code}")
            
    except Exception as e:
        logger.error(f"Erro ao salvar arquivo enviado: {e}")

def analise_pre_consolidacao_v2(df_consolidado, df_novo):
    """An√°lise pr√©-consolida√ß√£o com visual melhorado"""
    try:
        st.markdown("### üìä An√°lise Pr√©-Consolida√ß√£o")
        
        # Preparar dados para an√°lise
        df_novo_temp = df_novo.copy()
        df_novo_temp['mes_ano'] = df_novo_temp['DATA'].dt.to_period('M')
        
        responsaveis_novos = set(df_novo['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique())
        
        if not df_consolidado.empty:
            df_consolidado_temp = df_consolidado.copy()
            df_consolidado_temp['mes_ano'] = df_consolidado_temp['DATA'].dt.to_period('M')
            responsaveis_existentes = set(df_consolidado['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique())
        else:
            responsaveis_existentes = set()
        
        # An√°lise de combina√ß√µes
        combinacoes_novas = []
        combinacoes_existentes = []
        
        grupos_novos = df_novo_temp.groupby(['RESPONS√ÅVEL', 'mes_ano'])
        
        for (responsavel, periodo), grupo in grupos_novos:
            if pd.isna(responsavel):
                continue
                
            responsavel_upper = str(responsavel).strip().upper()
            
            if not df_consolidado.empty:
                mask_existente = (
                    (df_consolidado_temp["mes_ano"] == periodo) &
                    (df_consolidado_temp["RESPONS√ÅVEL"].astype(str).str.strip().str.upper() == responsavel_upper)
                )
                
                if mask_existente.any():
                    combinacoes_existentes.append({
                        "Respons√°vel": responsavel,
                        "Per√≠odo": periodo.strftime("%m/%Y"),
                        "Novos Registros": len(grupo),
                        "Registros Existentes": mask_existente.sum()
                    })
                else:
                    combinacoes_novas.append({
                        "Respons√°vel": responsavel,
                        "Per√≠odo": periodo.strftime("%m/%Y"),
                        "Registros": len(grupo)
                    })
            else:
                combinacoes_novas.append({
                    "Respons√°vel": responsavel,
                    "Per√≠odo": periodo.strftime("%m/%Y"),
                    "Registros": len(grupo)
                })
        
        # Exibir m√©tricas
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{len(responsaveis_novos)}</div>
                <div class="metric-label">Respons√°veis</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{len(df_novo)}</div>
                <div class="metric-label">Registros Novos</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{len(combinacoes_novas)}</div>
                <div class="metric-label">Novos Per√≠odos</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{len(combinacoes_existentes)}</div>
                <div class="metric-label">Per√≠odos Atualizados</div>
            </div>
            """, unsafe_allow_html=True)
        
        # Detalhes das opera√ß√µes
        if combinacoes_novas:
            with st.expander("‚ûï Novos Per√≠odos que ser√£o Adicionados"):
                df_novas = pd.DataFrame(combinacoes_novas)
                st.dataframe(df_novas, use_container_width=True, hide_index=True)
        
        if combinacoes_existentes:
            with st.expander("üîÑ Per√≠odos que ser√£o Substitu√≠dos"):
                df_existentes = pd.DataFrame(combinacoes_existentes)
                st.dataframe(df_existentes, use_container_width=True, hide_index=True)
        
        return True
        
    except Exception as e:
        logger.error(f"Erro na an√°lise pr√©-consolida√ß√£o: {e}")
        st.error(f"‚ùå Erro na an√°lise: {str(e)}")
        return False

def processar_consolidacao_com_lock(df_novo, nome_arquivo, token):
    """Consolida√ß√£o com sistema de lock e feedback melhorado - v2.4.0"""
    session_id = gerar_id_sessao()
    
    status_container = st.empty()
    progress_container = st.empty()
    
    try:
        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üìÑ Iniciando processo de consolida√ß√£o v2.4.0...</h4>
        </div>
        """, unsafe_allow_html=True)
        
        sistema_ocupado, lock_data = verificar_lock_existente(token)
        if sistema_ocupado:
            status_container.markdown("""
            <div class="custom-alert error">
                <h4>üîí Sistema ocupado! Outro usu√°rio est√° fazendo consolida√ß√£o.</h4>
            </div>
            """, unsafe_allow_html=True)
            return False
        
        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üîí Bloqueando sistema para consolida√ß√£o...</h4>
        </div>
        """, unsafe_allow_html=True)
        progress_container.progress(10)
        
        lock_criado, session_lock = criar_lock(token, "Consolida√ß√£o de planilha v2.4.0")
        
        if not lock_criado:
            status_container.markdown("""
            <div class="custom-alert error">
                <h4>‚ùå N√£o foi poss√≠vel bloquear o sistema. Tente novamente.</h4>
            </div>
            """, unsafe_allow_html=True)
            return False
        
        status_container.markdown(f"""
        <div class="custom-alert success">
            <h4>‚úÖ Sistema bloqueado com sucesso! (ID: {session_lock})</h4>
        </div>
        """, unsafe_allow_html=True)
        progress_container.progress(15)
        
        atualizar_status_lock(token, session_lock, "BAIXANDO_ARQUIVO", "Baixando arquivo consolidado")
        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üì• Baixando arquivo consolidado existente...</h4>
        </div>
        """, unsafe_allow_html=True)
        progress_container.progress(25)
        
        df_consolidado, arquivo_existe = baixar_arquivo_consolidado(token)
        
        if arquivo_existe:
            status_container.markdown(f"""
            <div class="custom-alert info">
                <h4>üìÇ Arquivo consolidado carregado ({len(df_consolidado):,} registros)</h4>
            </div>
            """, unsafe_allow_html=True)
        else:
            status_container.markdown("""
            <div class="custom-alert info">
                <h4>üìÇ Criando novo arquivo consolidado</h4>
            </div>
            """, unsafe_allow_html=True)
        
        progress_container.progress(35)

        atualizar_status_lock(token, session_lock, "PREPARANDO_DADOS", "Validando e preparando dados")
        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üîß Preparando e validando dados...</h4>
        </div>
        """, unsafe_allow_html=True)
        
        df_novo = df_novo.copy()
        df_novo.columns = df_novo.columns.str.strip().str.upper()
        
        df_novo["DATA"] = pd.to_datetime(df_novo["DATA"], errors="coerce")
        linhas_invalidas = df_novo["DATA"].isna().sum()
        df_novo = df_novo.dropna(subset=["DATA"])

        if df_novo.empty:
            status_container.markdown("""
            <div class="custom-alert error">
                <h4>‚ùå Nenhum registro v√°lido para consolidar</h4>
            </div>
            """, unsafe_allow_html=True)
            remover_lock(token, session_lock)
            return False

        if linhas_invalidas > 0:
            status_container.markdown(f"""
            <div class="custom-alert warning">
                <h4>üßπ {linhas_invalidas} linhas com datas inv√°lidas foram removidas</h4>
            </div>
            """, unsafe_allow_html=True)

        progress_container.progress(45)

        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üìä Realizando an√°lise pr√©-consolida√ß√£o...</h4>
        </div>
        """, unsafe_allow_html=True)
        analise_ok = analise_pre_consolidacao_v2(df_consolidado, df_novo)
        
        if not analise_ok:
            status_container.markdown("""
            <div class="custom-alert error">
                <h4>‚ùå Erro na an√°lise pr√©-consolida√ß√£o</h4>
            </div>
            """, unsafe_allow_html=True)
            remover_lock(token, session_lock)
            return False
        
        progress_container.progress(55)

        atualizar_status_lock(token, session_lock, "CONSOLIDANDO", f"Processando {len(df_novo)} registros por m√™s/ano")
        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üîÑ Processando consolida√ß√£o (l√≥gica por m√™s/ano v2.4.0)...</h4>
        </div>
        """, unsafe_allow_html=True)
        progress_container.progress(65)
        
        df_final, inseridos, substituidos, removidos, detalhes, novas_combinacoes, combinacoes_existentes = comparar_e_atualizar_registros_v2(
            df_consolidado, df_novo
        )
        
        progress_container.progress(75)

        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üõ°Ô∏è Executando verifica√ß√£o de seguran√ßa...</h4>
        </div>
        """, unsafe_allow_html=True)
        verificacao_ok, msg_verificacao = verificar_seguranca_consolidacao_v2(df_consolidado, df_novo, df_final)
        
        if not verificacao_ok:
            status_container.markdown(f"""
            <div class="custom-alert error">
                <h4>‚ùå ERRO DE SEGURAN√áA: {msg_verificacao}</h4>
            </div>
            """, unsafe_allow_html=True)
            st.error("üõë **Consolida√ß√£o cancelada para proteger os dados!**")
            remover_lock(token, session_lock)
            return False
        else:
            status_container.markdown(f"""
            <div class="custom-alert success">
                <h4>‚úÖ Verifica√ß√£o de seguran√ßa passou: {msg_verificacao}</h4>
            </div>
            """, unsafe_allow_html=True)

        df_final = df_final.sort_values(["DATA", "RESPONS√ÅVEL"], na_position='last').reset_index(drop=True)
        progress_container.progress(80)
        
        if removidos > 0:
            atualizar_status_lock(token, session_lock, "CRIANDO_BACKUP", f"Backup de {removidos} registros substitu√≠dos")
            status_container.markdown("""
            <div class="custom-alert info">
                <h4>üíæ Criando backup dos dados substitu√≠dos...</h4>
            </div>
            """, unsafe_allow_html=True)
        
        atualizar_status_lock(token, session_lock, "SALVANDO_ENVIADO", "Salvando c√≥pia do arquivo enviado")
        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üíæ Salvando c√≥pia do arquivo enviado...</h4>
        </div>
        """, unsafe_allow_html=True)
        salvar_arquivo_enviado(df_novo, nome_arquivo, token)
        
        progress_container.progress(85)
        
        atualizar_status_lock(token, session_lock, "UPLOAD_FINAL", "Salvando arquivo consolidado")
        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üì§ Salvando arquivo consolidado final...</h4>
        </div>
        """, unsafe_allow_html=True)
        
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df_final.to_excel(writer, index=False, sheet_name="Vendas CTs")
        buffer.seek(0)
        
        consolidado_nome = "Reports_Geral_Consolidado.xlsx"
        sucesso, status_code, resposta = upload_onedrive(consolidado_nome, buffer.read(), token, "consolidado")

        progress_container.progress(95)

        remover_lock(token, session_lock)
        progress_container.progress(100)
        
        if sucesso:
            status_container.empty()
            progress_container.empty()
            
            st.markdown("""
            <div class="custom-alert success">
                <h2>üéâ CONSOLIDA√á√ÉO REALIZADA COM SUCESSO!</h2>
                <p>üîì Sistema liberado e dispon√≠vel para outros usu√°rios</p>
            </div>
            """, unsafe_allow_html=True)
            
            with st.expander("üìç Localiza√ß√£o dos Arquivos", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"üìä **Arquivo Consolidado:**\n`{PASTA_CONSOLIDADO}/Reports_Geral_Consolidado.xlsx`")
                with col2:
                    st.info(f"üíæ **Backups e Envios:**\n`{PASTA_ENVIOS_BACKUPS}/`")
            
            st.markdown("### üìà **Resultado da Consolida√ß√£o**")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{len(df_final):,}</div>
                    <div class="metric-label">üìä Total Final</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{inseridos}</div>
                    <div class="metric-label">‚ûï Inseridos</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{substituidos}</div>
                    <div class="metric-label">üîÑ Substitu√≠dos</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col4:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{removidos}</div>
                    <div class="metric-label">üóëÔ∏è Removidos</div>
                </div>
                """, unsafe_allow_html=True)
            
            if novas_combinacoes > 0 or combinacoes_existentes > 0:
                st.markdown("### üìà **An√°lise de Combina√ß√µes (Respons√°vel + M√™s/Ano)**")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown(f"""
                    <div class="metric-container">
                        <div class="metric-value">{novas_combinacoes}</div>
                        <div class="metric-label">üÜï Novos Per√≠odos</div>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"""
                    <div class="metric-container">
                        <div class="metric-value">{combinacoes_existentes}</div>
                        <div class="metric-label">üîÑ Per√≠odos Atualizados</div>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    total_processadas = novas_combinacoes + combinacoes_existentes
                    st.markdown(f"""
                    <div class="metric-container">
                        <div class="metric-value">{total_processadas}</div>
                        <div class="metric-label">üìä Total Processado</div>
                    </div>
                    """, unsafe_allow_html=True)
                
                if novas_combinacoes > 0:
                    st.success(f"üéâ **{novas_combinacoes} novo(s) per√≠odo(s) adicionado(s)** - Dados completamente novos!")
                if combinacoes_existentes > 0:
                    st.info(f"üîÑ **{combinacoes_existentes} per√≠odo(s) atualizado(s)** - Dados mensais completamente substitu√≠dos!")
            
            # Verificar se a coluna DATA_ULTIMO_ENVIO foi adicionada
            if 'DATA_ULTIMO_ENVIO' in df_final.columns:
                st.markdown("""
                <div class="custom-alert success">
                    <h4>üìÖ NOVO: Campo "Data do √öltimo Envio" adicionado!</h4>
                    <p>A planilha consolidada agora inclui a data do √∫ltimo envio para cada respons√°vel</p>
                </div>
                """, unsafe_allow_html=True)
            
            if detalhes:
                with st.expander("üìã Detalhes das Opera√ß√µes", expanded=removidos > 0):
                    df_detalhes = pd.DataFrame(detalhes)
                    
                    operacoes_inseridas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'INSERIDO']
                    operacoes_substituidas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'SUBSTITU√çDO']
                    operacoes_removidas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'REMOVIDO']
                    
                    if not operacoes_inseridas.empty:
                        st.markdown("#### ‚ûï **Registros Inseridos (Novos)**")
                        st.dataframe(operacoes_inseridas, use_container_width=True, hide_index=True)
                    
                    if not operacoes_substituidas.empty:
                        st.markdown("#### üîÑ **Registros Substitu√≠dos**")
                        st.dataframe(operacoes_substituidas, use_container_width=True, hide_index=True)
                    
                    if not operacoes_removidas.empty:
                        st.markdown("#### üóëÔ∏è **Registros Removidos**")
                        st.dataframe(operacoes_removidas, use_container_width=True, hide_index=True)
            
            if not df_final.empty:
                resumo_responsaveis = df_final.groupby("RESPONS√ÅVEL").agg({
                    "DATA": ["count", "min", "max"]
                }).round(0)
                
                resumo_responsaveis.columns = ["Total Registros", "Data Inicial", "Data Final"]
                resumo_responsaveis["Data Inicial"] = pd.to_datetime(resumo_responsaveis["Data Inicial"]).dt.strftime("%d/%m/%Y")
                resumo_responsaveis["Data Final"] = pd.to_datetime(resumo_responsaveis["Data Final"]).dt.strftime("%d/%m/%Y")
                
                # Adicionar informa√ß√£o sobre data do √∫ltimo envio se dispon√≠vel
                if 'DATA_ULTIMO_ENVIO' in df_final.columns:
                    ultimo_envio = df_final.groupby("RESPONS√ÅVEL")["DATA_ULTIMO_ENVIO"].max()
                    ultimo_envio = ultimo_envio.dt.strftime("%d/%m/%Y %H:%M")
                    resumo_responsaveis["√öltimo Envio"] = ultimo_envio
                
                with st.expander("üë• Resumo por Respons√°vel"):
                    st.dataframe(resumo_responsaveis, use_container_width=True)
            
            return True
        else:
            status_container.markdown(f"""
            <div class="custom-alert error">
                <h4>‚ùå Erro no upload: Status {status_code}</h4>
            </div>
            """, unsafe_allow_html=True)
            if status_code != 500:
                st.code(resposta)
            return False
            
    except Exception as e:
        logger.error(f"Erro na consolida√ß√£o: {e}")
        remover_lock(token, session_id, force=True)
        
        status_container.markdown(f"""
        <div class="custom-alert error">
            <h4>‚ùå Erro durante consolida√ß√£o: {str(e)}</h4>
        </div>
        """, unsafe_allow_html=True)
        progress_container.empty()
        st.error("üîì **Sistema liberado automaticamente ap√≥s erro.**")
        return False

# ===========================
# INTERFACE STREAMLIT MELHORADA
# ===========================
def exibir_info_versao():
    """Exibe informa√ß√µes de vers√£o e changelog com visual melhorado"""
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è Informa√ß√µes do Sistema")
        
        st.markdown(f"""
        <div class="status-card">
            <strong>Vers√£o:</strong> {APP_VERSION}<br>
            <strong>Data:</strong> {VERSION_DATE}
        </div>
        """, unsafe_allow_html=True)
        
        if APP_VERSION == "2.4.0":
            st.markdown("""
            <div class="status-card success">
                <strong>üé® VISUAL MELHORADO</strong><br>
                <strong>üìÖ CAMPO DATA √öLTIMO ENVIO</strong>
            </div>
            """, unsafe_allow_html=True)
        
        with st.expander("üìù Configura√ß√£o de Pastas"):
            st.markdown("**Arquivo Consolidado:**")
            st.code(PASTA_CONSOLIDADO, language=None)
            st.markdown("**Backups e Envios:**")
            st.code(PASTA_ENVIOS_BACKUPS, language=None)
        
        with st.expander("üÜï Novidades v2.4.0"):
            st.markdown("""
            **üé® Visual Melhorado:**
            - Interface moderna e responsiva
            - CSS organizado e padronizado
            - Componentes visuais aprimorados
            - Anima√ß√µes e transi√ß√µes suaves
            
            **üìÖ Novo Campo:**
            - Data do √∫ltimo envio na planilha
            - Rastreamento por respons√°vel
            - Atualiza√ß√£o autom√°tica
            """)

def main():
    st.set_page_config(
        page_title=f"DSView BI - Upload Planilhas v{APP_VERSION}", 
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Aplicar estilos CSS melhorados
    aplicar_estilos_css()

    # Header principal melhorado
    st.markdown(f"""
    <div class="main-header fade-in">
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <h1>üìä DSView BI ‚Äî Upload de Planilhas</h1>
                <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">Sistema de consolida√ß√£o de relat√≥rios</p>
            </div>
            <div class="version-badge">
                <strong>v{APP_VERSION}</strong><br>
                <small>{VERSION_DATE}</small>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    if APP_VERSION == "2.4.0":
        st.markdown("""
        <div class="custom-alert success">
            <h4>üé® VISUAL MELHORADO + üìÖ CAMPO DATA √öLTIMO ENVIO</h4>
            <p>Interface moderna e nova funcionalidade de rastreamento de envios!</p>
        </div>
        """, unsafe_allow_html=True)

    st.sidebar.markdown("### üì§ Upload de Planilhas")
    st.sidebar.markdown("Sistema de consolida√ß√£o de relat√≥rios")
    st.sidebar.divider()
    st.sidebar.markdown("**Status do Sistema:**")
    
    token = obter_token()
    if not token:
        st.sidebar.error("‚ùå Desconectado")
        st.error("‚ùå N√£o foi poss√≠vel autenticar. Verifique as credenciais.")
        st.stop()
    else:
        st.sidebar.success("‚úÖ Conectado")

    st.markdown("## üîí Status do Sistema")
    
    sistema_ocupado = exibir_status_sistema(token)
    
    if sistema_ocupado:
        st.markdown("---")
        st.info("üîÑ Esta p√°gina ser√° atualizada automaticamente a cada 15 segundos")
        time.sleep(15)
        st.rerun()

    st.divider()

    exibir_info_versao()

    st.markdown("## üì§ Upload de Planilha Excel")
    
    if sistema_ocupado:
        st.markdown("""
        <div class="custom-alert warning">
            <h4>‚ö†Ô∏è Upload desabilitado - Sistema em uso por outro usu√°rio</h4>
            <p>üí° Aguarde a libera√ß√£o do sistema ou tente novamente em alguns minutos</p>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("üîÑ Verificar Status Novamente"):
            st.rerun()
        
        return
    
    st.markdown("""
    <div class="custom-alert info">
        <h4>üí° Importante</h4>
        <p>A planilha deve conter uma coluna 'RESPONS√ÅVEL' com os nomes dos respons√°veis!</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="custom-alert error">
        <h4>üîí VALIDA√á√ÉO SUPER RIGOROSA ATIVADA</h4>
        <p>üìã QUALQUER problema de data (vazias, formato inv√°lido, futuras, antigas) impedir√° a consolida√ß√£o!</p>
    </div>
    """, unsafe_allow_html=True)
    
    with st.expander("üéØ Novidades da v2.4.0 - VISUAL MELHORADO + DATA √öLTIMO ENVIO", expanded=True):
        st.markdown("### üé® **Melhorias Visuais:**")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
            **‚ú® Interface Moderna:**
            - CSS organizado e padronizado
            - Componentes visuais aprimorados
            - Layout responsivo
            - Anima√ß√µes suaves
            """)
            
        with col2:
            st.markdown("""
            **üìä Dashboard Melhorado:**
            - M√©tricas visuais aprimoradas
            - Cards de status modernos
            - Feedback visual durante processos
            - Tema consistente
            """)
        
        st.markdown("### üìÖ **Nova Funcionalidade:**")
        st.success("üÜï **Campo 'Data do √öltimo Envio'** - A planilha consolidada agora registra quando cada respons√°vel teve seus dados atualizados pela √∫ltima vez!")
        
        st.markdown("### üîß **Como Funciona:**")
        st.info("Quando voc√™ envia dados de um respons√°vel, o sistema automaticamente registra a data e hora do envio na coluna 'DATA_ULTIMO_ENVIO'")
        st.info("Isso permite rastrear quando cada respons√°vel teve seus dados atualizados pela √∫ltima vez")
    
    st.divider()

    uploaded_file = st.file_uploader(
        "Escolha um arquivo Excel", 
        type=["xlsx", "xls"],
        help="Formatos aceitos: .xlsx, .xls | Certifique-se de que h√° uma coluna 'RESPONS√ÅVEL' na planilha"
    )

    df = None
    if uploaded_file:
        try:
            st.markdown(f"""
            <div class="custom-alert success">
                <h4>üìÅ Arquivo carregado: {uploaded_file.name}</h4>
            </div>
            """, unsafe_allow_html=True)
            
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            with st.spinner("üìñ Lendo arquivo..."):
                if file_extension == 'xls':
                    xls = pd.ExcelFile(uploaded_file, engine='xlrd')
                else:
                    xls = pd.ExcelFile(uploaded_file)
                
                sheets = xls.sheet_names
                
                if len(sheets) > 1:
                    if "Vendas CTs" in sheets:
                        sheet = "Vendas CTs"
                        st.success("‚úÖ Aba 'Vendas CTs' encontrada e selecionada automaticamente")
                    else:
                        sheet = st.selectbox(
                            "Selecione a aba (recomendado: 'Vendas CTs'):", 
                            sheets,
                            help="Para melhor compatibilidade, use uma aba chamada 'Vendas CTs'"
                        )
                        if sheet != "Vendas CTs":
                            st.warning("‚ö†Ô∏è Recomendamos que a aba seja chamada 'Vendas CTs'")
                else:
                    sheet = sheets[0]
                    if sheet != "Vendas CTs":
                        st.warning("‚ö†Ô∏è Recomendamos que a aba seja chamada 'Vendas CTs'")
                
                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                df.columns = df.columns.str.strip().str.upper()
                
                st.success(f"‚úÖ Dados carregados: {len(df)} linhas, {len(df.columns)} colunas")
                
                # Preview dos dados com visual melhorado
                with st.expander("üëÄ Preview dos Dados", expanded=True):
                    st.dataframe(df.head(10), use_container_width=True)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.markdown(f"""
                        <div class="metric-container">
                            <div class="metric-value">{len(df)}</div>
                            <div class="metric-label">Linhas</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown(f"""
                        <div class="metric-container">
                            <div class="metric-value">{len(df.columns)}</div>
                            <div class="metric-label">Colunas</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col3:
                        if "RESPONS√ÅVEL" in df.columns:
                            responsaveis_unicos = df["RESPONS√ÅVEL"].dropna().nunique()
                            st.markdown(f"""
                            <div class="metric-container">
                                <div class="metric-value">{responsaveis_unicos}</div>
                                <div class="metric-label">Respons√°veis</div>
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown(f"""
                            <div class="metric-container">
                                <div class="metric-value">‚ùå</div>
                                <div class="metric-label">Respons√°veis</div>
                            </div>
                            """, unsafe_allow_html=True)
                
        except Exception as e:
            st.error(f"‚ùå Erro ao ler arquivo: {str(e)}")
            st.stop()

    if df is not None:
        st.markdown("### üîç Valida√ß√£o dos Dados")
        
        with st.spinner("üîç Validando dados..."):
            erros, avisos, problemas_datas = validar_dados_enviados(df)
        
        # Exibir resultados da valida√ß√£o
        if erros:
            st.markdown("""
            <div class="custom-alert error">
                <h4>‚ùå Problemas Encontrados</h4>
                <p>Corrija os problemas abaixo antes de prosseguir:</p>
            </div>
            """, unsafe_allow_html=True)
            
            for erro in erros:
                st.error(erro)
            
            if problemas_datas:
                exibir_problemas_datas(problemas_datas)
            
            botao_desabilitado = True
        else:
            st.markdown("""
            <div class="custom-alert success">
                <h4>‚úÖ Valida√ß√£o Aprovada</h4>
                <p>Todos os dados est√£o v√°lidos e prontos para consolida√ß√£o!</p>
            </div>
            """, unsafe_allow_html=True)
            botao_desabilitado = False
        
        if avisos:
            for aviso in avisos:
                st.info(aviso)
        
        st.divider()
        
        # Bot√µes de a√ß√£o com visual melhorado
        if not erros:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                if botao_desabilitado:
                    st.button("‚ùå Consolidar Dados", type="primary", disabled=True, 
                             help="Corrija todos os problemas antes de prosseguir")
                    st.caption("üîí Bot√£o bloqueado - h√° problemas na planilha")
                else:
                    # Bot√£o principal sem confirma√ß√£o dupla
                    if st.button("‚úÖ **Consolidar Dados**", type="primary", 
                                help="Inicia a consolida√ß√£o por m√™s/ano imediatamente"):
                        
                        # Aviso importante antes de iniciar
                        st.markdown("""
                        <div class="custom-alert warning">
                            <h4>‚è≥ Consolida√ß√£o iniciada! Aguarde o t√©rmino do processo. N√ÉO feche esta p√°gina!</h4>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Iniciar consolida√ß√£o diretamente
                        sucesso = processar_consolidacao_com_lock(df, uploaded_file.name, token)
                        
                        if sucesso:
                            st.balloons()
                            st.markdown("""
                            <div class="custom-alert success">
                                <h2>üéâ CONSOLIDA√á√ÉO FINALIZADA COM SUCESSO!</h2>
                                <p>üí° Voc√™ pode enviar uma nova planilha ou fechar esta p√°gina</p>
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown("""
                            <div class="custom-alert error">
                                <h4>‚ùå Falha na consolida√ß√£o. Tente novamente.</h4>
                            </div>
                            """, unsafe_allow_html=True)
            
            with col2:
                if st.button("üîÑ Limpar Tela", type="secondary"):
                    st.rerun()
                    
        # Informa√ß√µes sobre o que a consolida√ß√£o far√°
        with st.expander("‚ÑπÔ∏è O que acontecer√° durante a consolida√ß√£o?", expanded=False):
            st.info("**üìä An√°lise dos dados enviados por m√™s/ano**")
            st.info("**üîÑ Substitui√ß√£o de per√≠odos mensais existentes** (mesmo respons√°vel + m√™s/ano)")
            st.info("**‚ûï Adi√ß√£o de novos per√≠odos** (combina√ß√µes inexistentes)")
            st.info("**üìÖ Atualiza√ß√£o da data do √∫ltimo envio** para respons√°veis modificados")
            st.info("**üíæ Cria√ß√£o de backups autom√°ticos** dos dados substitu√≠dos")
            st.info("**üîí Bloqueio tempor√°rio do sistema** durante o processo")
            st.info("**üõ°Ô∏è Verifica√ß√£o de seguran√ßa** antes de salvar")
            st.info("**üìà Relat√≥rio completo** das opera√ß√µes realizadas")
            st.success("**üéØ NOVO:** Agora a consolida√ß√£o √© feita por **RESPONS√ÅVEL + M√äS/ANO** - elimina duplicatas!")
            st.success("**üìÖ NOVO:** Campo **DATA_ULTIMO_ENVIO** registra quando cada respons√°vel foi atualizado!")

    # Footer melhorado
    st.markdown("---")
    st.markdown(f"""
    <div class="footer">
        <strong>DSView BI - Sistema de Consolida√ß√£o de Relat√≥rios v{APP_VERSION}</strong><br>
        ‚ö†Ô∏è Certifique-se de que sua planilha contenha:<br>
        ‚Ä¢ Uma aba chamada <strong>'Vendas CTs'</strong><br>
        ‚Ä¢ Uma coluna <strong>'DATA'</strong><br>
        ‚Ä¢ Uma coluna <strong>'RESPONS√ÅVEL'</strong><br>
        ‚Ä¢ Colunas: <strong>TMO - Duto, TMO - Freio, TMO - Sanit, TMO - Verniz, CX EVAP</strong><br>
        <br>
        üé® <strong>v2.4.0:</strong> Visual melhorado + Campo data do √∫ltimo envio<br>
        <small>√öltima atualiza√ß√£o: {VERSION_DATE}</small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()

