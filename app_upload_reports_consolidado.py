import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta
from io import BytesIO
from msal import ConfidentialClientApplication
import unicodedata
import logging
import os
import json
import uuid
import time

# ===========================
# CONFIGURA√á√ïES DE VERS√ÉO - ATUALIZADO v2.2.4
# ===========================
APP_VERSION = "2.2.4"
VERSION_DATE = "2025-08-14"
CHANGELOG = {
    "2.2.4": {
        "date": "2025-08-14",
        "changes": [
            "üîß CORRE√á√ÉO CR√çTICA: L√≥gica de consolida√ß√£o reescrita",
            "üõ°Ô∏è Sistema de verifica√ß√£o de seguran√ßa implementado",
            "üîç Logs detalhados para monitoramento de consolida√ß√£o",
            "üìä An√°lise pr√©-consolida√ß√£o com previs√£o de impacto",
            "‚ö° Feedback visual melhorado durante processo",
            "üö® Alertas claros antes e durante consolida√ß√£o",
            "üéØ Corrigido problema de exclus√£o indevida de respons√°veis",
            "üìà M√©tricas em tempo real durante processamento"
        ]
    },
    "2.2.3": {
        "date": "2025-08-08",
        "changes": [
            "üîí Valida√ß√£o super rigorosa implementada",
            "‚ùå QUALQUER problema de data agora impede consolida√ß√£o",
            "üìã Obrigat√≥rio corrigir TODOS os problemas antes de enviar",
            "üîß Inclui: datas vazias, formatos inv√°lidos, datas imposs√≠veis, futuras e antigas",
            "üìä Mensagem clara solicitando revis√£o completa da planilha",
            "üõ°Ô∏è Zero toler√¢ncia para garantir 100% qualidade dos dados"
        ]
    },
    "2.2.2": {
        "date": "2025-08-08",
        "changes": [
            "üîí Valida√ß√£o rigorosa implementada",
            "‚ùå Problemas cr√≠ticos de data agora impedem consolida√ß√£o", 
            "üîß Datas vazias, formatos inv√°lidos e datas imposs√≠veis devem ser corrigidos",
            "‚ö†Ô∏è Problemas menores (futuro/antigas) geram apenas avisos",
            "üìä Categoriza√ß√£o inteligente de problemas por severidade"
        ]
    },
    "2.2.1": {
        "date": "2025-08-07",
        "changes": [
            "üîí Sistema de lock implementado - apenas 1 usu√°rio pode enviar por vez",
            "‚è±Ô∏è Timeout autom√°tico de 10 minutos para processos travados",
            "üìä Interface mostra status do sistema em tempo real",
            "üîÑ Auto-refresh quando sistema est√° ocupado",
            "üÜò Bot√£o de libera√ß√£o for√ßada para processos √≥rf√£os",
            "üì± Session ID √∫nico para controle de concorr√™ncia",
            "üõ°Ô∏è Prote√ß√£o completa contra perda de dados em envios simult√¢neos"
        ]
    }
}

# ===========================
# CONFIGURA√á√ÉO DE LOGGING
# ===========================
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===========================
# CREDENCIAIS VIA ST.SECRETS
# ===========================
try:
    CLIENT_ID = st.secrets["CLIENT_ID"]
    CLIENT_SECRET = st.secrets["CLIENT_SECRET"]
    TENANT_ID = st.secrets["TENANT_ID"]
    EMAIL_ONEDRIVE = st.secrets["EMAIL_ONEDRIVE"]
    SITE_ID = st.secrets["SITE_ID"]
    DRIVE_ID = st.secrets["DRIVE_ID"]
except KeyError as e:
    st.error(f"‚ùå Credencial n√£o encontrada: {e}")
    st.stop()

# ===========================
# CONFIGURA√á√ÉO DE PASTAS - v2.2.0
# ===========================
# PASTA PRINCIPAL - onde fica o arquivo consolidado
PASTA_CONSOLIDADO = "Documentos Compartilhados/LimparAuto/FontedeDados"

# NOVA PASTA - para arquivos enviados e backups
PASTA_ENVIOS_BACKUPS = "Documentos Compartilhados/PlanilhasEnviadas_Backups/LimparAuto"

# Manter compatibilidade (algumas fun√ß√µes ainda usam)
PASTA = PASTA_CONSOLIDADO

# ===========================
# CONFIGURA√á√ÉO DO SISTEMA DE LOCK - v2.2.1
# ===========================
ARQUIVO_LOCK = "sistema_lock.json"
TIMEOUT_LOCK_MINUTOS = 10

# ===========================
# AUTENTICA√á√ÉO
# ===========================
@st.cache_data(ttl=3300)  # Cache por 55 minutos (token v√°lido por 1h)
def obter_token():
    """Obt√©m token de acesso para Microsoft Graph API"""
    try:
        app = ConfidentialClientApplication(
            CLIENT_ID,
            authority=f"https://login.microsoftonline.com/{TENANT_ID}",
            client_credential=CLIENT_SECRET
        )
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        
        if "access_token" not in result:
            error_desc = result.get("error_description", "Token n√£o obtido")
            st.error(f"‚ùå Falha na autentica√ß√£o: {error_desc}")
            return None
            
        return result["access_token"]
        
    except Exception as e:
        st.error(f"‚ùå Erro na autentica√ß√£o: {str(e)}")
        logger.error(f"Erro de autentica√ß√£o: {e}")
        return None

# ===========================
# SISTEMA DE LOCK PARA CONTROLE DE CONCORR√äNCIA - v2.2.1
# ===========================

def gerar_id_sessao():
    """Gera um ID √∫nico para a sess√£o atual"""
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())[:8]
    return st.session_state.session_id

def verificar_lock_existente(token):
    """Verifica se existe um lock ativo no sistema"""
    try:
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            lock_data = response.json()
            
            # Verificar colunas com valores nulos
        colunas_nulas = df.columns[df.isnull().any()].tolist()
        if colunas_nulas:
            st.warning(f"‚ö†Ô∏è Colunas com valores nulos: {', '.join(colunas_nulas[:5])}")
            if len(colunas_nulas) > 5:
                st.warning(f"... e mais {len(colunas_nulas) - 5} colunas")
        else:
            st.success("‚úÖ Nenhuma coluna com valores nulos.")

        # NOVA VALIDA√á√ÉO SUPER RIGOROSA v2.2.4
        st.subheader("üîç Valida√ß√µes Super Rigorosas")
        erros, avisos, linhas_invalidas_detalhes = validar_dados_enviados(df)
        
        # Mostrar avisos
        for aviso in avisos:
            if aviso.startswith("‚úÖ"):
                st.success(aviso)
            else:
                st.warning(aviso)
        
        # Mostrar detalhes das linhas inv√°lidas
        if linhas_invalidas_detalhes:
            exibir_relatorio_problemas_datas(linhas_invalidas_detalhes)
        
        # Mostrar erros - AGORA MAIS PROMINENT
        if erros:
            st.markdown("## ‚ùå **PROBLEMAS ENCONTRADOS - CORRE√á√ÉO OBRIGAT√ìRIA**")
            
            for erro in erros:
                if erro.startswith("‚ùå"):
                    st.error(erro)
                elif erro.startswith("üîß"):
                    st.error(erro)
                elif erro.startswith("üìã"):
                    st.warning(erro)
                else:
                    st.error(erro)
            
            # Mensagem final clara
            st.markdown("---")
            st.error("üö´ **A consolida√ß√£o est√° BLOQUEADA at√© que todos os problemas sejam corrigidos!**")
            st.info("üí° **Pr√≥ximos passos:**")
            st.info("1. ‚úèÔ∏è Abra sua planilha Excel")
            st.info("2. üîß Corrija TODOS os problemas listados acima")
            st.info("3. üíæ Salve o arquivo")
            st.info("4. üîÑ Fa√ßa o upload novamente")

        # Bot√£o de envio com verifica√ß√£o de lock e feedback melhorado
        st.divider()
        st.markdown("### üöÄ **Consolidar Dados**")
        
        col1, col2 = st.columns([1, 4])
        with col1:
            # Verificar novamente se sistema est√° livre antes de permitir envio
            sistema_ocupado_agora, _ = verificar_lock_existente(token)
            
            if sistema_ocupado_agora:
                st.error("üîí Sistema foi bloqueado por outro usu√°rio")
                if st.button("üîÑ Atualizar P√°gina"):
                    st.rerun()
            else:
                # Bot√£o desabilitado se houver QUALQUER erro
                botao_desabilitado = bool(erros)
                
                if botao_desabilitado:
                    st.button("‚ùå Consolidar Dados", type="primary", disabled=True, 
                             help="Corrija todos os problemas antes de prosseguir")
                    st.caption("üîí Bot√£o bloqueado - h√° problemas na planilha")
                else:
                    # BOT√ÉO COM CONFIRMA√á√ÉO E FEEDBACK MELHORADO
                    if st.button("‚úÖ Consolidar Dados", type="primary", help="Clique para iniciar a consolida√ß√£o"):
                        
                        # Confirma√ß√£o final antes de processar
                        with st.expander("‚ö†Ô∏è **CONFIRMA√á√ÉO FINAL**", expanded=True):
                            st.warning("**Voc√™ est√° prestes a consolidar os dados. Esta a√ß√£o ir√°:**")
                            st.info("‚Ä¢ üìä Analisar os dados enviados")
                            st.info("‚Ä¢ üîÑ Substituir dados existentes com mesma data e respons√°vel")
                            st.info("‚Ä¢ ‚ûï Adicionar novos dados")
                            st.info("‚Ä¢ üíæ Criar backups autom√°ticos")
                            st.info("‚Ä¢ üîí Bloquear sistema durante o processo")
                            
                            col_confirma, col_cancela = st.columns(2)
                            
                            with col_confirma:
                                if st.button("üéØ **CONFIRMAR CONSOLIDA√á√ÉO**", type="primary"):
                                    st.info("üöÄ **Iniciando consolida√ß√£o...**")
                                    st.warning("‚è≥ **Aguarde o t√©rmino do processo. N√ÉO feche esta p√°gina!**")
                                    
                                    # Usar a nova fun√ß√£o com lock e feedback melhorado
                                    sucesso = processar_consolidacao_com_lock(df, uploaded_file.name, token)
                                    
                                    if sucesso:
                                        st.balloons()
                                        st.success("üéâ **CONSOLIDA√á√ÉO FINALIZADA COM SUCESSO!**")
                                        st.info("üí° Voc√™ pode enviar uma nova planilha ou fechar esta p√°gina")
                                    else:
                                        st.error("‚ùå **Falha na consolida√ß√£o. Tente novamente.**")
                            
                            with col_cancela:
                                if st.button("‚ùå Cancelar", type="secondary"):
                                    st.info("üîÑ Consolida√ß√£o cancelada. Voc√™ pode fazer ajustes na planilha se necess√°rio.")
                                    st.rerun()
                        
        with col2:
            if st.button("üîÑ Limpar Tela", type="secondary"):
                st.rerun()

    # Rodap√© com informa√ß√µes
    st.divider()
    st.markdown(
        f"""
        <div style="text-align: center; color: #666; font-size: 0.8em;">
            <strong>DSView BI - Sistema de Consolida√ß√£o de Relat√≥rios v{APP_VERSION}</strong><br>
            ‚ö†Ô∏è Certifique-se de que sua planilha contenha:<br>
            ‚Ä¢ Uma aba chamada <strong>'Vendas CTs'</strong><br>
            ‚Ä¢ Uma coluna <strong>'DATA'</strong><br>
            ‚Ä¢ Uma coluna <strong>'RESPONS√ÅVEL'</strong><br>
            ‚Ä¢ Colunas: <strong>TMO - Duto, TMO - Freio, TMO - Sanit, TMO - Verniz, CX EVAP</strong><br>
            <br>
            üîß <strong>v2.2.4:</strong> L√≥gica de consolida√ß√£o corrigida - Verifica√ß√µes de seguran√ßa implementadas<br>
            üîí <strong>v2.2.3:</strong> Valida√ß√£o super rigorosa - QUALQUER problema de data impede consolida√ß√£o<br>
            <small>√öltima atualiza√ß√£o: {VERSION_DATE}</small>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main() se o lock n√£o expirou
            timestamp_lock = datetime.fromisoformat(lock_data['timestamp'])
            agora = datetime.now()
            
            if agora - timestamp_lock > timedelta(minutes=TIMEOUT_LOCK_MINUTOS):
                # Lock expirado - remover automaticamente
                logger.info(f"Lock expirado removido automaticamente. Era de {timestamp_lock}")
                remover_lock(token, force=True)
                return False, None
            
            return True, lock_data
        
        elif response.status_code == 404:
            # Arquivo de lock n√£o existe
            return False, None
        else:
            # Erro ao verificar - assumir que n√£o h√° lock por seguran√ßa
            logger.warning(f"Erro ao verificar lock: {response.status_code}")
            return False, None
            
    except Exception as e:
        logger.error(f"Erro ao verificar lock: {e}")
        return False, None

def criar_lock(token, operacao="Consolida√ß√£o de dados"):
    """Cria um lock para bloquear outras opera√ß√µes"""
    try:
        session_id = gerar_id_sessao()
        
        lock_data = {
            "timestamp": datetime.now().isoformat(),
            "session_id": session_id,
            "operacao": operacao,
            "status": "EM_ANDAMENTO",
            "app_version": APP_VERSION
        }
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.put(url, headers=headers, data=json.dumps(lock_data))
        
        if response.status_code in [200, 201]:
            logger.info(f"Lock criado com sucesso. Session ID: {session_id}")
            return True, session_id
        else:
            logger.error(f"Erro ao criar lock: {response.status_code}")
            return False, None
            
    except Exception as e:
        logger.error(f"Erro ao criar lock: {e}")
        return False, None

def remover_lock(token, session_id=None, force=False):
    """Remove o lock do sistema"""
    try:
        if not force and session_id:
            # Verificar se o lock pertence a esta sess√£o
            lock_existe, lock_data = verificar_lock_existente(token)
            if lock_existe and lock_data.get('session_id') != session_id:
                logger.warning("Tentativa de remover lock de outra sess√£o!")
                return False
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.delete(url, headers=headers)
        
        if response.status_code in [200, 204]:
            logger.info("Lock removido com sucesso")
            return True
        elif response.status_code == 404:
            # Lock j√° n√£o existe
            return True
        else:
            logger.error(f"Erro ao remover lock: {response.status_code}")
            return False
            
    except Exception as e:
        logger.error(f"Erro ao remover lock: {e}")
        return False

def atualizar_status_lock(token, session_id, novo_status, detalhes=None):
    """Atualiza o status do lock durante o processo"""
    try:
        lock_existe, lock_data = verificar_lock_existente(token)
        
        if not lock_existe or lock_data.get('session_id') != session_id:
            logger.warning("Lock n√£o existe ou n√£o pertence a esta sess√£o")
            return False
        
        # Atualizar dados do lock
        lock_data['status'] = novo_status
        lock_data['ultima_atualizacao'] = datetime.now().isoformat()
        
        if detalhes:
            lock_data['detalhes'] = detalhes
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.put(url, headers=headers, data=json.dumps(lock_data))
        return response.status_code in [200, 201]
        
    except Exception as e:
        logger.error(f"Erro ao atualizar status do lock: {e}")
        return False

def exibir_status_sistema(token):
    """Exibe o status atual do sistema de lock"""
    lock_existe, lock_data = verificar_lock_existente(token)
    
    if lock_existe:
        timestamp_inicio = datetime.fromisoformat(lock_data['timestamp'])
        duracao = datetime.now() - timestamp_inicio
        
        # Determinar cor baseada na dura√ß√£o
        if duracao.total_seconds() < 60:  # Menos de 1 minuto
            cor = "üü°"  # Amarelo - normal
        elif duracao.total_seconds() < 300:  # Menos de 5 minutos  
            cor = "üü†"  # Laranja - demorado
        else:  # Mais de 5 minutos
            cor = "üî¥"  # Vermelho - muito demorado
        
        # Calcular tempo restante at√© timeout
        tempo_limite = timestamp_inicio + timedelta(minutes=TIMEOUT_LOCK_MINUTOS)
        tempo_restante = tempo_limite - datetime.now()
        
        st.error(f"üîí **Sistema ocupado** - Outro usu√°rio est√° enviando dados")
        
        with st.expander("‚ÑπÔ∏è Detalhes do processo em andamento"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.info(f"**Opera√ß√£o:** {lock_data.get('operacao', 'N/A')}")
                st.info(f"**Status:** {lock_data.get('status', 'N/A')}")
                st.info(f"**In√≠cio:** {timestamp_inicio.strftime('%H:%M:%S')}")
                
            with col2:
                st.info(f"{cor} **Dura√ß√£o:** {int(duracao.total_seconds()//60)}min {int(duracao.total_seconds()%60)}s")
                if tempo_restante.total_seconds() > 0:
                    st.info(f"‚è±Ô∏è **Timeout em:** {int(tempo_restante.total_seconds()//60)}min")
                else:
                    st.warning("‚ö†Ô∏è **Processo pode ter travado** (ser√° liberado automaticamente)")
                
            # Detalhes adicionais se dispon√≠veis
            if 'detalhes' in lock_data:
                st.info(f"**Detalhes:** {lock_data['detalhes']}")
                
            # Mostrar session ID para debug (apenas alguns caracteres)
            session_id_display = lock_data.get('session_id', 'N/A')[:8]
            st.caption(f"Session ID: {session_id_display}")
        
        # Bot√£o de for√ßa para administradores (caso necess√°rio)
        if tempo_restante.total_seconds() < 0:
            if st.button("üÜò Liberar Sistema (For√ßar)", type="secondary"):
                if remover_lock(token, force=True):
                    st.success("‚úÖ Sistema liberado com sucesso!")
                    st.rerun()
                else:
                    st.error("‚ùå Erro ao liberar sistema")
        
        return True  # Sistema ocupado
    else:
        # Sistema livre
        st.success("‚úÖ **Sistema dispon√≠vel** - Voc√™ pode enviar sua planilha")
        return False  # Sistema livre

# ===========================
# FUN√á√ïES AUXILIARES
# ===========================

def criar_pasta_se_nao_existir(caminho_pasta, token):
    """Cria pasta no OneDrive se n√£o existir"""
    try:
        # Dividir o caminho em partes
        partes = caminho_pasta.split('/')
        caminho_atual = ""
        
        for parte in partes:
            if not parte:
                continue
                
            caminho_anterior = caminho_atual
            caminho_atual = f"{caminho_atual}/{parte}" if caminho_atual else parte
            
            # Verificar se a pasta existe
            url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{caminho_atual}"
            headers = {"Authorization": f"Bearer {token}"}
            response = requests.get(url, headers=headers)
            
            if response.status_code == 404:
                # Criar pasta
                parent_url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root"
                if caminho_anterior:
                    parent_url += f":/{caminho_anterior}"
                parent_url += ":/children"
                
                create_body = {
                    "name": parte,
                    "folder": {},
                    "@microsoft.graph.conflictBehavior": "rename"
                }
                
                create_response = requests.post(
                    parent_url, 
                    headers={**headers, "Content-Type": "application/json"}, 
                    json=create_body
                )
                
                if create_response.status_code not in [200, 201]:
                    logger.warning(f"N√£o foi poss√≠vel criar pasta {parte}")
                    
    except Exception as e:
        logger.warning(f"Erro ao criar estrutura de pastas: {e}")

# ===========================
# UPLOAD E BACKUP - v2.2.0
# ===========================
def upload_onedrive(nome_arquivo, conteudo_arquivo, token, tipo_arquivo="consolidado"):
    """
    Faz upload de arquivo para OneDrive com pasta espec√≠fica baseada no tipo
    
    tipo_arquivo: "consolidado", "enviado", "backup"
    """
    try:
        # Determinar pasta baseada no tipo
        if tipo_arquivo == "consolidado":
            pasta_base = PASTA_CONSOLIDADO
        elif tipo_arquivo in ["enviado", "backup"]:
            pasta_base = PASTA_ENVIOS_BACKUPS
        else:
            pasta_base = PASTA_CONSOLIDADO  # fallback
        
        # Garantir que a pasta existe
        pasta_arquivo = "/".join(nome_arquivo.split("/")[:-1]) if "/" in nome_arquivo else ""
        if pasta_arquivo:
            criar_pasta_se_nao_existir(f"{pasta_base}/{pasta_arquivo}", token)
        
        # Fazer backup se arquivo j√° existir (apenas para consolidado)
        if tipo_arquivo == "consolidado" and "/" not in nome_arquivo:
            mover_arquivo_existente(nome_arquivo, token, pasta_base)
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{pasta_base}/{nome_arquivo}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/octet-stream"
        }
        response = requests.put(url, headers=headers, data=conteudo_arquivo)
        
        return response.status_code in [200, 201], response.status_code, response.text
        
    except Exception as e:
        logger.error(f"Erro no upload: {e}")
        return False, 500, f"Erro interno: {str(e)}"

def mover_arquivo_existente(nome_arquivo, token, pasta_base=None):
    """Move arquivo existente para backup antes de substituir"""
    try:
        if pasta_base is None:
            pasta_base = PASTA_CONSOLIDADO
            
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{pasta_base}/{nome_arquivo}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            file_id = response.json().get("id")
            timestamp = datetime.now().strftime("%Y-%m-%d_%Hh%M")
            nome_base = nome_arquivo.replace(".xlsx", "")
            novo_nome = f"{nome_base}_backup_{timestamp}.xlsx"
            
            patch_url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/items/{file_id}"
            patch_body = {"name": novo_nome}
            patch_headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }
            patch_response = requests.patch(patch_url, headers=patch_headers, json=patch_body)
            
            if patch_response.status_code in [200, 201]:
                st.info(f"üíæ Backup criado: {novo_nome}")
            else:
                st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel criar backup do arquivo existente")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao processar backup: {str(e)}")
        logger.error(f"Erro no backup: {e}")

# ===========================
# VALIDA√á√ÉO MELHORADA DE DATAS
# ===========================
def validar_datas_detalhadamente(df):
    """
    üîç NOVA VALIDA√á√ÉO DETALHADA DE DATAS - v2.1.0
    
    Detecta 6 tipos diferentes de problemas:
    1. VAZIO - Datas em branco ou nulas
    2. FORMATO - Formatos inv√°lidos ou n√£o convers√≠veis
    3. IMPOSS√çVEL - Datas logicamente imposs√≠veis (31/02)
    4. FUTURO - Datas muito distantes no futuro
    5. ANTIGA - Datas muito antigas
    6. INCONSISTENTE - Outros problemas de consist√™ncia
    """
    from datetime import datetime
    import pandas as pd
    
    problemas = []
    
    logger.info(f"üîç Iniciando valida√ß√£o detalhada de {len(df)} registros...")
    
    for idx, row in df.iterrows():
        linha_excel = idx + 2  # Excel come√ßa em 1 + cabe√ßalho
        valor_original = row["DATA"]
        responsavel = row.get("RESPONS√ÅVEL", "N/A")
        
        problema_encontrado = None
        tipo_problema = None
        data_convertida = None
        
        # 1. VERIFICAR SE DATA EST√Å VAZIA
        if pd.isna(valor_original) or str(valor_original).strip() == "":
            problema_encontrado = "Data vazia ou nula"
            tipo_problema = "VAZIO"
            
        else:
            try:
                # 2. TENTAR CONVERTER PARA DATETIME
                data_convertida = pd.to_datetime(valor_original, errors='raise')
                
                # 3. VERIFICA√á√ïES DE L√ìGICA DE NEG√ìCIO
                hoje = datetime.now()
                ano_atual = hoje.year
                
                # Data muito no futuro (mais de 2 anos)
                if data_convertida > hoje + pd.Timedelta(days=730):
                    problema_encontrado = f"Data muito distante no futuro: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "FUTURO"
                
                # Data muito antiga (antes de 2020)
                elif data_convertida < pd.Timestamp('2020-01-01'):
                    problema_encontrado = f"Data muito antiga: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "ANTIGA"
                
                # Verificar datas imposs√≠veis (ex: 31/02, 30/02, etc.)
                elif data_convertida.day > 31 or data_convertida.month > 12:
                    problema_encontrado = f"Data imposs√≠vel: dia={data_convertida.day}, m√™s={data_convertida.month}"
                    tipo_problema = "IMPOSS√çVEL"
                    
                # Verificar se a data est√° num futuro muito pr√≥ximo mas suspeito
                elif data_convertida > hoje + pd.Timedelta(days=90):
                    problema_encontrado = f"Data no futuro (verificar se est√° correta): {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "FUTURO"
                    
            except (ValueError, TypeError, pd.errors.OutOfBoundsDatetime, OverflowError) as e:
                # Data n√£o pode ser convertida - problema de formato
                problema_encontrado = f"Formato inv√°lido: '{str(valor_original)}'"
                tipo_problema = "FORMATO"
                logger.debug(f"Erro de convers√£o na linha {linha_excel}: {e}")
        
        # Se encontrou qualquer problema, adicionar aos detalhes
        if problema_encontrado:
            problemas.append({
                "Linha no Excel": linha_excel,
                "Data Inv√°lida": str(valor_original)[:50],  # Limitar tamanho
                "Tipo Problema": tipo_problema,
                "Descri√ß√£o": problema_encontrado,
                "Respons√°vel": str(responsavel)[:30]  # Limitar tamanho
            })
    
    logger.info(f"‚úÖ Valida√ß√£o conclu√≠da: {len(problemas)} problemas encontrados")
    return problemas

def exibir_relatorio_problemas_datas(problemas_datas):
    """
    üìã Exibe relat√≥rio visual detalhado dos problemas encontrados nas datas
    """
    if not problemas_datas:
        st.success("‚úÖ **Todas as datas est√£o v√°lidas e consistentes!**")
        return
    
    # Cabe√ßalho do relat√≥rio
    st.error(f"‚ö† **ATEN√á√ÉO: {len(problemas_datas)} problemas encontrados nas datas**")
    
    # Converter para DataFrame para an√°lise
    df_problemas = pd.DataFrame(problemas_datas)
    
    # 1. RESUMO POR TIPO DE PROBLEMA
    if "Tipo Problema" in df_problemas.columns:
        tipos_problema = df_problemas.groupby('Tipo Problema').size().sort_values(ascending=False)
        
        st.markdown("### üìä **Resumo dos Problemas:**")
        
        # Criar colunas para mostrar os tipos
        cols = st.columns(min(len(tipos_problema), 4))
        
        emoji_map = {
            "VAZIO": "üî¥",
            "FORMATO": "üü†", 
            "IMPOSS√çVEL": "üü£",
            "FUTURO": "üü°",
            "ANTIGA": "üü§",
            "INCONSISTENTE": "‚ö´"
        }
        
        for i, (tipo, qtd) in enumerate(tipos_problema.items()):
            emoji = emoji_map.get(tipo, "‚ùå")
            col_idx = i % len(cols)
            
            with cols[col_idx]:
                st.metric(
                    label=f"{emoji} {tipo}",
                    value=f"{qtd} linha{'s' if qtd > 1 else ''}",
                    help=f"Problemas do tipo {tipo}"
                )
    
    st.divider()
    
    # 2. TABELA DETALHADA DOS PROBLEMAS
    st.markdown("### üìã **Detalhes das Linhas com Problemas:**")
    
    # Preparar colunas para exibi√ß√£o
    colunas_exibir = ["Linha no Excel", "Respons√°vel", "Data Inv√°lida", "Descri√ß√£o"]
    
    # Limitar n√∫mero de linhas exibidas para n√£o sobrecarregar
    max_linhas_exibir = 50
    
    if len(df_problemas) <= max_linhas_exibir:
        st.dataframe(
            df_problemas[colunas_exibir], 
            use_container_width=True, 
            hide_index=True,
            height=min(400, len(df_problemas) * 35)
        )
    else:
        st.dataframe(
            df_problemas.head(max_linhas_exibir)[colunas_exibir], 
            use_container_width=True, 
            hide_index=True,
            height=400
        )
        st.warning(f"‚ö†Ô∏è **Exibindo apenas as primeiras {max_linhas_exibir} linhas.** Total de problemas: {len(df_problemas)}")
    
    # 3. AN√ÅLISE POR RESPONS√ÅVEL
    if "Respons√°vel" in df_problemas.columns:
        responsaveis_problemas = df_problemas.groupby('Respons√°vel').size().sort_values(ascending=False)
        
        if len(responsaveis_problemas) > 1:
            st.markdown("### üë• **Problemas por Respons√°vel:**")
            
            col1, col2 = st.columns([2, 3])
            
            with col1:
                for responsavel, qtd in responsaveis_problemas.head(5).items():
                    st.write(f"‚Ä¢ **{responsavel}**: {qtd} problema{'s' if qtd > 1 else ''}")
                    
                if len(responsaveis_problemas) > 5:
                    st.write(f"‚Ä¢ ... e mais {len(responsaveis_problemas) - 5} respons√°veis")
            
            with col2:
                # Gr√°fico simples de problemas por respons√°vel
                st.bar_chart(responsaveis_problemas.head(10))
    
    st.divider()
    
    # 4. GUIA DE CORRE√á√ÉO DETALHADA
    st.markdown("### üí° **Guia de Corre√ß√£o:**")
    
    with st.expander("üìñ Como corrigir cada tipo de problema", expanded=True):
        
        guia_correcao = {
            "VAZIO": {
                "emoji": "üî¥",
                "problema": "C√©lulas de data em branco",
                "solucao": "Preencha com a data correta no formato DD/MM/AAAA",
                "exemplo": "Exemplo: 15/03/2024"
            },
            "FORMATO": {
                "emoji": "üü†", 
                "problema": "Formato de data inv√°lido",
                "solucao": "Use apenas n√∫meros no formato DD/MM/AAAA",
                "exemplo": "‚úÖ 15/03/2024  ‚ùå '15 de mar√ßo' ou 'mar√ßo/2024'"
            },
            "IMPOSS√çVEL": {
                "emoji": "üü£",
                "problema": "Datas que n√£o existem no calend√°rio",
                "solucao": "Verifique dia e m√™s (ex: fevereiro n√£o tem 30 dias)",
                "exemplo": "‚úÖ 28/02/2024  ‚ùå 31/02/2024"
            },
            "FUTURO": {
                "emoji": "üü°",
                "problema": "Datas muito distantes no futuro",
                "solucao": "Verifique se o ano est√° correto",
                "exemplo": "Se for 2024, n√£o use 2034"
            },
            "ANTIGA": {
                "emoji": "üü§",
                "problema": "Datas muito antigas (antes de 2020)",
                "solucao": "Confirme se o ano est√° correto",
                "exemplo": "Se for 2024, n√£o use 2014"
            }
        }
        
        # Mostrar apenas as dicas para os tipos de problema encontrados
        tipos_encontrados = df_problemas['Tipo Problema'].unique()
        
        for tipo in tipos_encontrados:
            if tipo in guia_correcao:
                info = guia_correcao[tipo]
                
                st.markdown(f"""
                **{info['emoji']} {tipo}:**
                - **Problema:** {info['problema']}
                - **Solu√ß√£o:** {info['solucao']}
                - **{info['exemplo']}**
                """)
    
    # 5. BOT√ÉO DE DOWNLOAD DO RELAT√ìRIO
    with st.expander("üíæ Baixar relat√≥rio de problemas"):
        if st.button("üì• Gerar Excel com problemas encontrados"):
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df_problemas.to_excel(writer, index=False, sheet_name="Problemas_Datas")
            buffer.seek(0)
            
            st.download_button(
                label="‚¨áÔ∏è Baixar relat√≥rio de problemas",
                data=buffer.getvalue(),
                file_name=f"problemas_datas_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

# ===========================
# VALIDA√á√ÉO SUPER RIGOROSA - v2.2.3
# ===========================
def validar_dados_enviados(df):
    """
    üîç VALIDA√á√ÉO SUPER RIGOROSA DOS DADOS ENVIADOS - v2.2.3
    
    QUALQUER problema de data agora IMPEDE consolida√ß√£o:
    - VAZIO, FORMATO, IMPOSS√çVEL, FUTURO, ANTIGA
    
    Zero toler√¢ncia para garantir 100% qualidade dos dados
    """
    erros = []
    avisos = []
    linhas_invalidas_detalhes = []
    
    # Validar se DataFrame n√£o est√° vazio
    if df.empty:
        erros.append("‚ùå A planilha est√° vazia")
        return erros, avisos, linhas_invalidas_detalhes
    
    # Validar se existe coluna RESPONS√ÅVEL
    if "RESPONS√ÅVEL" not in df.columns:
        erros.append("‚ö†Ô∏è A planilha deve conter uma coluna 'RESPONS√ÅVEL'")
        avisos.append("üìã Certifique-se de que sua planilha tenha uma coluna chamada 'RESPONS√ÅVEL'")
    else:
        # Validar se h√° respons√°veis v√°lidos
        responsaveis_validos = df["RESPONS√ÅVEL"].notna().sum()
        if responsaveis_validos == 0:
            erros.append("‚ùå Nenhum respons√°vel v√°lido encontrado na coluna 'RESPONS√ÅVEL'")
        else:
            # Mostrar respons√°veis √∫nicos encontrados
            responsaveis_unicos = df["RESPONS√ÅVEL"].dropna().unique()
            if len(responsaveis_unicos) > 0:
                avisos.append(f"üë• Respons√°veis encontrados: {', '.join(responsaveis_unicos[:5])}")
                if len(responsaveis_unicos) > 5:
                    avisos.append(f"... e mais {len(responsaveis_unicos) - 5} respons√°veis")
    
    # NOVA VALIDA√á√ÉO SUPER RIGOROSA DE DATAS - v2.2.3
    if "DATA" not in df.columns:
        erros.append("‚ö†Ô∏è A planilha deve conter uma coluna 'DATA'")
        avisos.append("üìã Lembre-se: o arquivo deve ter uma aba chamada 'Vendas CTs' com as colunas 'DATA' e 'RESPONS√ÅVEL'")
    else:
        # Executar valida√ß√£o detalhada de datas
        problemas_datas = validar_datas_detalhadamente(df)
        
        if problemas_datas:
            # üÜï NOVA L√ìGICA v2.2.3: QUALQUER problema = ERRO
            erros.append(f"‚ùå {len(problemas_datas)} problemas de data encontrados - CONSOLIDA√á√ÉO BLOQUEADA")
            erros.append("üîß √â OBRIGAT√ìRIO corrigir TODOS os problemas antes de enviar")
            erros.append("üìã Revise sua planilha e corrija todas as datas inv√°lidas")
            
            # Categorizar e detalhar tipos de problemas
            tipos_problema = {}
            for problema in problemas_datas:
                tipo = problema["Tipo Problema"]
                tipos_problema[tipo] = tipos_problema.get(tipo, 0) + 1
            
            # Criar mensagem detalhada dos problemas
            detalhes_problemas = []
            emoji_map = {
                "VAZIO": "üî¥",
                "FORMATO": "üü†", 
                "IMPOSS√çVEL": "üü£",
                "FUTURO": "üü°",
                "ANTIGA": "üü§"
            }
            
            for tipo, qtd in tipos_problema.items():
                emoji = emoji_map.get(tipo, "‚ùå")
                detalhes_problemas.append(f"{emoji} {tipo}: {qtd} linha{'s' if qtd > 1 else ''}")
            
            erros.append(f"üìä Problemas por tipo: {', '.join(detalhes_problemas)}")
            
            # Mensagem espec√≠fica baseada nos tipos de problema
            if "VAZIO" in tipos_problema:
                erros.append("üî¥ CR√çTICO: Existem datas em branco - preencha todas as datas")
            if "FORMATO" in tipos_problema:
                erros.append("üü† CR√çTICO: Existem formatos inv√°lidos - use formato DD/MM/AAAA")
            if "IMPOSS√çVEL" in tipos_problema:
                erros.append("üü£ CR√çTICO: Existem datas imposs√≠veis - verifique dias e meses")
            if "FUTURO" in tipos_problema:
                erros.append("üü° ATEN√á√ÉO: Existem datas no futuro - confirme se est√£o corretas")
            if "ANTIGA" in tipos_problema:
                erros.append("üü§ ATEN√á√ÉO: Existem datas muito antigas - confirme se est√£o corretas")
            
            # Manter detalhes para exibi√ß√£o na interface
            linhas_invalidas_detalhes = problemas_datas
            
        else:
            avisos.append("‚úÖ Todas as datas est√£o v√°lidas e consistentes!")
    
    # Validar duplicatas na planilha enviada (apenas aviso - n√£o impede mais)
    if not df.empty and "DATA" in df.columns:
        df_temp = df.copy()
        df_temp["DATA"] = pd.to_datetime(df_temp["DATA"], errors="coerce")
        df_temp = df_temp.dropna(subset=["DATA"])
        
        if not df_temp.empty:
            duplicatas = df_temp.duplicated(subset=["DATA"], keep=False).sum()
            if duplicatas > 0:
                avisos.append(f"‚ö†Ô∏è {duplicatas} linhas com datas duplicadas na planilha")
    
    return erros, avisos, linhas_invalidas_detalhes

# ===========================
# FUN√á√ïES DE CONSOLIDA√á√ÉO CORRIGIDAS - v2.2.4
# ===========================

def baixar_arquivo_consolidado(token):
    """Baixa o arquivo consolidado existente da pasta espec√≠fica"""
    consolidado_nome = "Reports_Geral_Consolidado.xlsx"
    url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{consolidado_nome}:/content"
    headers = {"Authorization": f"Bearer {token}"}
    
    try:
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            df_consolidado = pd.read_excel(BytesIO(response.content))
            df_consolidado.columns = df_consolidado.columns.str.strip().str.upper()
            
            # Log de debug
            logger.info(f"‚úÖ Arquivo consolidado baixado: {len(df_consolidado)} registros")
            if not df_consolidado.empty:
                responsaveis_existentes = df_consolidado['RESPONS√ÅVEL'].dropna().unique()
                logger.info(f"üìä Respons√°veis no consolidado: {responsaveis_existentes}")
            
            return df_consolidado, True
        else:
            logger.info("üìÑ Arquivo consolidado n√£o existe - ser√° criado novo")
            return pd.DataFrame(), False
            
    except Exception as e:
        logger.error(f"Erro ao baixar arquivo consolidado: {e}")
        return pd.DataFrame(), False

def criar_backup_substituicoes(df_consolidado, detalhes_operacao, token):
    """Cria backup dos registros que foram substitu√≠dos na pasta de backups"""
    try:
        # Extrair apenas opera√ß√µes de remo√ß√£o
        removidos = [d for d in detalhes_operacao if d["Opera√ß√£o"] == "REMOVIDO"]
        
        if not removidos:
            return
        
        # Identificar os registros que foram removidos
        registros_backup = []
        
        for item in removidos:
            responsavel = item["Respons√°vel"]
            data_str = item["Data"]
            data = pd.to_datetime(data_str, format="%d/%m/%Y").date()
            
            mask = (
                (df_consolidado["DATA"].dt.date == data) &
                (df_consolidado["RESPONS√ÅVEL"].astype(str).str.strip().str.upper() == str(responsavel).strip().upper())
            )
            
            registros_removidos = df_consolidado[mask]
            if not registros_removidos.empty:
                registros_backup.append(registros_removidos)
        
        if registros_backup:
            df_backup = pd.concat(registros_backup, ignore_index=True)
            
            # Adicionar metadados de backup
            df_backup["BACKUP_TIMESTAMP"] = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
            df_backup["BACKUP_MOTIVO"] = "Substitui√ß√£o por novo envio"
            df_backup["APP_VERSION"] = APP_VERSION
            
            # Salvar backup NA NOVA PASTA
            timestamp = datetime.now().strftime('%d-%m-%Y_%Hh%M')
            nome_backup = f"Backups_Substituicoes/backup_substituicao_{timestamp}.xlsx"
            
            buffer = BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df_backup.to_excel(writer, index=False, sheet_name="Registros Substituidos")
            buffer.seek(0)
            
            # USAR NOVA FUN√á√ÉO COM TIPO "backup"
            sucesso, _, _ = upload_onedrive(nome_backup, buffer.read(), token, "backup")
            if sucesso:
                st.info(f"üíæ Backup dos dados substitu√≠dos criado: {PASTA_ENVIOS_BACKUPS}/{nome_backup}")
            else:
                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel criar backup dos dados substitu√≠dos")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao criar backup: {e}")
        logger.error(f"Erro no backup: {e}")

def verificar_seguranca_consolidacao(df_consolidado, df_novo, df_final):
    """
    üõ°Ô∏è VERIFICA√á√ÉO DE SEGURAN√áA CR√çTICA - v2.2.4
    
    Garante que nenhum respons√°vel foi perdido inadvertidamente durante a consolida√ß√£o
    """
    try:
        # Obter respons√°veis √∫nicos de cada DataFrame
        responsaveis_antes = set(df_consolidado['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique()) if not df_consolidado.empty else set()
        responsaveis_novos = set(df_novo['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique())
        responsaveis_depois = set(df_final['RESPONS√ÅVEL'].dropna().astype(str).str.strip().str.upper().unique())
        
        # Log detalhado
        logger.info(f"üõ°Ô∏è VERIFICA√á√ÉO DE SEGURAN√áA:")
        logger.info(f"   Respons√°veis ANTES: {responsaveis_antes}")
        logger.info(f"   Respons√°veis NOVOS: {responsaveis_novos}")
        logger.info(f"   Respons√°veis DEPOIS: {responsaveis_depois}")
        
        # Calcular respons√°veis esperados (uni√£o dos existentes + novos)
        responsaveis_esperados = responsaveis_antes.union(responsaveis_novos)
        responsaveis_perdidos = responsaveis_esperados - responsaveis_depois
        
        # Verificar se algum respons√°vel foi perdido
        if responsaveis_perdidos:
            error_msg = f"Respons√°veis perdidos durante consolida√ß√£o: {', '.join(responsaveis_perdidos)}"
            logger.error(f"‚ùå ERRO CR√çTICO: {error_msg}")
            return False, error_msg
        
        # Verificar se todos os respons√°veis antigos ainda existem (exceto os que foram substitu√≠dos por novos)
        for resp in responsaveis_antes:
            if resp not in responsaveis_novos:  # N√£o foi enviado agora
                if resp not in responsaveis_depois:  # Mas sumiu do final
                    error_msg = f"Respons√°vel '{resp}' foi removido sem justificativa"
                    logger.error(f"‚ùå ERRO: {error_msg}")
                    return False, error_msg
        
        # Verifica√ß√µes de contagem por respons√°vel (apenas para os que n√£o foram substitu√≠dos)
        for resp in responsaveis_antes:
            if resp not in responsaveis_novos:  # Respons√°vel n√£o foi re-enviado
                # Contar registros antes e depois
                count_antes = (df_consolidado['RESPONS√ÅVEL'].astype(str).str.strip().str.upper() == resp).sum()
                count_depois = (df_final['RESPONS√ÅVEL'].astype(str).str.strip().str.upper() == resp).sum()
                
                if count_depois < count_antes:
                    error_msg = f"Respons√°vel '{resp}' perdeu registros: tinha {count_antes}, ficou com {count_depois}"
                    logger.warning(f"‚ö†Ô∏è ATEN√á√ÉO: {error_msg}")
                    # N√£o retornar erro aqui, pode ser leg√≠timo em alguns casos
        
        logger.info(f"‚úÖ VERIFICA√á√ÉO DE SEGURAN√áA PASSOU!")
        logger.info(f"   Total antes: {len(responsaveis_antes)} respons√°veis")
        logger.info(f"   Total novos: {len(responsaveis_novos)} respons√°veis") 
        logger.info(f"   Total depois: {len(responsaveis_depois)} respons√°veis")
        
        return True, f"Verifica√ß√£o passou: {len(responsaveis_depois)} respons√°veis mantidos"
        
    except Exception as e:
        error_msg = f"Erro durante verifica√ß√£o de seguran√ßa: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        return False, error_msg

def comparar_e_atualizar_registros(df_consolidado, df_novo):
    """
    üîß L√ìGICA DE CONSOLIDA√á√ÉO CORRIGIDA - v2.2.4
    
    Para cada combina√ß√£o RESPONS√ÅVEL + DATA no arquivo enviado:
    
    1. SE N√ÉO EXISTE na planilha consolidada:
       ‚ûï INSERE todos os novos registros (SEM TOCAR nos existentes)
       
    2. SE J√Å EXISTE na planilha consolidada:
       üóëÔ∏è REMOVE apenas os registros antigos DESSA COMBINA√á√ÉO ESPEC√çFICA
       ‚ûï INSERE todos os novos registros dessa combina√ß√£o
    
    CORRE√á√ÉO CR√çTICA: Nunca remove registros de outros respons√°veis ou outras datas!
    """
    registros_inseridos = 0
    registros_substituidos = 0
    registros_removidos = 0
    detalhes_operacao = []
    combinacoes_novas = 0
    combinacoes_existentes = 0
    
    # Log inicial
    logger.info(f"üîß INICIANDO CONSOLIDA√á√ÉO:")
    logger.info(f"   Consolidado atual: {len(df_consolidado)} registros")
    logger.info(f"   Novo arquivo: {len(df_novo)} registros")
    
    if df_consolidado.empty:
        # Primeiro envio - todos os registros s√£o novos
        df_final = df_novo.copy()
        registros_inseridos = len(df_novo)
        
        # Contar combina√ß√µes √∫nicas
        combinacoes_unicas = df_novo.groupby(['RESPONS√ÅVEL', df_novo['DATA'].dt.date]).size()
        combinacoes_novas = len(combinacoes_unicas)
        
        logger.info(f"‚úÖ PRIMEIRA CONSOLIDA√á√ÉO: {registros_inseridos} registros inseridos")
        
        for _, row in df_novo.iterrows():
            detalhes_operacao.append({
                "Opera√ß√£o": "INSERIDO",
                "Respons√°vel": row["RESPONS√ÅVEL"],
                "Data": row["DATA"].strftime("%d/%m/%Y"),
                "Motivo": "Primeira consolida√ß√£o - arquivo vazio"
            })
        
        return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao, combinacoes_novas, combinacoes_existentes
    
    # üîß CORRE√á√ÉO: Garantir que as colunas existem no consolidado
    colunas = df_novo.columns.tolist()
    for col in colunas:
        if col not in df_consolidado.columns:
            df_consolidado[col] = None
            logger.info(f"‚ûï Coluna '{col}' adicionada ao consolidado")
    
    # üîß CORRE√á√ÉO CR√çTICA: Come√ßar com uma C√ìPIA COMPLETA do consolidado
    df_final = df_consolidado.copy()
    registros_inicial = len(df_final)
    
    logger.info(f"üîç Estado inicial do consolidado:")
    if not df_final.empty:
        responsaveis_iniciais = df_final['RESPONS√ÅVEL'].dropna().unique()
        logger.info(f"   Respons√°veis: {responsaveis_iniciais}")
        logger.info(f"   Total de registros: {len(df_final)}")
    
    # Agrupar registros novos por RESPONS√ÅVEL e DATA
    grupos_novos = df_novo.groupby(['RESPONS√ÅVEL', df_novo['DATA'].dt.date])
    
    logger.info(f"üìä Processando {len(grupos_novos)} combina√ß√µes √∫nicas de Respons√°vel+Data")
    
    for (responsavel, data_grupo), grupo_df in grupos_novos:
        if pd.isna(responsavel) or str(responsavel).strip() == '':
            logger.warning(f"‚ö†Ô∏è Pulando respons√°vel inv√°lido: {responsavel}")
            continue
        
        logger.info(f"üîç Processando: '{responsavel}' em {data_grupo} ({len(grupo_df)} registros)")
        
        # üîß CORRE√á√ÉO: Buscar registros existentes APENAS para este respons√°vel e data ESPEC√çFICOS
        mask_existente = (
            (df_final["DATA"].dt.date == data_grupo) &
            (df_final["RESPONS√ÅVEL"].astype(str).str.strip().str.upper() == str(responsavel).strip().upper())
        )
        
        registros_existentes = df_final[mask_existente]
        total_antes_operacao = len(df_final)
        
        logger.info(f"   üìã Encontrados {len(registros_existentes)} registros existentes para esta combina√ß√£o")
        
        if not registros_existentes.empty:
            # ===== CEN√ÅRIO 2: SUBSTITUI√á√ÉO APENAS DA COMBINA√á√ÉO ESPEC√çFICA =====
            num_removidos = len(registros_existentes)
            
            logger.info(f"   üîÑ SUBSTITUI√á√ÉO: Removendo {num_removidos} registros antigos")
            
            # üîß CORRE√á√ÉO CR√çTICA: Remove APENAS os registros dessa combina√ß√£o espec√≠fica
            df_final = df_final[~mask_existente]
            
            total_depois_remocao = len(df_final)
            registros_removidos += num_removidos
            combinacoes_existentes += 1
            
            logger.info(f"   ‚úÖ Removidos {num_removidos} registros. Total: {total_antes_operacao} -> {total_depois_remocao}")
            
            # Verifica√ß√£o de seguran√ßa na remo√ß√£o
            if total_depois_remocao != (total_antes_operacao - num_removidos):
                logger.error(f"‚ùå ERRO NA REMO√á√ÉO! Esperado: {total_antes_operacao - num_removidos}, Atual: {total_depois_remocao}")
            
            # Adicionar detalhes da remo√ß√£o
            detalhes_operacao.append({
                "Opera√ß√£o": "REMOVIDO",
                "Respons√°vel": responsavel,
                "Data": data_grupo.strftime("%d/%m/%Y"),
                "Motivo": f"Substitui√ß√£o: {num_removidos} registro(s) antigo(s) removido(s)"
            })
            
            registros_substituidos += len(grupo_df)
            operacao_tipo = "SUBSTITU√çDO"
            motivo = f"Substitui√ß√£o completa: {len(grupo_df)} novo(s) registro(s)"
            
        else:
            # ===== CEN√ÅRIO 1: INSER√á√ÉO DE NOVOS DADOS =====
            logger.info(f"   ‚ûï NOVA COMBINA√á√ÉO: Adicionando {len(grupo_df)} registros")
            registros_inseridos += len(grupo_df)
            combinacoes_novas += 1
            operacao_tipo = "INSERIDO"
            motivo = f"Nova combina√ß√£o: {len(grupo_df)} registro(s) inserido(s)"
        
        # üîß CORRE√á√ÉO: Inserir novos registros (tanto para inser√ß√£o quanto substitui√ß√£o)
        total_antes_insercao = len(df_final)
        df_final = pd.concat([df_final, grupo_df], ignore_index=True)
        total_depois_insercao = len(df_final)
        
        logger.info(f"   ‚úÖ Inseridos {len(grupo_df)} registros. Total: {total_antes_insercao} -> {total_depois_insercao}")
        
        # Adicionar detalhes da opera√ß√£o
        detalhes_operacao.append({
            "Opera√ß√£o": operacao_tipo,
            "Respons√°vel": responsavel,
            "Data": data_grupo.strftime("%d/%m/%Y"),
            "Motivo": motivo
        })
    
    # Log final detalhado
    logger.info(f"üèÅ CONSOLIDA√á√ÉO FINALIZADA:")
    logger.info(f"   Total inicial: {registros_inicial}")
    logger.info(f"   Total final: {len(df_final)}")
    logger.info(f"   Inseridos: {registros_inseridos}")
    logger.info(f"   Substitu√≠dos: {registros_substituidos}")
    logger.info(f"   Removidos: {registros_removidos}")
    
    if not df_final.empty:
        responsaveis_finais = df_final['RESPONS√ÅVEL'].dropna().unique()
        logger.info(f"   Respons√°veis finais: {responsaveis_finais}")
    
    return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao, combinacoes_novas, combinacoes_existentes

def analise_pre_consolidacao(df_consolidado, df_novo):
    """
    üìä AN√ÅLISE PR√â-CONSOLIDA√á√ÉO - v2.2.4
    
    Mostra ao usu√°rio exatamente o que vai acontecer antes de executar
    """
    try:
        # Dados b√°sicos
        responsaveis_no_envio = df_novo["RESPONS√ÅVEL"].dropna().unique()
        periodo_min = df_novo["DATA"].min().strftime("%d/%m/%Y")
        periodo_max = df_novo["DATA"].max().strftime("%d/%m/%Y")
        
        combinacoes_envio = df_novo.groupby(['RESPONS√ÅVEL', df_novo['DATA'].dt.date]).size()
        total_combinacoes = len(combinacoes_envio)
        
        st.markdown("### üîç **An√°lise Pr√©-Consolida√ß√£o**")
        
        # Informa√ß√µes b√°sicas
        col1, col2, col3 = st.columns(3)
        with col1:
            st.info(f"üë• **Respons√°veis no envio:**\n{', '.join(responsaveis_no_envio)}")
        with col2:
            st.info(f"üìÖ **Per√≠odo:**\n{periodo_min} at√© {periodo_max}")
        with col3:
            st.info(f"üìä **Combina√ß√µes √∫nicas:**\n{total_combinacoes} (Respons√°vel + Data)")
        
        # An√°lise de impacto se houver dados existentes
        if not df_consolidado.empty:
            registros_para_consolidar = 0
            registros_para_alterar = 0
            registros_que_serao_removidos = 0
            
            # Analisar cada combina√ß√£o
            for responsavel in responsaveis_no_envio:
                datas_envio = df_novo[df_novo["RESPONS√ÅVEL"] == responsavel]["DATA"].dt.date.unique()
                
                for data in datas_envio:
                    # Buscar conflitos no consolidado
                    mask_conflito = (
                        (df_consolidado["DATA"].dt.date == data) &
                        (df_consolidado["RESPONS√ÅVEL"].astype(str).str.strip().str.upper() == str(responsavel).strip().upper())
                    )
                    
                    registros_envio = len(df_novo[
                        (df_novo["RESPONS√ÅVEL"] == responsavel) & 
                        (df_novo["DATA"].dt.date == data)
                    ])
                    
                    if mask_conflito.any():
                        # Haver√° substitui√ß√£o
                        registros_existentes = mask_conflito.sum()
                        registros_que_serao_removidos += registros_existentes
                        registros_para_alterar += registros_envio
                    else:
                        # Ser√° nova inser√ß√£o
                        registros_para_consolidar += registros_envio
            
            # Calcular total esperado
            total_atual = len(df_consolidado)
            total_enviado = len(df_novo)
            total_esperado = total_atual - registros_que_serao_removidos + total_enviado
            
            # Mostrar m√©tricas de impacto
            st.markdown("### üìà **Impacto da Consolida√ß√£o**")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä Registros Atuais", f"{total_atual:,}")
            with col2:
                st.metric("üì§ Registros Enviados", f"{total_enviado:,}")
            with col3:
                st.metric("üóëÔ∏è Ser√£o Removidos", f"{registros_que_serao_removidos:,}")
            with col4:
                st.metric("üéØ Total Esperado", f"{total_esperado:,}")
            
            # Mostrar an√°lise de opera√ß√µes
            if registros_para_consolidar > 0 and registros_para_alterar == 0:
                st.success(f"‚úÖ **{registros_para_consolidar} registro(s) ser√£o CONSOLIDADOS** (dados novos)")
                st.info("‚ÑπÔ∏è Nenhum registro existente ser√° alterado")
                
            elif registros_para_alterar > 0 and registros_para_consolidar == 0:
                st.warning(f"üîÑ **{registros_para_alterar} registro(s) ser√£o ALTERADOS** (substituindo dados existentes)")
                st.info("‚ÑπÔ∏è Nenhum registro novo ser√° adicionado")
                
            elif registros_para_consolidar > 0 and registros_para_alterar > 0:
                col1, col2 = st.columns(2)
                with col1:
                    st.success(f"‚úÖ **{registros_para_consolidar} registro(s) ser√£o CONSOLIDADOS**")
                    st.caption("(dados completamente novos)")
                with col2:
                    st.warning(f"üîÑ **{registros_para_alterar} registro(s) ser√£o ALTERADOS**")
                    st.caption("(substituindo dados existentes)")
            
            # Aviso especial para substitui√ß√µes
            if registros_que_serao_removidos > 0:
                st.warning(f"‚ö†Ô∏è **{registros_que_serao_removidos} registros existentes ser√£o substitu√≠dos** pelos novos dados")
                st.info("üíæ Um backup autom√°tico ser√° criado dos dados substitu√≠dos")
        else:
            st.success(f"‚úÖ **{len(df_novo)} registro(s) ser√£o CONSOLIDADOS** (primeira consolida√ß√£o)")
            
        return True
        
    except Exception as e:
        st.error(f"‚ùå Erro na an√°lise pr√©-consolida√ß√£o: {e}")
        logger.error(f"Erro na an√°lise pr√©-consolida√ß√£o: {e}")
        return False

def salvar_arquivo_enviado(df, nome_arquivo_original, token):
    """Salva o arquivo enviado com o nome original na nova pasta de enviados"""
    try:
        if not df.empty and "DATA" in df.columns:
            data_base = df["DATA"].min()
            nome_pasta = f"Relatorios_Enviados/{data_base.strftime('%Y-%m')}"
            timestamp = datetime.now().strftime('%d-%m-%Y_%Hh%M')
            
            # Usar nome original do arquivo com timestamp
            nome_sem_extensao = os.path.splitext(nome_arquivo_original)[0]
            nome_arquivo = f"{nome_pasta}/{nome_sem_extensao}_{timestamp}_v{APP_VERSION}.xlsx"
            
            # Salvar arquivo
            buffer_envio = BytesIO()
            with pd.ExcelWriter(buffer_envio, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name="Vendas CTs")
            buffer_envio.seek(0)
            
            # USAR NOVA FUN√á√ÉO COM TIPO "enviado"
            sucesso, _, _ = upload_onedrive(nome_arquivo, buffer_envio.read(), token, "enviado")
            if sucesso:
                st.info(f"üíæ Arquivo salvo como: {PASTA_ENVIOS_BACKUPS}/{nome_arquivo}")
            else:
                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel salvar c√≥pia do arquivo enviado")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel salvar c√≥pia do arquivo: {e}")
        logger.error(f"Erro ao salvar arquivo enviado: {e}")

# ===========================
# NOVA FUN√á√ÉO DE CONSOLIDA√á√ÉO COM FEEDBACK MELHORADO - v2.2.4
# ===========================

def processar_consolidacao_com_lock(df_novo, nome_arquivo, token):
    """
    üîß VERS√ÉO CORRIGIDA E MELHORADA - v2.2.4
    
    Consolida√ß√£o com sistema de lock, verifica√ß√µes de seguran√ßa e feedback visual aprimorado
    """
    session_id = gerar_id_sessao()
    
    # Container para status em tempo real
    status_container = st.empty()
    progress_container = st.empty()
    
    try:
        # Status inicial
        status_container.info("üîÑ **Iniciando processo de consolida√ß√£o...**")
        
        # 1. Verificar se sistema est√° livre
        sistema_ocupado, lock_data = verificar_lock_existente(token)
        if sistema_ocupado:
            status_container.error("üîí Sistema ocupado! Outro usu√°rio est√° fazendo consolida√ß√£o.")
            return False
        
        # 2. Criar lock
        status_container.info("üîí **Bloqueando sistema para consolida√ß√£o...**")
        progress_container.progress(10)
        
        lock_criado, session_lock = criar_lock(token, "Consolida√ß√£o de planilha")
        
        if not lock_criado:
            status_container.error("‚ùå N√£o foi poss√≠vel bloquear o sistema. Tente novamente.")
            return False
        
        status_container.success(f"‚úÖ **Sistema bloqueado com sucesso!** (ID: {session_lock})")
        progress_container.progress(15)
        
        # 3. Atualizar status: baixando arquivo
        atualizar_status_lock(token, session_lock, "BAIXANDO_ARQUIVO", "Baixando arquivo consolidado")
        status_container.info("üì• **Baixando arquivo consolidado existente...**")
        progress_container.progress(25)
        
        # 4. Baixar arquivo consolidado existente
        df_consolidado, arquivo_existe = baixar_arquivo_consolidado(token)
        
        if arquivo_existe:
            status_container.info(f"üìÇ **Arquivo consolidado carregado** ({len(df_consolidado):,} registros)")
        else:
            status_container.info("üìÇ **Criando novo arquivo consolidado**")
        
        progress_container.progress(35)

        # 5. Atualizar status: preparando dados
        atualizar_status_lock(token, session_lock, "PREPARANDO_DADOS", "Validando e preparando dados")
        status_container.info("üîß **Preparando e validando dados...**")
        
        # 6. Preparar dados novos
        df_novo = df_novo.copy()
        df_novo.columns = df_novo.columns.str.strip().str.upper()
        
        # Converter datas e remover linhas inv√°lidas
        df_novo["DATA"] = pd.to_datetime(df_novo["DATA"], errors="coerce")
        linhas_invalidas = df_novo["DATA"].isna().sum()
        df_novo = df_novo.dropna(subset=["DATA"])

        if df_novo.empty:
            status_container.error("‚ùå **Nenhum registro v√°lido para consolidar**")
            remover_lock(token, session_lock)
            return False

        if linhas_invalidas > 0:
            status_container.warning(f"üßπ **{linhas_invalidas} linhas com datas inv√°lidas foram removidas**")

        progress_container.progress(45)

        # 7. An√°lise pr√©-consolida√ß√£o
        status_container.info("üìä **Realizando an√°lise pr√©-consolida√ß√£o...**")
        analise_ok = analise_pre_consolidacao(df_consolidado, df_novo)
        
        if not analise_ok:
            status_container.error("‚ùå **Erro na an√°lise pr√©-consolida√ß√£o**")
            remover_lock(token, session_lock)
            return False
        
        progress_container.progress(55)

        # 8. Atualizar status: processando consolida√ß√£o
        atualizar_status_lock(token, session_lock, "CONSOLIDANDO", f"Processando {len(df_novo)} registros")
        status_container.info("üîÑ **Processando consolida√ß√£o (l√≥gica corrigida v2.2.4)...**")
        progress_container.progress(65)
        
        # 9. Processar consolida√ß√£o
        df_final, inseridos, substituidos, removidos, detalhes, novas_combinacoes, combinacoes_existentes = comparar_e_atualizar_registros(
            df_consolidado, df_novo
        )
        
        progress_container.progress(75)

        # 10. VERIFICA√á√ÉO DE SEGURAN√áA CR√çTICA
        status_container.info("üõ°Ô∏è **Executando verifica√ß√£o de seguran√ßa...**")
        verificacao_ok, msg_verificacao = verificar_seguranca_consolidacao(df_consolidado, df_novo, df_final)
        
        if not verificacao_ok:
            status_container.error(f"‚ùå **ERRO DE SEGURAN√áA:** {msg_verificacao}")
            st.error("üõë **Consolida√ß√£o cancelada para proteger os dados!**")
            remover_lock(token, session_lock)
            return False
        else:
            status_container.success(f"‚úÖ **Verifica√ß√£o de seguran√ßa passou:** {msg_verificacao}")

        # 11. Ordenar por data e respons√°vel
        df_final = df_final.sort_values(["DATA", "RESPONS√ÅVEL"], na_position='last').reset_index(drop=True)
        progress_container.progress(80)
        
        # 12. Atualizar status: criando backups
        if removidos > 0:
            atualizar_status_lock(token, session_lock, "CRIANDO_BACKUP", f"Backup de {removidos} registros substitu√≠dos")
            status_container.info("üíæ **Criando backup dos dados substitu√≠dos...**")
            criar_backup_substituicoes(df_consolidado, detalhes, token)
        
        # 13. Atualizar status: salvando arquivo enviado
        atualizar_status_lock(token, session_lock, "SALVANDO_ENVIADO", "Salvando c√≥pia do arquivo enviado")
        status_container.info("üíæ **Salvando c√≥pia do arquivo enviado...**")
        salvar_arquivo_enviado(df_novo, nome_arquivo, token)
        
        progress_container.progress(85)
        
        # 14. Atualizar status: upload final
        atualizar_status_lock(token, session_lock, "UPLOAD_FINAL", "Salvando arquivo consolidado")
        status_container.info("üì§ **Salvando arquivo consolidado final...**")
        
        # 15. Salvar arquivo consolidado
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df_final.to_excel(writer, index=False, sheet_name="Vendas CTs")
        buffer.seek(0)
        
        consolidado_nome = "Reports_Geral_Consolidado.xlsx"
        sucesso, status_code, resposta = upload_onedrive(consolidado_nome, buffer.read(), token, "consolidado")

        progress_container.progress(95)

        # 16. Remover lock SEMPRE (sucesso ou erro)
        remover_lock(token, session_lock)
        progress_container.progress(100)
        
        if sucesso:
            # Limpar containers de status
            status_container.empty()
            progress_container.empty()
            
            # Exibir resultado final
            st.success("üéâ **CONSOLIDA√á√ÉO REALIZADA COM SUCESSO!**")
            st.success("üîì **Sistema liberado e dispon√≠vel para outros usu√°rios**")
            
            # Mostrar localiza√ß√£o dos arquivos
            with st.expander("üìç Localiza√ß√£o dos Arquivos", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"üìä **Arquivo Consolidado:**\n`{PASTA_CONSOLIDADO}/Reports_Geral_Consolidado.xlsx`")
                with col2:
                    st.info(f"üíæ **Backups e Envios:**\n`{PASTA_ENVIOS_BACKUPS}/`")
            
            # M√©tricas de resultado
            st.markdown("### üìà **Resultado da Consolida√ß√£o**")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä Total Final", f"{len(df_final):,}")
            with col2:
                st.metric("‚ûï Inseridos", f"{inseridos}")
            with col3:
                st.metric("üîÑ Substitu√≠dos", f"{substituidos}")
            with col4:
                st.metric("üóëÔ∏è Removidos", f"{removidos}")
            
            # M√©tricas de combina√ß√µes
            if novas_combinacoes > 0 or combinacoes_existentes > 0:
                st.markdown("### üìà **An√°lise de Combina√ß√µes (Respons√°vel + Data)**")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üÜï Novas Combina√ß√µes", novas_combinacoes, 
                             help="Combina√ß√µes de Respons√°vel + Data que n√£o existiam antes")
                with col2:
                    st.metric("üîÑ Combina√ß√µes Atualizadas", combinacoes_existentes,
                             help="Combina√ß√µes que j√° existiam e foram substitu√≠das")
                with col3:
                    total_processadas = novas_combinacoes + combinacoes_existentes
                    st.metric("üìä Total Processado", total_processadas,
                             help="Total de combina√ß√µes √∫nicas processadas")
                
                if novas_combinacoes > 0:
                    st.success(f"üéâ **{novas_combinacoes} nova(s) combina√ß√£o(√µes) adicionada(s)** - Dados completamente novos!")
                if combinacoes_existentes > 0:
                    st.info(f"üîÑ **{combinacoes_existentes} combina√ß√£o(√µes) atualizada(s)** - Dados existentes foram substitu√≠dos pelos novos!")
            
            # Detalhes das opera√ß√µes
            if detalhes:
                with st.expander("üìã Detalhes das Opera√ß√µes", expanded=removidos > 0):
                    df_detalhes = pd.DataFrame(detalhes)
                    
                    operacoes_inseridas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'INSERIDO']
                    operacoes_substituidas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'SUBSTITU√çDO']
                    operacoes_removidas = df_detalhes[df_detalhes['Opera√ß√£o'] == 'REMOVIDO']
                    
                    if not operacoes_inseridas.empty:
                        st.markdown("#### ‚ûï **Registros Inseridos (Novos)**")
                        st.dataframe(operacoes_inseridas, use_container_width=True, hide_index=True)
                    
                    if not operacoes_substituidas.empty:
                        st.markdown("#### üîÑ **Registros Substitu√≠dos**")
                        st.dataframe(operacoes_substituidas, use_container_width=True, hide_index=True)
                    
                    if not operacoes_removidas.empty:
                        st.markdown("#### üóëÔ∏è **Registros Removidos**")
                        st.dataframe(operacoes_removidas, use_container_width=True, hide_index=True)
            
            # Resumo por respons√°vel
            if not df_final.empty:
                resumo_responsaveis = df_final.groupby("RESPONS√ÅVEL").agg({
                    "DATA": ["count", "min", "max"]
                }).round(0)
                
                resumo_responsaveis.columns = ["Total Registros", "Data Inicial", "Data Final"]
                resumo_responsaveis["Data Inicial"] = pd.to_datetime(resumo_responsaveis["Data Inicial"]).dt.strftime("%d/%m/%Y")
                resumo_responsaveis["Data Final"] = pd.to_datetime(resumo_responsaveis["Data Final"]).dt.strftime("%d/%m/%Y")
                
                with st.expander("üë• Resumo por Respons√°vel"):
                    st.dataframe(resumo_responsaveis, use_container_width=True)
            
            return True
        else:
            status_container.error(f"‚ùå **Erro no upload:** Status {status_code}")
            if status_code != 500:
                st.code(resposta)
            return False
            
    except Exception as e:
        # EM CASO DE ERRO, SEMPRE REMOVER O LOCK
        logger.error(f"Erro na consolida√ß√£o: {e}")
        remover_lock(token, session_id, force=True)
        
        # Limpar containers e mostrar erro
        status_container.error(f"‚ùå **Erro durante consolida√ß√£o:** {str(e)}")
        progress_container.empty()
        st.error("üîì **Sistema liberado automaticamente ap√≥s erro.**")
        return False

# ===========================
# INTERFACE STREAMLIT
# ===========================
def exibir_info_versao():
    """Exibe informa√ß√µes de vers√£o e changelog"""
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è Informa√ß√µes do Sistema")
        st.info(f"**Vers√£o:** {APP_VERSION}")
        st.info(f"**Data:** {VERSION_DATE}")
        
        # Destaque para nova vers√£o
        if APP_VERSION == "2.2.4":
            st.success("üîß **L√ìGICA CONSOLIDA√á√ÉO CORRIGIDA**")
            st.caption("Corrigido problema de exclus√£o indevida")
        
        # Mostrar configura√ß√£o de pastas
        with st.expander("üìÅ Configura√ß√£o de Pastas"):
            st.markdown("**Arquivo Consolidado:**")
            st.code(PASTA_CONSOLIDADO, language=None)
            st.markdown("**Backups e Envios:**")
            st.code(PASTA_ENVIOS_BACKUPS, language=None)
        
        with st.expander("üìã Changelog"):
            for version, info in CHANGELOG.items():
                st.markdown(f"#### v{version} ({info['date']})")
                for change in info['changes']:
                    st.markdown(f"- {change}")
                st.markdown("---")

def main():
    st.set_page_config(
        page_title=f"DSView BI - Upload Planilhas v{APP_VERSION}", 
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Header com logo e vers√£o
    st.markdown(
        f'''
        <div style="display: flex; align-items: center; justify-content: space-between; margin-bottom: 20px;">
            <div style="display: flex; align-items: center; gap: 15px;">
                <h2 style="margin: 0; color: #2E8B57;">üìä DSView BI ‚Äî Upload de Planilhas</h2>
            </div>
            <div style="text-align: right; color: #666; font-size: 0.9em;">
                <strong>v{APP_VERSION}</strong><br>
                <small>{VERSION_DATE}</small>
            </div>
        </div>
        ''',
        unsafe_allow_html=True
    )

    # Destaque para nova vers√£o corrigida
    if APP_VERSION == "2.2.4":
        st.success("üîß **L√ìGICA DE CONSOLIDA√á√ÉO CORRIGIDA** - Problema de exclus√£o indevida de respons√°veis resolvido!")

    # Sidebar navigation
    st.sidebar.markdown("### üì§ Upload de Planilhas")
    st.sidebar.markdown("Sistema de consolida√ß√£o de relat√≥rios")
    st.sidebar.divider()
    st.sidebar.markdown("**Status do Sistema:**")
    
    # Verificar autentica√ß√£o
    token = obter_token()
    if not token:
        st.sidebar.error("‚ùå Desconectado")
        st.error("‚ùå N√£o foi poss√≠vel autenticar. Verifique as credenciais.")
        st.stop()
    else:
        st.sidebar.success("‚úÖ Conectado")

    # ===========================
    # VERIFICA√á√ÉO DE SISTEMA DE LOCK
    # ===========================
    st.markdown("## üîí Status do Sistema")
    
    # Verificar e exibir status do lock
    sistema_ocupado = exibir_status_sistema(token)
    
    # Auto-refresh a cada 15 segundos se sistema estiver ocupado
    if sistema_ocupado:
        st.markdown("---")
        st.info("üîÑ Esta p√°gina ser√° atualizada automaticamente a cada 15 segundos")
        time.sleep(15)
        st.rerun()

    st.divider()

    # Informa√ß√µes de vers√£o na sidebar
    exibir_info_versao()

    st.markdown("## üì§ Upload de Planilha Excel")
    
    # Mostrar aviso se sistema estiver ocupado
    if sistema_ocupado:
        st.warning("‚ö†Ô∏è **Upload desabilitado** - Sistema em uso por outro usu√°rio")
        st.info("üí° **Aguarde** a libera√ß√£o do sistema ou tente novamente em alguns minutos")
        
        # Bot√£o para atualizar status
        if st.button("üîÑ Verificar Status Novamente"):
            st.rerun()
        
        # N√£o mostrar o resto da interface se sistema estiver ocupado
        return
    
    # Sistema livre - mostrar interface normal
    st.info("üí° **Importante**: A planilha deve conter uma coluna 'RESPONS√ÅVEL' com os nomes dos respons√°veis!")
    
    # Aviso sobre valida√ß√£o rigorosa
    st.error("üîí **VALIDA√á√ÉO SUPER RIGOROSA ATIVADA v2.2.3**")
    st.warning("üìã **QUALQUER problema de data (vazias, formato inv√°lido, futuras, antigas) impedir√° a consolida√ß√£o!**")
    st.info("üí° **Dica**: Revise cuidadosamente sua planilha antes de enviar. Todas as datas devem estar corretas.")
    
    # Nova estrutura de pastas
    with st.expander("üìÅ Nova Estrutura de Pastas - v2.2.0", expanded=False):
        st.markdown("### üéØ Organiza√ß√£o Melhorada dos Arquivos")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**üìä Arquivo Consolidado:**")
            st.code(f"{PASTA_CONSOLIDADO}/Reports_Geral_Consolidado.xlsx", language=None)
            st.caption("Arquivo principal com todos os dados consolidados")
            
        with col2:
            st.markdown("**üíæ Backups e Envios:**")
            st.code(f"{PASTA_ENVIOS_BACKUPS}/", language=None)
            st.caption("Pasta separada para arquivos enviados e backups")
        
        st.success("‚úÖ **Benef√≠cios:** Melhor organiza√ß√£o, backups separados e facilita a manuten√ß√£o")
    
    # Corre√ß√µes da v2.2.4
    with st.expander("üîß Corre√ß√µes da v2.2.4 - L√ìGICA CONSOLIDA√á√ÉO", expanded=True):
        st.markdown("### üõ°Ô∏è **Problemas Corrigidos:**")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
            **‚ùå Problema Anterior:**
            - Exclus√£o indevida de respons√°veis
            - Perda de dados durante consolida√ß√£o
            - Falta de verifica√ß√µes de seguran√ßa
            """)
            
        with col2:
            st.markdown("""
            **‚úÖ Solu√ß√µes Implementadas:**
            - Verifica√ß√£o de seguran√ßa obrigat√≥ria
            - Logs detalhados de consolida√ß√£o
            - An√°lise pr√©-consolida√ß√£o
            - Feedback visual em tempo real
            """)
        
        st.success("üéØ **Resultado:** Consolida√ß√£o 100% segura - nenhum dado ser√° perdido inadvertidamente!")
    
    st.divider()

    # Upload de arquivo (s√≥ aparece se sistema estiver livre)
    uploaded_file = st.file_uploader(
        "Escolha um arquivo Excel", 
        type=["xlsx", "xls"],
        help="Formatos aceitos: .xlsx, .xls | Certifique-se de que h√° uma coluna 'RESPONS√ÅVEL' na planilha"
    )

    # Processar arquivo carregado
    df = None
    if uploaded_file:
        try:
            st.success(f"üìÅ Arquivo carregado: **{uploaded_file.name}**")
            
            # Detectar tipo de arquivo
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            with st.spinner("üìñ Lendo arquivo..."):
                if file_extension == 'xls':
                    xls = pd.ExcelFile(uploaded_file, engine='xlrd')
                else:
                    xls = pd.ExcelFile(uploaded_file)
                
                sheets = xls.sheet_names
                
                # Selecionar aba
                if len(sheets) > 1:
                    # Verificar se existe aba "Vendas CTs" 
                    if "Vendas CTs" in sheets:
                        sheet = "Vendas CTs"
                        st.success("‚úÖ Aba 'Vendas CTs' encontrada e selecionada automaticamente")
                    else:
                        sheet = st.selectbox(
                            "Selecione a aba (recomendado: 'Vendas CTs'):", 
                            sheets,
                            help="Para melhor compatibilidade, use uma aba chamada 'Vendas CTs'"
                        )
                        if sheet != "Vendas CTs":
                            st.warning("‚ö†Ô∏è Recomendamos que a aba seja chamada 'Vendas CTs'")
                else:
                    sheet = sheets[0]
                    if sheet != "Vendas CTs":
                        st.warning(f"‚ö†Ô∏è A aba atual se chama '{sheet}'. Recomendamos renome√°-la para 'Vendas CTs'")
                
                # Ler dados
                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                df.columns = df.columns.str.strip().str.upper()
                
            st.success(f"‚úÖ Dados carregados com sucesso!")
            
        except Exception as e:
            st.error(f"‚ùå Erro ao ler o Excel: {e}")
            logger.error(f"Erro ao ler Excel: {e}")

    # Mostrar pr√©via e valida√ß√µes
    if df is not None:
        # Pr√©via dos dados
        st.subheader("üëÄ Pr√©via dos dados")
        st.dataframe(df.head(10), use_container_width=True, height=300)

        # Resumo dos dados
        st.subheader("üìä Resumo dos dados")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Linhas", df.shape[0])
        with col2:
            st.metric("Colunas", df.shape[1])
        with col3:
            if "DATA" in df.columns:
                datas_validas = pd.to_datetime(df["DATA"], errors="coerce").notna().sum()
                st.metric("Datas v√°lidas", datas_validas)

        # Resumo de totais por produto
        st.subheader("üí∞ Resumo de Totais por Produto")
        
        # Lista das colunas de produtos corrigidas
        colunas_produtos = ['TMO - DUTO', 'TMO - FREIO', 'TMO - SANIT', 'TMO - VERNIZ', 'CX EVAP']
        
        # Encontrar colunas que existem no DataFrame
        colunas_encontradas = [col for col in colunas_produtos if col in df.columns]
        
        if colunas_encontradas:
            # Calcular totais
            totais = {}
            total_geral = 0
            
            for coluna in colunas_encontradas:
                # Converter para num√©rico, tratando erros como 0
                valores_numericos = pd.to_numeric(df[coluna], errors='coerce').fillna(0)
                total = int(valores_numericos.sum())  # Converter para inteiro
                totais[coluna] = total
                total_geral += total
            
            # Calcular TMO - Total se houver colunas TMO
            colunas_tmo = [col for col in colunas_encontradas if col.startswith('TMO -')]
            if colunas_tmo:
                tmo_total = sum(totais[col] for col in colunas_tmo)
                totais['TMO - TOTAL'] = tmo_total
            
            # Exibir m√©tricas em colunas
            produtos_para_exibir = [col for col in colunas_produtos if col in totais]
            if 'TMO - TOTAL' in totais:
                produtos_para_exibir.append('TMO - TOTAL')
            
            num_colunas = len(produtos_para_exibir)
            cols = st.columns(num_colunas)
            
            # Mostrar totais por produto
            for i, coluna in enumerate(produtos_para_exibir):
                with cols[i]:
                    total = totais[coluna]
                    # Formatar n√∫mero com separadores de milhares (formato inteiro)
                    total_formatado = f"{total:,}".replace(',', '.')
                    
                    # Definir emoji baseado no produto
                    if 'DUTO' in coluna:
                        emoji = "üîß"
                    elif 'FREIO' in coluna:
                        emoji = "üöó"
                    elif 'SANIT' in coluna:
                        emoji = "üßΩ"
                    elif 'VERNIZ' in coluna:
                        emoji = "üé®"
                    elif 'EVAP' in coluna:
                        emoji = "üì¶"
                    elif 'TOTAL' in coluna:
                        emoji = "üí∞"
                    else:
                        emoji = "üìä"
                    
                    # Nome simplificado para exibi√ß√£o
                    nome_display = coluna.replace('TMO - ', '').title()
                    
                    st.metric(f"{emoji} {nome_display}", total_formatado)
            
            # Tabela resumo adicional
            with st.expander("üìã Detalhes dos Totais"):
                resumo_data = []
                for coluna in produtos_para_exibir:
                    total = totais[coluna]
                    nome_produto = coluna.replace('TMO - ', '').title()
                    resumo_data.append({
                        'Produto': nome_produto,
                        'Total': f"{total:,}".replace(',', '.'),
                        'Registros': (pd.to_numeric(df[coluna], errors='coerce') > 0).sum() if coluna in df.columns else 0
                    })
                
                df_resumo = pd.DataFrame(resumo_data)
                st.dataframe(df_resumo, use_container_width=True, hide_index=True)
        else:
            st.warning("‚ö†Ô∏è Nenhuma coluna de produtos encontrada")
            
            # Mostrar colunas dispon√≠veis para ajudar o usu√°rio
            with st.expander("üîç Ver colunas dispon√≠veis"):
                colunas_disponiveis = [col for col in df.columns if col != 'DATA']
                st.write("**Colunas encontradas na planilha:**")
                for col in colunas_disponiveis:
                    st.write(f"‚Ä¢ {col}")
                st.info("üí° **Dica:** Renomeie as colunas na sua planilha para: TMO - Duto, TMO - Freio, TMO - Sanit, TMO - Verniz, CX EVAP")

        # Verificar